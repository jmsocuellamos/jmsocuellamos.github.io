<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.4 Multicolinealidad y Diagnóstico del modelo | Modelos Estadísticos</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="1.4 Multicolinealidad y Diagnóstico del modelo | Modelos Estadísticos" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.4 Multicolinealidad y Diagnóstico del modelo | Modelos Estadísticos" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Javier Morales (Universidad Miguel Hernández de Elche)" />
<meta name="author" content="Mª Asunción Martínez (Universidad Miguel Hernández de Elche)" />


<meta name="date" content="2020-05-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="comparación-y-selección-de-modelos.html"/>
<link rel="next" href="predicción.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Estadísticos</a></li>
<li><a href="./">J. Morales y A.M. Mayoral</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="requisitos.html"><a href="requisitos.html"><i class="fa fa-check"></i>Requisitos</a></li>
<li class="chapter" data-level="1" data-path="rlm.html"><a href="rlm.html"><i class="fa fa-check"></i><b>1</b> Regresión Lineal Múltiple y Polinómica</a><ul>
<li class="chapter" data-level="1.1" data-path="tipos-de-modelos.html"><a href="tipos-de-modelos.html"><i class="fa fa-check"></i><b>1.1</b> Tipos de modelos</a><ul>
<li class="chapter" data-level="1.1.1" data-path="tipos-de-modelos.html"><a href="tipos-de-modelos.html#modelos-de-rlm"><i class="fa fa-check"></i><b>1.1.1</b> Modelos de RLM</a></li>
<li class="chapter" data-level="1.1.2" data-path="tipos-de-modelos.html"><a href="tipos-de-modelos.html#modelos-de-rp"><i class="fa fa-check"></i><b>1.1.2</b> Modelos de RP</a></li>
<li class="chapter" data-level="1.1.3" data-path="tipos-de-modelos.html"><a href="tipos-de-modelos.html#expresión-en-r-de-los-modelos"><i class="fa fa-check"></i><b>1.1.3</b> Expresión en <code>R</code> de los modelos</a></li>
<li class="chapter" data-level="1.1.4" data-path="tipos-de-modelos.html"><a href="tipos-de-modelos.html#modelo-saturado-y-anidado"><i class="fa fa-check"></i><b>1.1.4</b> Modelo saturado y anidado</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="estimación-inferencia-y-bondad-de-ajuste.html"><a href="estimación-inferencia-y-bondad-de-ajuste.html"><i class="fa fa-check"></i><b>1.2</b> Estimación, inferencia y bondad de ajuste</a><ul>
<li class="chapter" data-level="1.2.1" data-path="estimación-inferencia-y-bondad-de-ajuste.html"><a href="estimación-inferencia-y-bondad-de-ajuste.html#estimación-por-mínimos-cuadrados"><i class="fa fa-check"></i><b>1.2.1</b> Estimación por mínimos cuadrados</a></li>
<li class="chapter" data-level="1.2.2" data-path="estimación-inferencia-y-bondad-de-ajuste.html"><a href="estimación-inferencia-y-bondad-de-ajuste.html#estimación-por-máxima-verosimilitud"><i class="fa fa-check"></i><b>1.2.2</b> Estimación por máxima verosimilitud</a></li>
<li class="chapter" data-level="1.2.3" data-path="estimación-inferencia-y-bondad-de-ajuste.html"><a href="estimación-inferencia-y-bondad-de-ajuste.html#inferencia"><i class="fa fa-check"></i><b>1.2.3</b> Inferencia</a></li>
<li class="chapter" data-level="1.2.4" data-path="estimación-inferencia-y-bondad-de-ajuste.html"><a href="estimación-inferencia-y-bondad-de-ajuste.html#ejemplos"><i class="fa fa-check"></i><b>1.2.4</b> Ejemplos</a></li>
<li class="chapter" data-level="1.2.5" data-path="estimación-inferencia-y-bondad-de-ajuste.html"><a href="estimación-inferencia-y-bondad-de-ajuste.html#bondad-del-ajuste"><i class="fa fa-check"></i><b>1.2.5</b> Bondad del ajuste</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="comparación-y-selección-de-modelos.html"><a href="comparación-y-selección-de-modelos.html"><i class="fa fa-check"></i><b>1.3</b> Comparación y selección de modelos</a><ul>
<li class="chapter" data-level="1.3.1" data-path="comparación-y-selección-de-modelos.html"><a href="comparación-y-selección-de-modelos.html#significatividad-de-los-predictores"><i class="fa fa-check"></i><b>1.3.1</b> Significatividad de los predictores</a></li>
<li class="chapter" data-level="1.3.2" data-path="comparación-y-selección-de-modelos.html"><a href="comparación-y-selección-de-modelos.html#los-estadísticos-aic-y-bic"><i class="fa fa-check"></i><b>1.3.2</b> Los estadísticos <span class="math inline">\(AIC\)</span> y <span class="math inline">\(BIC\)</span></a></li>
<li class="chapter" data-level="1.3.3" data-path="comparación-y-selección-de-modelos.html"><a href="comparación-y-selección-de-modelos.html#procedimientos-secuenciales-de-selección-de-variables"><i class="fa fa-check"></i><b>1.3.3</b> Procedimientos secuenciales de selección de variables</a></li>
<li class="chapter" data-level="1.3.4" data-path="comparación-y-selección-de-modelos.html"><a href="comparación-y-selección-de-modelos.html#funciones-especificas-para-modelos-de-regresión"><i class="fa fa-check"></i><b>1.3.4</b> Funciones especificas para modelos de regresión</a></li>
<li class="chapter" data-level="1.3.5" data-path="comparación-y-selección-de-modelos.html"><a href="comparación-y-selección-de-modelos.html#ejemplos-2"><i class="fa fa-check"></i><b>1.3.5</b> Ejemplos</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="multicolinealidad-y-diagnóstico-del-modelo.html"><a href="multicolinealidad-y-diagnóstico-del-modelo.html"><i class="fa fa-check"></i><b>1.4</b> Multicolinealidad y Diagnóstico del modelo</a><ul>
<li class="chapter" data-level="1.4.1" data-path="multicolinealidad-y-diagnóstico-del-modelo.html"><a href="multicolinealidad-y-diagnóstico-del-modelo.html#multicolinealidad"><i class="fa fa-check"></i><b>1.4.1</b> Multicolinealidad</a></li>
<li class="chapter" data-level="1.4.2" data-path="multicolinealidad-y-diagnóstico-del-modelo.html"><a href="multicolinealidad-y-diagnóstico-del-modelo.html#diagnóstico-del-modelo"><i class="fa fa-check"></i><b>1.4.2</b> Diagnóstico del modelo</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="predicción.html"><a href="predicción.html"><i class="fa fa-check"></i><b>1.5</b> Predicción</a><ul>
<li class="chapter" data-level="1.5.1" data-path="predicción.html"><a href="predicción.html#estimación-de-la-respuesta-media."><i class="fa fa-check"></i><b>1.5.1</b> Estimación de la respuesta media.</a></li>
<li class="chapter" data-level="1.5.2" data-path="predicción.html"><a href="predicción.html#predicción-de-nuevas-observaciones."><i class="fa fa-check"></i><b>1.5.2</b> Predicción de nuevas observaciones.</a></li>
<li class="chapter" data-level="1.5.3" data-path="predicción.html"><a href="predicción.html#ejemplos-5"><i class="fa fa-check"></i><b>1.5.3</b> Ejemplos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ejercicios-modelos-de-regresión.html"><a href="ejercicios-modelos-de-regresión.html"><i class="fa fa-check"></i><b>2</b> Ejercicios modelos de regresión</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Creado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Estadísticos</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multicolinealidad-y-diagnóstico-del-modelo" class="section level2">
<h2><span class="header-section-number">1.4</span> Multicolinealidad y Diagnóstico del modelo</h2>
<div id="multicolinealidad" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Multicolinealidad</h3>
<p>La <strong>multicolinealidad</strong> es un problema relativamente frecuente en regresión lineal múltiple, y en general en análisis con varias variables explicativas, entre cuyas soluciones se halla la selección de variables. Cuando los regresores no están relacionados linealmente entre sí, se dice que son <em>ortogonales</em>. Que exista multicolinealidad significa que las columnas de <span class="math inline">\(X\)</span> no son linealmente independientes. Si existiera una dependencia lineal total entre algunas de las columnas, tendríamos que el rango de la matriz <span class="math inline">\(X&#39;X\)</span> sería menor a <span class="math inline">\(p\)</span> y <span class="math inline">\((X&#39;X)^{-1}\)</span> no existiría. El hecho de que haya multicolinealidad, esto es, una relación casi lineal entre algunos regresores, afecta a la estimación e interpretación de los coeficientes del modelo.</p>
<p>La multicolinealidad no es un problema de violación de hipótesis; simplemente es una situación que puede ocasionar problemas en las inferencias con el modelo de regresión. Nos ocupamos a continuación de examinar las causas de la multicolinealidad, algunos de los efectos que tiene en las inferencias, los métodos básicos para detectar el problema y algunas formas de tratarlo.</p>
<div id="causas" class="section level4">
<h4><span class="header-section-number">1.4.1.1</span> Causas</h4>
<p>Montgomery y Peck (1992) comentan que la colinealidad puede surgir por el método de recogida de datos, restricciones en el modelo o en la población, especificación y sobreformulación del modelo (consideración de más variables de las necesarias); en modelos polinómicos, por ejemplo, se pueden presentar problemas serios de multicolinealidad en la matriz de diseño <span class="math inline">\(X\)</span> cuando el rango de variación de los predictores es muy pequeño. Obviamente, modelos con más covariables son más propicios a padecer problemas de multicolinealidad.</p>
</div>
<div id="efectos" class="section level4">
<h4><span class="header-section-number">1.4.1.2</span> Efectos</h4>
<p>Los principales efectos de la multicolinealidad son los siguientes:</p>
<ul>
<li>Una multicolinealidad fuerte produce varianzas y covarianzas grandes para los estimadores de mínimos cuadrados. Así, muestras con pequeñas diferencias podrían dar lugar a estimaciones muy diferentes de los coeficientes del modelo. Es decir, las estimaciones de los coeficientes resultan poco fiables cuando hay un problema de multicolinealidad. De hecho, dichos coeficientes vienen a explicar cómo varía la respuesta cuando varía la variable independiente en cuestión y todas las demás quedan fijas; si las variables predictoras están relacionadas entre sí, es inviable que al variar una no lo vayan a hacer las demás y en consecuencia puedan quedar fijas. La multicolinealidad reduce la efectividad del ajuste lineal si su propósito es determinar los efectos de las variables independientes.</li>
<li>A consecuencia de la gran magnitud de los errores estándar de las estimaciones, muchas de éstas no resultarían significativamente distintas de cero: los intervalos de confianza serán ‘grandes’ y por tanto, con frecuencia contendrán al cero.</li>
<li>La multicolinealidad tiende a producir estimaciones de mínimos cuadrados <span class="math inline">\(\hat{\beta}_j\)</span> muy grandes en valor absoluto.</li>
<li>Los coeficientes del ajuste con todos los predictores difieren bastante de los que se obtendrían con una regresión simple entre la respuesta y cada variable explicativa.</li>
<li>La multicolinealidad no afecta al ajuste global del modelo (medidas como la <span class="math inline">\(R^2\)</span>, etc.) y por lo tanto no afecta a la habilidad del modelo para estimar puntualmente la respuesta o la varianza residual. Sin embargo, al aumentar los errores estándar de las estimaciones de los coeficientes del modelo, también lo hacen los errores estándar de las estimaciones de la respuesta media y de la predicción de nuevas observaciones, lo que afecta a la estimación en intervalo.</li>
</ul>
</div>
<div id="diagnósticos" class="section level4">
<h4><span class="header-section-number">1.4.1.3</span> Diagnósticos</h4>
<p>Existen diversos diagnósticos propuestos para detectar problemas de multicolinealidad. Consideramos los más relevantes, que son:</p>
<ul>
<li>Los <strong>gráficos entre variables explicativas</strong> son útiles para estudiar la relación entre las variables explicativas y su disposición en el espacio, y con ello detectar correlaciones o identificar observaciones muy alejadas del resto de datos y que pueden influenciar notablemente la estimación. Consisten en gráficos de dispersión entre un par de covariables continuas o un par de factores (a través de sus códigos), y gráficos de cajas cuando se trata de investigar la relación entre un factor y una covariable.</li>
<li>Una medida simple de multicolinealidad consiste en la inspección de los elementos fuera de la diagonal de la matriz <span class="math inline">\(X&#39;X\)</span>, es decir, las correlaciones simples <span class="math inline">\(r_{ij}\)</span> entre todos los regresores. Si dos regresores <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j\)</span> son casi linealmente dependientes, entonces <span class="math inline">\(|r_{ij}| \approx 1\)</span>. Sin embargo, cuando la multicolinealidad involucra a varias variables, no hay garantías de detectarla a través de las correlaciones bivariadas.</li>
<li>Puesto que uno de los efectos principales de la multicolinealidad es la inflación de la varianza y covarianza de las estimaciones, es posible calcular unos <strong>factores de inflación de la varianza</strong>, <strong>FIV</strong>, que permiten apreciar tal efecto. En concreto, la varianza de <span class="math inline">\(\hat{\beta}_j\)</span> viene estimada por <span class="math inline">\(Var(\hat{\beta}_j)=s^2 \, C_{jj}\)</span>, donde <span class="math inline">\(C_{jj}^X\)</span> son los elementos de la diagonal de la matriz <span class="math inline">\((X&#39;X)^{-1}\)</span>, es decir,</li>
</ul>
<p><span class="math display">\[
C_{jj}^X=\frac{1}{(1-R_j^2) \, S_{x_j x_j}}, \ \ j=1,2,\ldots,p,
\]</span></p>
<p>con <span class="math inline">\(R_j^2\)</span> el coeficiente de determinación múltiple para la regresión de <span class="math inline">\(x_j\)</span> sobre las restantes <span class="math inline">\(p-1\)</span> covariables. Si hay una correlación muy alta entre <span class="math inline">\(x_j\)</span> y los restantes regresores, entonces <span class="math inline">\(R_j^2 \approx 1\)</span>. En particular, puesto que <span class="math inline">\(s^2\)</span> no varía ante un problema de multicolinealidad, si ésta existe, la varianza de <span class="math inline">\(\hat{\beta}_j\)</span> aumenta por un factor igual a <span class="math inline">\(1/(1-R_j^2)\)</span>, que se define como el FIV para <span class="math inline">\(x_j\)</span>:</p>
<p><span class="math display">\[
FIV_j=1/(1-R_j^2).
\]</span></p>
<p>Generalmente, valores de un FIV superiores a 10 dan indicios de un problema de multicolinealidad, si bien su magnitud depende del modelo ajustado. Lo ideal es compararlo con su equivalente en el modelo ajustado, esto es, <span class="math inline">\(1/(1-R^2)\)</span>, donde <span class="math inline">\(R^2\)</span> es el coeficiente de determinación del modelo. Los valores FIV mayores que esta cantidad implican que la relación entre las variables independientes es mayor que la que existe entre la respuesta y los predictores, y por tanto dan indicios de multicolinealidad.</p>
<ul>
<li><p>Dado que la multicolinealidad afecta a la singularidad (rango menor que <span class="math inline">\(p\)</span>) de la matriz <span class="math inline">\(X&#39;X\)</span>, sus valores propios <span class="math inline">\(\lambda_1,\lambda_2,\ldots,\lambda_p\)</span> pueden revelar multicolinealidad en los datos. De hecho, si hay una o más dependencias casi lineales en los datos, entonces uno o más de los valores propios será pequeño.</p></li>
<li><p>En lugar de buscar valores propios pequeños, se puede optar por calcular el <strong>número de condición</strong> de <span class="math inline">\(X&#39;X\)</span>, definido por:</p></li>
</ul>
<p><span class="math display">\[
\kappa = \lambda_{max}/\lambda_{min},
\]</span></p>
<p>que es una medida de dispersión en el espectro de valores propios de <span class="math inline">\(X&#39;X\)</span>. Generalmente, si el número de condición es menor que 100, no hay problemas de multicolinealidad. Números de condición entre 100 y 1000 implican multicolinealidad moderada, y mayores que 1000 implican multicolinealidad severa.</p>
<ul>
<li>Los <strong>índices de condición</strong> de la matriz <span class="math inline">\(X&#39;X\)</span> también son útiles para el diagnóstico de multicolinealidad y se definen por:</li>
</ul>
<p><span class="math display">\[
\kappa_j = \lambda_{max}/\lambda_j, \ \ \ j=1,\ldots,p.
\]</span></p>
<p>El número de índices de condición que son grandes (por ejemplo, <span class="math inline">\(\geq 1000\)</span>) es una medida útil del número de dependencias casi lineales en <span class="math inline">\(X&#39;X\)</span>.</p>
<ul>
<li>Otra posibilidad de diagnóstico es a través de un análisis de componentes principales. Este tipo de análisis multivariante se plantea sobre conjuntos de variables relacionadas linealmente entre sí y tiene como finalidad la de definir un conjunto menor de nuevas variables obtenidas como combinación lineal de las originales, y que a la vez resultan ortogonales entre sí. Si el análisis de componentes principales resulta significativo, estamos reconociendo multicolinealidad.</li>
</ul>
</div>
<div id="soluciones" class="section level4">
<h4><span class="header-section-number">1.4.1.4</span> Soluciones</h4>
<p>Una vez detectado un problema de multicolinealidad, es recomendable intentar aliviarlo (por sus efectos). Para ello disponemos de diversos recursos, y en función del objetivo del análisis, será más aconsejable uno u otro. Básicamente podemos distinguir como objetivos esenciales:</p>
<ul>
<li>Estimar bien la respuesta media en función de un conjunto de variables explicativas, sin importar demasiado la contribución individual de cada una de esas variables.</li>
<li>Hacer un <strong>análisis de estructura</strong>, esto es, describir el efecto de las variables explicativas en la predicción de la respuesta. Las magnitudes y significatividades de los coeficientes son entonces de interés. Así, en un análisis de estructura es importante conseguir un buen modelo de ajuste para cuantificar bien la información que aportan las variables explicativas sobre la respuesta.</li>
</ul>
<p>Hay tres aproximaciones básicas como remedio a la multicolinealidad:</p>
<ul>
<li><p><strong>Selección de variables</strong> (ver Sección <strong>XX</strong>). Respecto a la selección de variables, lo ideal ante un problema de multicolinealidad es seleccionar aquellas variables predictoras que son más significativas y contienen la mayor parte de la información sobre la respuesta. Sin embargo, hay que actuar con precaución, pues los métodos automáticos de selección de variables son bastante sensibles cuando existe relación entre los regresores y no está garantizado que el modelo resultante tenga menor multicolinealidad. Por otro lado, la capacidad predictiva del modelo puede verse seriamente menguada al reducir el número de covariables consideradas, de modo que este remedio iría más indicado cuando el objetivo del análisis es el 2.</p></li>
<li><p><strong>Redefinición de variables.</strong> Otra alternativa es transformar las covariables. Para ello es importante identificar entre qué covariables hay relación, con el fin de utilizar transformaciones apropiadas. Si varias variables están relacionadas linealmente, a veces funciona considerar la más completa de ellas tal y como es, y transformaciones de las otras con cocientes o diferencias respecto de la más completa. Es decir, si <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j\)</span> están relacionadas y <span class="math inline">\(x_i\)</span> da una información más completa que <span class="math inline">\(x_j\)</span>, se puede considerar un nuevo ajuste que involucre a las variables <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j/x_i\)</span>, o bien a <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j-x_i\)</span>.
Cuando la intuición o el conocimiento de las variables no sugiere ninguna transformación concreta, una opción es llevar a cabo un <em>análisis de componentes principales</em> con el fin de obtener nuevas variables, expresables como combinación lineal de las originales, ortogonales entre sí y que contengan toda la información disponible en las primeras. En ocasiones, las componentes que resultan tienen un significado intuitivo por la forma de asimilar la información de las variables originales, y en ocasiones no, en cuyo caso se puede proceder a la realización de un análisis factorial y a la búsqueda de alguna rotación geométrica que permita llegar a variables “interpretables”.
Una vez obtenidas las componentes <span class="math inline">\(Z\)</span>, se pueden seguir dos alternativas: i) plantear una regresión de la respuesta explicada por todas las componentes principales obtenidas, o ii) ajustar un modelo de regresión sólo con las componentes más relevantes como variables predictoras (<strong>componentes principales incompletas</strong>). En el primer caso, a partir del modelo ajustado <span class="math inline">\(y=Z\gamma+\epsilon\)</span>, es posible recuperar el efecto de las variables originales sobre la respuesta sin más que deshacer el cambio. Esto no es posible para la segunda alternativa, pues las estimaciones que se consiguen están sesgadas; sin embargo, esta opción reduce la varianza de las estimaciones respecto del modelo original.</p></li>
<li><p><strong>Estimación sesgada.</strong> Si uno de los efectos de la multicolinealidad es que aumenta el error estándar de las estimaciones por mínimos cuadrados de los coeficientes del modelo, cabe la posibilidad de utilizar estimadores que, aun sesgados, produzcan estimaciones con menor error estándar y un error cuadrático medio inferior al de los estimadores de mínimos cuadrados (que son, de los insesgados, los de mínima varianza).</p></li>
</ul>
<p>Hay varios procedimientos de estimación sesgada. Las <em>componentes principales incompletas</em> es uno de ellos. La <em>regresión Ridge</em> es otro método interesante. La <strong>regresión Ridge</strong> consiste en utilizar como estimador de <span class="math inline">\(\beta\)</span>, el siguiente:</p>
<p><span class="math display">\[
\hat{\beta}_k=(X&#39;X+kI)^{-1} X&#39;y,
\]</span></p>
<p>donde <span class="math inline">\(k\)</span> es una constante pequeña arbitraria.</p>
<p>Cuando todos los predictores están estandarizados, tenemos que <span class="math inline">\(X&#39;X\)</span> es la matriz de correlaciones, con unos en la diagonal. Así, la correlación “efectiva” que se consigue ahora entre <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j\)</span> es <span class="math inline">\(r_{ij}/(1+k)\)</span>. Es decir, todas las correlaciones se reducen artificialmente en un factor <span class="math inline">\(1/(1+k)\)</span>, reduciendo entonces la multicolinealidad. Valores grandes de <span class="math inline">\(k\)</span> reducen la multicolinealidad pero, como contraprestación, aumentan el sesgo de las estimaciones. Para determinar el valor de <span class="math inline">\(k\)</span> a utilizar, se suelen considerar gráficos en los que se representa <span class="math inline">\(k\)</span> versus las estimaciones del modelo (<em>ridge plots</em>). Para valores pequeños de <span class="math inline">\(k\)</span>, las estimaciones de los coeficientes cambian mucho, mientras que a medida que <span class="math inline">\(k\)</span> aumenta, las estimaciones parecen estabilizarse. Se dice que se consigue un valor óptimo para <span class="math inline">\(k\)</span> cuando se da dicha estabilización en las estimaciones. Este procedimiento resulta pues, algo subjetivo, pero sin embargo ha resultado efectivo en la práctica.</p>
<p>Hay otros procedimientos sesgados de estimación propuestos en la literatura que alivian el problema de la multicolinealidad.</p>
</div>
<div id="ejemplos-3" class="section level4">
<h4><span class="header-section-number">1.4.1.5</span> Ejemplos</h4>
<p>A continuación, realizamos el estudio de multicolinealidad para los diferentes bancos de datos que hemos venido trabajando. Para el calculo de los factores de inflacción de la varianza y los números de condición utilizamos la función <code>ols_coll_diag()</code> de la librería <code>olsrr</code>. Con ella obtenemos el <code>VIF</code> asociado con cada variable, el índice de condición asociado con cada valor propio, y la matriz de correlaciones asociada al modelo ajustado.</p>
<p>En caso de detectar multicolinealidad trataremos de corregirla con los procedimientos presentados.</p>
<div id="datos-de-bosque-3" class="section level5">
<h5><span class="header-section-number">1.4.1.5.1</span> Datos de bosque</h5>
<p>Para el análisis de multicolinealidad tomamos el modelo obtenido después del proceso de selección de variables de la sección anterior.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb69-1" title="1"><span class="co"># Modelos</span></a>
<a class="sourceLine" id="cb69-2" title="2">fit.bosque&lt;-<span class="st"> </span><span class="kw">lm</span>(vol <span class="op">~</span><span class="st"> </span>d16 <span class="op">+</span><span class="st"> </span>ht, <span class="dt">data =</span> bosque)</a>
<a class="sourceLine" id="cb69-3" title="3"><span class="co"># Análisis de multicolinealidad</span></a>
<a class="sourceLine" id="cb69-4" title="4"><span class="kw">ols_coll_diag</span>(fit.bosque)</a></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##   Variables Tolerance      VIF
## 1       d16  0.813726 1.228915
## 2        ht  0.813726 1.228915
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##    Eigenvalue Condition Index   intercept         d16           ht
## 1 2.991530311         1.00000 0.000270918 0.001143249 0.0002206333
## 2 0.007330472        20.20137 0.077611612 0.924370594 0.0288009800
## 3 0.001139217        51.24405 0.922117470 0.074486157 0.9709783867</code></pre>
<p>Del análisis realizado no parece detectarse multicolinealidad a través de <span class="math inline">\(VIF\)</span>, ni a través de los índices de condición. El valor de <span class="math inline">\(1/(1-R^2)\)</span> para dicho modelo es 21.28 que es superior a los valore de <span class="math inline">\(VIF\)</span> observados. Por tanto, no parece haber un problema de multicolinealidad con el modelo obtenido.</p>
</div>
<div id="datos-de-concentración-3" class="section level5">
<h5><span class="header-section-number">1.4.1.5.2</span> Datos de concentración</h5>
<p>En este caso analizamos el modelo saturado en primer lugar.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb71-1" title="1"><span class="co"># Modelos</span></a>
<a class="sourceLine" id="cb71-2" title="2">fit.concen&lt;-<span class="st"> </span><span class="kw">lm</span>(concen <span class="op">~</span><span class="st"> </span>p.cuerpo <span class="op">+</span><span class="st"> </span>p.higado <span class="op">+</span><span class="st"> </span>dosis, <span class="dt">data =</span> concentracion)</a>
<a class="sourceLine" id="cb71-3" title="3"><span class="co"># Análisis de multicolinealidad</span></a>
<a class="sourceLine" id="cb71-4" title="4"><span class="kw">ols_coll_diag</span>(fit.concen)</a></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##   Variables  Tolerance       VIF
## 1  p.cuerpo 0.01919315 52.101917
## 2  p.higado 0.74868308  1.335679
## 3     dosis 0.01944498 51.427154
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##     Eigenvalue Condition Index    intercept     p.cuerpo    p.higado
## 1 3.980955e+00         1.00000 0.0005211255 1.049346e-05 0.001061756
## 2 1.307262e-02        17.45068 0.0912614776 7.180392e-04 0.963765107
## 3 5.885352e-03        26.00803 0.8549633200 4.879743e-03 0.028213823
## 4 8.720917e-05       213.65475 0.0532540769 9.943917e-01 0.006959314
##          dosis
## 1 1.138353e-05
## 2 8.095775e-04
## 3 6.508870e-03
## 4 9.926702e-01</code></pre>
<p>Hay dos <span class="math inline">\(VIF\)</span> que indican multicolinealidad y un número de condición por encima de 100. Probamos con el modelo obtenido en el proceso de selección de variables:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" title="1"><span class="co"># Modelos</span></a>
<a class="sourceLine" id="cb73-2" title="2">fit.concen&lt;-<span class="st"> </span><span class="kw">lm</span>(concen <span class="op">~</span><span class="st"> </span>p.cuerpo <span class="op">+</span><span class="st"> </span>dosis, <span class="dt">data =</span> concentracion)</a>
<a class="sourceLine" id="cb73-3" title="3"><span class="co"># Análisis de multicolinealidad</span></a>
<a class="sourceLine" id="cb73-4" title="4"><span class="kw">ols_coll_diag</span>(fit.concen)</a></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##   Variables  Tolerance      VIF
## 1  p.cuerpo 0.01947892 51.33755
## 2     dosis 0.01947892 51.33755
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##     Eigenvalue Condition Index    intercept     p.cuerpo        dosis
## 1 2.993933e+00         1.00000 0.0009364888 1.884523e-05 2.017998e-05
## 2 5.978794e-03        22.37764 0.9398136118 4.217372e-03 5.578232e-03
## 3 8.781609e-05       184.64349 0.0592498994 9.957638e-01 9.944016e-01</code></pre>
<p>Se siguen presentando problemas de multicolinealidad. Sin embargo, aunque esto puede parecer un problema muy grave no lo es dada la situación experimental dada. Es de esperar que la dosis suministrada este claramente asociada con el peso del sujeto, y por tanto dichas variables tienen que estar relacionadas. Aunque la multicolinealidad afecta a la precisión del modelo (en este caso es poco relevante porque nuestro ajuste es bastante malo) no es un problema con el diagnóstico del modelo. En la sección siguiente determinaremos si el modelo debe ser modificado o si por el contrario nos quedamos con el modelo obtenido tras la selección de variables.</p>
</div>
<div id="datos-de-papel-3" class="section level5">
<h5><span class="header-section-number">1.4.1.5.3</span> Datos de papel</h5>
<p>Para este conjunto de datos es de esperar que los indicadores de multicolinealidad proporcionen resultados altos, ya que al tratarse de un MP la variable predictora es la misma.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb75-1" title="1"><span class="co"># Análisis de multicolinealidad</span></a>
<a class="sourceLine" id="cb75-2" title="2"><span class="kw">ols_coll_diag</span>(fit.papel)</a></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##     Variables  Tolerance      VIF
## 1      madera 0.05840859 17.12077
## 2 I(madera^2) 0.05840859 17.12077
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##   Eigenvalue Condition Index  intercept      madera I(madera^2)
## 1  2.7005883        1.000000 0.01001057 0.001973208 0.003447858
## 2  0.2904492        3.049257 0.18853949 0.001001403 0.035409847
## 3  0.0089625       17.358596 0.80144993 0.997025390 0.961142295</code></pre>
<p>El resultado del <span class="math inline">\(VIF\)</span> muestra multicolinealidad pero como es el comportamiento natural para este tipo de modelos se decide no actuar.</p>
</div>
</div>
</div>
<div id="diagnóstico-del-modelo" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Diagnóstico del modelo</h3>
<p>Estudiamos en este punto el proceso de diagnóstico de un modelo RLM o MP de los que hemos venido estudiando hasta ahora. El diagnóstico del modelo es realmente valioso por cuanto nos permite corroborar que se cumplen (o no) cada una de las hipótesis asumidas para el ajuste del modelo y que dan credibilidad a las conclusiones que obtenemos. Este diagnóstico suele sugerir con frecuencia alguna modificación correctora del modelo propuesto y nos obliga a repetir la dinámica de análisis (modelo alternativo y selección de variables) hasta dar con una solución satisfactoria.</p>
<p>La herramienta básica para el diagnóstico del modelo es el análisis de los residuos, tanto a través de gráficos, como de tests que verifican la validez de las hipótesis asumidas en el ajuste del modelo lineal:</p>
<ul>
<li><span class="math inline">\(E(\epsilon_i)=0 , \ \forall i=1,\ldots,n \ \rightsquigarrow\)</span> bondad del ajuste o linealidad.</li>
<li><span class="math inline">\(Var(\epsilon_i)=\sigma^2, \ \forall i \ \rightsquigarrow\)</span> Varianza constante (homocedasticidad).</li>
<li><span class="math inline">\(\epsilon \sim N(0,\sigma^2I) \ \rightsquigarrow\)</span> Normalidad de los errores.</li>
<li><span class="math inline">\(Cov(\epsilon_i,\epsilon_j)=0, \forall \ i\neq j \ \rightsquigarrow\)</span> Independencia de los errores.</li>
</ul>
<p>Si encontramos indicios de violación de alguna de ellas, en ocasiones podremos resolverlas a través de las soluciones que proponemos a continuación. Tanto las herramientas de diagnóstico como las soluciones propuestas para cuando encontramos problemas, son una ampliación del análisis de residuos que ya estudiamos para el modelo de regresión lineal simple. Aunque se pueden definir diferentes tipos de residuos, aquí nos concentramos en los que son de uso habitual en el diagnóstico de modelos lineales.</p>
<div id="tipos-de-residuos" class="section level4">
<h4><span class="header-section-number">1.4.2.1</span> Tipos de Residuos</h4>
<p>Presentamos diversos tipos de residuos, útiles tanto para la diagnosis del modelo como para el análisis de influencia (detección de observaciones influyentes y/o raras o anómalas). Generalmente, los procedimientos de diagnóstico del modelo basados en residuos son gráficos, si bien en ocasiones disponemos de algunos tests basados en ellos.</p>
<div id="residuos-comunes" class="section level5">
<h5><span class="header-section-number">1.4.2.1.1</span> Residuos comunes</h5>
<p>Los residuos comunes del modelo lineal <span class="math inline">\(y=X\beta+\epsilon\)</span> consisten simplemente en las desviaciones entre los datos observados <span class="math inline">\(y_i\)</span> y los predichos <span class="math inline">\(\hat{y}_i\)</span>, esto es, los obtenidos de:</p>
<p><span class="math display">\[
\textbf{e}=\textbf{y}-\hat{\textbf{y}}=y-X\hat{\beta}=\textbf{y}-X\hat{\beta}=(I-X(X&#39;X)^{-1}X&#39;)\textbf{y}
\]</span></p>
<p>cuando <span class="math inline">\(X&#39;X\)</span> es no singular.</p>
<p>Surge así una matriz básica en la definición de los residuos, denominada matriz gorro y definida por:</p>
<p><span class="math display">\[
H=X(X&#39;X)^{-1}X&#39;,
\]</span></p>
<p>que tiene su importancia en la interpretación y redefinición de nuevos tipos de residuos, como veremos. A sus elementos nos referiremos como <span class="math inline">\(h_{ij}\)</span>. Esta matriz <span class="math inline">\(H\)</span> es simétrica (<span class="math inline">\(H&#39;=H\)</span>) e idempotente (<span class="math inline">\(HH=H\)</span>), de dimensión <span class="math inline">\(n \times n\)</span> y de rango <span class="math inline">\(p=rang(X)\)</span>.</p>
<p>En términos de <span class="math inline">\(H\)</span>, los residuos <span class="math inline">\(\textbf{e}\)</span> se pueden escribir como:</p>
<p><span class="math display">\[
\textbf{e} = \textbf{y}-\hat{\textbf{y}} = (I-H) \textbf{y},
\]</span></p>
<p>esto es,</p>
<p><span class="math display">\[
e_i=(1-\sum_{j=1}^n h_{ij}) \, y_i=y_i-\hat{y}_i, \ \ \ i=1,\ldots, n.
\]</span></p>
<p>De esta forma se puede demostrar que la varianza de cada residuo viene dada por:
<span class="math display">\[
Var(e_i)=(1-h_{ii})\sigma^2, \ \ i=1,\ldots,n,
\]</span></p>
<p>y la correlación entre los residuos <span class="math inline">\(e_i\)</span> y <span class="math inline">\(e_j\)</span>:</p>
<p><span class="math display">\[
Cor(e_i,e_j)=\frac{-h_{ij}}{\sqrt{(1-h_{ii})(1-h_{jj})}}.
\]</span></p>
</div>
<div id="residuos-estandarizados." class="section level5">
<h5><span class="header-section-number">1.4.2.1.2</span> Residuos estandarizados.</h5>
<p>Son residuos de media cero y varianza aproximadamente unidad, definidos por:</p>
<p><span class="math display">\[
r_i=\frac{e_i}{\sqrt{s^2}}, \qquad i=1,\ldots,n,
\]</span></p>
<p>donde <span class="math inline">\(s^2\)</span> es la estimación habitual de <span class="math inline">\(\sigma^2\)</span> que da el cuadrado medio residual.
Una modificación de estos ´residuos son los denominados residuos estudentizados que se interpretan de forma similar a estos. En los ejemplos introduciremos los procedimientos gráficos que podemos utilizar con este tipo de residuos para el estudio de la linealidad y homocedasticidad.</p>
<p><strong>Dado que la verificación de hipótesis se basa en los residuos del modelo, los procedimientos que utilizamos para verificarlas son los mismos a los descritos para el modelo RLS en la unidad anterior. La única diferencia es la existencia de más de una predictora.</strong></p>
</div>
</div>
<div id="linealidad" class="section level4">
<h4><span class="header-section-number">1.4.2.2</span> Linealidad</h4>
<p>Si hay alguna variable explicativa que no ha sido incluida en el ajuste del modelo, representarla versus los residuos ayuda a identificar algún tipo de tendencia que dicha variable pueda explicar. Si no se detecta ninguna tendencia en el gráfico de dispersión en principio no tenemos ninguna evidencia que nos sugiera incorporar dicha variable al modelo para predecir mejor la respuesta. Estos gráficos son útiles también para detectar outliers y heterocedasticidad.</p>
</div>
<div id="homocedasticidad" class="section level4">
<h4><span class="header-section-number">1.4.2.3</span> Homocedasticidad</h4>
<p>La heterocedasticidad, que es como se denomina el problema de varianza no constante, aparece generalmente cuando el modelo está mal especificado, bien en la relación de la respuesta con los predictores, bien en la distribución de la respuesta, bien en ambas cuestiones. La violación de la hipótesis de varianza constante, <span class="math inline">\(Var(\epsilon)=\sigma^2 I\)</span>, se detecta usualmente a través del análisis gráfico de los residuos:</p>
<ul>
<li><strong>Gráficos de residuos versus valores ajustados</strong> <span class="math inline">\(\hat{y}_i\)</span>.- Cuando aparece alguna tendencia como una forma de embudo o un abombamiento, etc., entonces decimos que podemos tener algún problema con la violación de la hipótesis de varianza constante para los errores.</li>
<li><strong>Gráficos de residuos versus predictores <span class="math inline">\(\textbf{x}_j\)</span>.-</strong> Básicamente se interpretan como los gráficos de residuos versus valores ajustados <span class="math inline">\(\hat{y}_i\)</span>. Es deseable que los residuos aparezcan representados en una banda horizontal sin tendencias alrededor del cero.</li>
</ul>
<p>Hay numerosos tests en la literatura para reconocer heterocedasticidad. Unos están basados en considerar la variabilidad de los residuos que consiguen explicar las variables explicativas sospechosas de inducir heterocedasticidad. Otros tests están basados en diferenciar las observaciones en grupos de varianza constante y comparar los ajustes obtenidos respecto a la hipótesis de tener una misma varianza común:</p>
<ul>
<li>El <strong>test de Breusch-Pagan</strong>.</li>
<li>El <strong>test de Bartlett</strong> o el <strong>test de Levene</strong>.</li>
</ul>
</div>
<div id="normalidad" class="section level4">
<h4><span class="header-section-number">1.4.2.4</span> Normalidad</h4>
<p>La hipótesis de normalidad de los errores <span class="math inline">\(\epsilon_i\)</span> en el modelo lineal justifica la utilización de los tests <span class="math inline">\(F\)</span> y <span class="math inline">\(t\)</span> para realizar los contrastes habituales y obtener conclusiones confiables a cierto nivel de confianza <span class="math inline">\(1-\alpha\)</span> dado. En muestras pequeñas, la no normalidad de los errores es muy difícil de diagnosticar a través del análisis de los residuos, pues éstos pueden diferir notablemente de los errores aleatorios <span class="math inline">\(\epsilon_i\)</span>.</p>
<p>En muestras grandes no se esperan demasiadas diferencias entre residuos y errores, y por lo tanto hacer un diagnóstico de normalidad sobre los residuos equivale prácticamente a hacerlo sobre los errores mismos.</p>
<p>La forma habitual de diagnosticar no normalidad es a través de los <strong>gráficos qq de normalidad</strong> y de tests como el de <strong>Shapiro-Wilks</strong>, específico para normalidad, o el de bondad de ajuste de <strong>Kolmogorov-Smirnov</strong>.</p>
</div>
<div id="incorrelación" class="section level4">
<h4><span class="header-section-number">1.4.2.5</span> Incorrelación</h4>
<p>Para los modelos RLM y MP asumimos que los errores observacionales están incorrelados dos a dos. Si esta hipótesis no es cierta, cabe esperar que un gráfico secuencial de los residuos manifieste alguna tendencia. Sin embargo, hay muchas formas en que los errores pueden estar correlados. De hecho, la independencia entre observaciones es una cuestión justificada básicamente por el muestreo realizado.</p>
<ul>
<li><p>Un gráfico de los residuos en función de la secuencia temporal en que se observaron los datos puede ayudar a apreciar un problema de correlación de los residuos.</p></li>
<li><p>Los gráficos de autocorrelación ayudan a detectar correlación serial, es decir, que un residuo de pende de los residuos anteriores. Dichos gráficos consisten en representar cada residuo (excepto el primero) versus el residuo anterior en la secuencia temporal sospechosa de inducir la correlación.</p></li>
</ul>
<p>Un test habitual para detectar cierto tipo de correlación serial es el <strong>test de Durbin-Watson</strong>.</p>
</div>
<div id="soluciones-a-problemas-detectados-en-el-diagnóstico-del-modelo" class="section level4">
<h4><span class="header-section-number">1.4.2.6</span> Soluciones a problemas detectados en el diagnóstico del modelo</h4>
<p>Las soluciones a los posibles problemas detectados en el diagnóstico son similares a las utilizadas para los modelos RLS:</p>
<ul>
<li>Propuesta de otros modelos adecuados a la distribución de la respuesta y su relación con los predictores (Modelos Lineales Generalizados que trataremos más adelante).</li>
<li>Transformar la variable respuesta (Transformaciones de Box-Cox).</li>
<li>Transformar las predictoras (Modelos de suavizado).</li>
</ul>
<p>Algunas de las soluciones, como las de transformar las predictoras mediante modelos de suavizado, tendrán una unidad especial de tratamiento ya que se tratan de modelos más generalistas que permiten ajustar muchos tipos de tendencias entre respuesta y predictoras.</p>
</div>
<div id="análisis-de-influencia" class="section level4">
<h4><span class="header-section-number">1.4.2.7</span> Análisis de influencia</h4>
<p>En ocasiones hay algún subconjunto de los datos que influencia desproporcionadamente el ajuste del modelo propuesto, con lo cual las estimaciones y predicciones dependen mucho de él. Es interesante siempre, localizar este tipo de datos, si existen, y evaluar su impacto en el modelo. Si estos datos influyentes son “malos” (provienen de errores en la medición, o de condiciones de experimentación diferentes, etc.) habrían de ser excluidos del ajuste; si son “buenos”, esto es, efectivamente proceden de buenas mediciones aunque raras, contendrán información sobre ciertas características relevantes a considerar en el ajuste. En todo caso, es importante localizarlos, y para ello existen una serie de procedimientos basados en diversos estadísticos que presentamos a continuación.</p>
<p>Hay diversos criterios para valorar la influencia de las observaciones en el ajuste, y en base a los cuales se proponen diversos estadísticos. Vamos a considerar tres de ellos: i) contribución a la estimación de los coeficientes; ii) influencia en la predicción y iii) influencia sobre la precisión de las estimaciones.</p>
<div id="sobre-los-coeficientes-del-modelo" class="section level5">
<h5><span class="header-section-number">1.4.2.7.1</span> Sobre los coeficientes del modelo</h5>
<p>Se han construido diversas medidas para valorar la influencia de las observaciones en la estimación de los coeficientes del modelo. Entre ellas, las más habituales son:</p>
<p><strong>Distancia de Cook.</strong> Medida de influencia para una observación <span class="math inline">\(y_i\)</span>, basada en la distancia entre la estimación de mínimos cuadrados obtenida con las <span class="math inline">\(n\)</span> observaciones, <span class="math inline">\(\hat{\textbf{y}}=X \hat{\beta}\)</span>, y la obtenida eliminando dicha observación, <span class="math inline">\(\hat{\textbf{y}}^{(i)}\)</span>. Una formulación habitual del estadístico de Cook es:</p>
<p><span class="math display">\[
D_i=\frac{(\hat{\textbf{y}}-\hat{\textbf{y}}^{(i)})&#39;(\hat{\textbf{y}}-\hat{\textbf{y}}^{(i)})}{p s^2}=\frac{(\hat{\beta}^{(i)}-\hat{\beta})&#39; X&#39;X (\hat{\beta}^{(i)}-\hat{\beta})}{p s^2}, \ \ i=1,\ldots,n,
\]</span></p>
<p>donde <span class="math inline">\(\hat{\beta}^{(i)}\)</span> es el vector de parámetros estimados en la regresión <span class="math inline">\(\hat{\textbf{y}}^{(i)}\)</span>.</p>
<p>Los puntos con un valor grande del estadístico <span class="math inline">\(D_i\)</span> identifican observaciones tales que el hecho de incluirlas o no en el ajuste dan lugar a diferencias considerables en las estimaciones de los coeficientes. Generalmente se consideran como influyentes aquellas observaciones con un valor del estadístico <span class="math inline">\(D_i&gt;1\)</span>, pero se identifican como potencialemnte influyentes todas aquellas con <span class="math inline">\(D_i&gt;4/n\)</span>, con <span class="math inline">\(n\)</span> el tamaño de la muestra.</p>
<p><strong>DFBETAS.</strong> Estadístico que indica cuánto cambia el coeficiente estimado <span class="math inline">\(\hat{\beta}_j\)</span> en desviaciones estándar para un modelo dado cuando se excluye la <span class="math inline">\(i\)</span>-ésima observación:</p>
<p><span class="math display">\[
DFBETAS_{j,i}=\frac{\hat{\beta}_j-\hat{\beta}^{(i)}_j}{s^2_{(i)} C_{jj}^X}, \quad j=0,1,\ldots,p; \ i=1,\ldots,n
\]</span></p>
<p>donde <span class="math inline">\(\hat{\beta}^{(i)}_j\)</span> es la j-ésima componente del vector <span class="math inline">\(\hat{\beta}_{(i)}\)</span>, y <span class="math inline">\(C_{jj}^X\)</span> es el elemento <span class="math inline">\(j\)</span> de la diagonal de <span class="math inline">\((X&#39;X)^{-1}\)</span>.</p>
<p>De forma habitual se considera como potencialmente influyente una observación si <span class="math inline">\(|DFBETAS_{j,i}|&gt;2/\sqrt{n}\)</span>, con <span class="math inline">\(n\)</span> el tamaño muestral.</p>
</div>
<div id="influencia-sobre-las-predicciones" class="section level5">
<h5><span class="header-section-number">1.4.2.7.2</span> Influencia sobre las predicciones</h5>
<p>Para investigar la influencia de la <span class="math inline">\(i\)</span>-ésima observación sobre los valores predichos por el modelo utilizamos el estadístico <strong>DFFITS</strong>. Se define el estadístico DFFITS para la observación i-ésima como:</p>
<p><span class="math display">\[
DFFITS_i = \frac{\hat{y}_i-\hat{y}^{(i)}_i}{\sqrt{s^2_{(i)} h_{ii}}}, \ \ i=1,\ldots,n,
\]</span></p>
<p>donde <span class="math inline">\(\hat{y}^{(i)}_i\)</span> es el valor predicho para <span class="math inline">\(y_i\)</span> por el modelo sin utilizar en la estimación la observación <span class="math inline">\(i\)</span>. Así, <span class="math inline">\(DFFITS_i\)</span> se puede interpretar como el número de desviaciones estándar que cambia la predicción de la <span class="math inline">\(i\)</span>-ésima respuesta cuando dicha observación es excluida del ajuste.</p>
<p>Generalmente, una observación para la que <span class="math inline">\(|DFFITS_i|&gt;2 \sqrt{p/n}\)</span> merece ser tratada con atención.</p>
</div>
<div id="influencia-sobre-la-precisión-de-las-estimaciones" class="section level5">
<h5><span class="header-section-number">1.4.2.7.3</span> Influencia sobre la precisión de las estimaciones</h5>
<p>Los diagnósticos vistos hasta ahora cuantifican de algún modo el efecto de las observaciones en las estimaciones. Sin embargo, no proporcionan información alguna sobre la precisión conjunta del ajuste. La precisión de la estimación de <span class="math inline">\(\hat{\beta}\)</span> se puede medir en función del estadístico <span class="math inline">\(\textsf{COVRATIO}\)</span>. Si <span class="math inline">\(COVRATIO_i&lt;1\)</span>, excluir la <span class="math inline">\(i\)</span>-ésima observación proporciona un ajuste más preciso; si <span class="math inline">\(COVRATIO_i&gt;1\)</span>, la <span class="math inline">\(i\)</span>-ésima observación mejora la precisión de la estimación. En este manual no utilizaremos este criterio y nos centraremos en los puntos anteriores</p>
</div>
</div>
<div id="funciones-para-diagnóstico-e-influencia" class="section level4">
<h4><span class="header-section-number">1.4.2.8</span> Funciones para diagnóstico e influencia</h4>
<p>EN la unidad anterior mostramos como realizar los gráficos y test de diagnóstico para un modelo RLS. Esos gráficos se pueden utilizar también en los modelos tratados en esta unidad, pero además se muestran las funciones de la librería <code>olsrr</code> que pueden ser utilizadas para esta tarea. Concretamente:</p>
<ul>
<li><code>ols_plot_resid_stand()</code>: gráfico secuencial de residuos estandarizados.</li>
<li><code>ols_plot_resid_stud()</code>: gráfico secuencial de residuos estudentizados.</li>
<li><code>ols_plot_resid_stud_fit()</code>: residuos estudentizados vs valores ajustados.</li>
<li><code>ols_plot_resid_qq()</code>: gráfico qq de normalidad.</li>
<li><code>ols_test_normality()</code>: tests de normalidad.</li>
<li><code>ols_test_breusch_pagan()</code>: Test de Bresuch-Pagan.</li>
</ul>
<p>Aunque la función por excelencia para obtener las medidas de influencia es <code>influence.measures()</code>, la librería <code>olsrr</code> presenta diversas funciones para este análisis con la ventaja de proporcionar herramientas gráficas y valores de detección, que permiten visualizar de forma rápida las posibles observaciones influyentes. Dichas funciones son:</p>
<ul>
<li><code>ols_plot_cooksd_chart()</code>: proporciona la distancia de Cook.</li>
<li><code>ols_plot_dfbetas()</code>: proporciona los <span class="math inline">\(DFBETAS\)</span>.</li>
<li><code>ols_plot_dffits()</code>: proporciona <span class="math inline">\(DFFITS\)</span>.</li>
</ul>
</div>
<div id="ejemplos-4" class="section level4">
<h4><span class="header-section-number">1.4.2.9</span> Ejemplos</h4>
<p>Realizamos el diagnóstico y análisis de influencia de los modelos ajustados, tras el proceso de selección de variables.</p>
<div id="datos-de-bosque-4" class="section level5">
<h5><span class="header-section-number">1.4.2.9.1</span> Datos de Bosque</h5>
<p>En primer lugar, ajustamos el modelo correspondiente y obtenemos los valores de diagnóstico.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb77-1" title="1"><span class="co"># Modelos</span></a>
<a class="sourceLine" id="cb77-2" title="2">fit.bosque &lt;-<span class="st"> </span><span class="kw">lm</span>(vol <span class="op">~</span><span class="st"> </span>d16 <span class="op">+</span><span class="st"> </span>ht, <span class="dt">data =</span> bosque)</a>
<a class="sourceLine" id="cb77-3" title="3"><span class="co"># Valores de diagnóstico</span></a>
<a class="sourceLine" id="cb77-4" title="4">diag.bosque &lt;-<span class="st"> </span><span class="kw">fortify</span>(fit.bosque)</a></code></pre></div>
<p>Estudiamos los gráficos de diagnóstico para detectar residuos grandes (gráfico secuencial de residuos), linealidad y homocedasticidad (gráfico de residuos estandarizados versus valores ajustados), y normalidad (gráfico qq).</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1"><span class="kw">ols_plot_resid_stand</span>(fit.bosque)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm032-1.png" width="672" /></p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb79-1" title="1"><span class="kw">ggplot</span>(diag.bosque, <span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .stdresid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb79-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb79-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm032-2.png" width="672" /></p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1"><span class="kw">ols_plot_resid_qq</span>(fit.bosque)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm032-3.png" width="672" /></p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb81-1" title="1"><span class="kw">acf</span>(diag.bosque<span class="op">$</span>.stdresid)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm032-4.png" width="672" /></p>
<p>El gráfico de secuencia de los residuos indica que la observación 18 es potencialemente una observación anómala. Cuando realizamos el análisis de influencia deberemos verificar esta situación para considerar la posible eliminación de esta observación.
El gráfico de residuos versus valores ajustados no muestra ningún tipo de tendencia (linealidad) ni comportamientos extraños que permitan pensar que se incumple la hipótesis de varianza constante.
El gráfico de normalidad también muestra un comportamiento adecuado teniendo en cuenta que el tamaño muestral es muy pequeño.
El gráfico de autocorelación no muestra dependencia entre los residuos, indicando que se cumple la hipótesis de independencia.</p>
<p>Dado que no se ha detectado falta de linealidad entre residuos y valores ajustados no es necesario realizar el gráfico de residuos versus predictoras. Sin embargo, los mostramos aquí para ver el código necesario.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1"><span class="kw">ggplot</span>(diag.bosque, <span class="kw">aes</span>(<span class="dt">x =</span> ht, <span class="dt">y =</span> .stdresid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb82-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb82-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm033-1.png" width="672" /></p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" title="1"><span class="kw">ggplot</span>(diag.bosque, <span class="kw">aes</span>(<span class="dt">x =</span> d16, <span class="dt">y =</span> .stdresid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb83-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>()<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb83-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm033-2.png" width="672" /></p>
<p>Como era de esperar los gráficos no muestran ningún tipo de tendencia.</p>
<p>Realizamos ahora los tests necesarios para verificar las hipótesis de normalidad, homocedasticidad, e independencia.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb84-1" title="1"><span class="kw">ols_test_normality</span>(fit.bosque)</a></code></pre></div>
<pre><code>## -----------------------------------------------
##        Test             Statistic       pvalue  
## -----------------------------------------------
## Shapiro-Wilk              0.9281         0.1420 
## Kolmogorov-Smirnov        0.1544         0.6712 
## Cramer-von Mises          1.6812         0.0000 
## Anderson-Darling          0.5362         0.1485 
## -----------------------------------------------</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb86-1" title="1"><span class="kw">ols_test_breusch_pagan</span>(fit.bosque)</a></code></pre></div>
<pre><code>## 
##  Breusch Pagan Test for Heteroskedasticity
##  -----------------------------------------
##  Ho: the variance is constant            
##  Ha: the variance is not constant        
## 
##              Data               
##  -------------------------------
##  Response : vol 
##  Variables: fitted values of vol 
## 
##         Test Summary         
##  ----------------------------
##  DF            =    1 
##  Chi2          =    0.8615473 
##  Prob &gt; Chi2   =    0.353306</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb88-1" title="1"><span class="kw">durbinWatsonTest</span>(fit.bosque)</a></code></pre></div>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1       0.1645488      1.487166   0.196
##  Alternative hypothesis: rho != 0</code></pre>
<p>Todos los tests resultan no significativos indicando que se cumplen las hipótesis del modelo. Para la hipótesis de normalidad nos debemos fijar en los resultados de Kolmogorov-Smirnov que tiene un mejor comportamiento, desde el punto de vista estadístico, que Shapiro-Wilk. En caso de discrepancias entre ellos nos debemos quedar con Kolmmogorov-Smirnov.</p>
<p>A pesar de que se cumplen las hipótesis del modelo, obtenemos las medidas de influencia asociadas con el modelo ajustado:</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" title="1"><span class="kw">ols_plot_cooksd_chart</span>(fit.bosque)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm035-1.png" width="672" /></p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1"><span class="kw">ols_plot_dfbetas</span>(fit.bosque)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm035-2.png" width="672" /></p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" title="1"><span class="kw">ols_plot_dffits</span>(fit.bosque)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm035-3.png" width="672" /></p>
<p>La distancia de Cook muestra dos observaciones (1 y 20) como potencialmente influyentes utilizando el punto de corte más restrictivo. Si utilizamos el punto de corte estándar que determina como influyente a los que tienen una distancia de Cook mayor que 1, ninguna de ellas sería clasificada como influyente.</p>
<p>EL resto de medidas de influencia siguen mostrando a las observaciones 1 y 20 como potencialmente influyentes, pero dado que se cumplen las hipótesis del modelo no nos planteamos la eliminación de dichas observaciones. Además, con tamaños de muestras tan pequeños sólo nos planteamos su eliminación si es la única solución para que se cumplan las hipótesis del modelo.</p>
</div>
<div id="datos-de-concentración-4" class="section level5">
<h5><span class="header-section-number">1.4.2.9.2</span> Datos de Concentración</h5>
<p>Ajustamos el modelo y obtenemos los valores de diagnóstico.</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" title="1"><span class="co"># Modelos</span></a>
<a class="sourceLine" id="cb93-2" title="2">fit.concen &lt;-<span class="st"> </span><span class="kw">lm</span>(concen <span class="op">~</span><span class="st"> </span>p.cuerpo <span class="op">+</span><span class="st"> </span>dosis, <span class="dt">data =</span> concentracion)</a>
<a class="sourceLine" id="cb93-3" title="3"><span class="co"># Valores de diagnóstico</span></a>
<a class="sourceLine" id="cb93-4" title="4">diag.concen &lt;-<span class="st"> </span><span class="kw">fortify</span>(fit.concen)</a></code></pre></div>
<p>Estudiamos los gráficos de diagnóstico para detectar residuos grandes (gráfico secuencial de residuos), linealidad y homocedasticidad (gráfico de residuos estandarizados versus valores ajustados), y normalidad (gráfico qq).</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" title="1"><span class="kw">ols_plot_resid_stand</span>(fit.concen)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm037-1.png" width="672" /></p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" title="1"><span class="kw">ggplot</span>(diag.concen, <span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .stdresid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb95-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb95-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm037-2.png" width="672" /></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" title="1"><span class="kw">ols_plot_resid_qq</span>(fit.concen)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm037-3.png" width="672" /></p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1"><span class="kw">acf</span>(diag.concen<span class="op">$</span>.stdresid)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm037-4.png" width="672" /></p>
<p>Aunque todos los gráficos parecen mostrar comportamientos adecuados, el gráfico de residuos versus ajustados muestra un punto alejado (valor ajustado alto) del resto lo que podría indicar que debemos tratar ese valor como anómalo y considerar su eliminación del banco de datos. Antes de tomar una decisión revisamos toda la batería de gráficos y tests de diagnóstico e influencia.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb98-1" title="1"><span class="kw">ggplot</span>(diag.concen, <span class="kw">aes</span>(<span class="dt">x =</span> p.cuerpo, <span class="dt">y =</span> .stdresid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb98-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb98-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm038-1.png" width="672" /></p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1"><span class="kw">ggplot</span>(diag.concen, <span class="kw">aes</span>(<span class="dt">x =</span> dosis, <span class="dt">y =</span> .stdresid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb99-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>()<span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb99-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm038-2.png" width="672" /></p>
<p>En los gráficos de residuos versus predictoras no se observan comportamientos anómalos.</p>
<p>Realizamos ahora los tests necesarios para verificar las hipótesis de normalidad, homocedasticidad, e independencia.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb100-1" title="1"><span class="kw">ols_test_normality</span>(fit.concen)</a></code></pre></div>
<pre><code>## -----------------------------------------------
##        Test             Statistic       pvalue  
## -----------------------------------------------
## Shapiro-Wilk              0.9544         0.4672 
## Kolmogorov-Smirnov        0.1414         0.7919 
## Cramer-von Mises          5.4464         0.0000 
## Anderson-Darling          0.3769         0.3742 
## -----------------------------------------------</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" title="1"><span class="kw">ols_test_breusch_pagan</span>(fit.concen)</a></code></pre></div>
<pre><code>## 
##  Breusch Pagan Test for Heteroskedasticity
##  -----------------------------------------
##  Ho: the variance is constant            
##  Ha: the variance is not constant        
## 
##                Data                
##  ----------------------------------
##  Response : concen 
##  Variables: fitted values of concen 
## 
##         Test Summary          
##  -----------------------------
##  DF            =    1 
##  Chi2          =    0.05255342 
##  Prob &gt; Chi2   =    0.8186782</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1"><span class="kw">durbinWatsonTest</span>(fit.concen)</a></code></pre></div>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1      -0.0227244      1.762427   0.586
##  Alternative hypothesis: rho != 0</code></pre>
<p>Todos los tests resultan no significativos indicando que se cumplen las hipótesis del modelo.</p>
<p>En último lugar realizamos el análisis de influencia:</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb106-1" title="1"><span class="kw">ols_plot_cooksd_chart</span>(fit.concen)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm040-1.png" width="672" /></p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" title="1"><span class="kw">ols_plot_dfbetas</span>(fit.concen)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm040-2.png" width="672" /></p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" title="1"><span class="kw">ols_plot_dffits</span>(fit.concen)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm040-3.png" width="672" /></p>
<p>La distancia de Cook muestra que la observación en la posición 3 es claramente influyente. De hecho, también es influyente en los coeficientes del modelo, y en el valor ajustado. Pasamos a eliminar dicha observación y a ajustar un nuevo modelo. Comenzaremos con el modelo saturado e iremos completando todo el análisis.</p>
<p>Creamos el nuevo banco de datos y ajustamos el nuevo modelo:</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb109-1" title="1"><span class="co"># Datos sin observación 3</span></a>
<a class="sourceLine" id="cb109-2" title="2">concentracion &lt;-<span class="st"> </span>concentracion[<span class="op">-</span><span class="dv">3</span>,]</a>
<a class="sourceLine" id="cb109-3" title="3"><span class="co"># Ajuste del modelo</span></a>
<a class="sourceLine" id="cb109-4" title="4">fit.concen &lt;-<span class="st"> </span><span class="kw">lm</span>(concen <span class="op">~</span><span class="st"> </span>p.cuerpo <span class="op">+</span><span class="st"> </span>dosis, <span class="dt">data =</span> concentracion)</a>
<a class="sourceLine" id="cb109-5" title="5"><span class="co"># Modelo ajustado</span></a>
<a class="sourceLine" id="cb109-6" title="6"><span class="kw">tab_model</span>(fit.concen)</a></code></pre></div>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
concen
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.33
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.08 – 0.75
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.110
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
p.cuerpo
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.04 – 0.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.797
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
dosis
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.88
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-6.37 – 8.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.800
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
18
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.005 / -0.128
</td>
</tr>
</table>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" title="1"><span class="co"># Bondad del ajuste</span></a>
<a class="sourceLine" id="cb110-2" title="2"><span class="kw">glance</span>(fit.concen)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   0.00483        -0.128 0.0762    0.0364   0.964     3   22.4 -36.9 -33.3
## # … with 2 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;</code></pre>
<p>EL test <span class="math inline">\(F\)</span> de la regresión nos indica que la variables predictoras no están relacionadas con la respuesta (p-valor &gt; 0.05), con lo que no tendría sentido seguir trabajando con este modelo y la conclusión obtenida es que no hemos podido obtener una relación entre concentración y peso cuerpo, peso del hígado, y dosis.</p>
<p>El efecto de eliminar una observación (a pesar de que se cumplen las hipótesis del modelo), es que la débil relación que habíamos establecido entre concentración frente a peso del cuerpo y dosis resulta inexistente. En este caso debe ser el investigador el que decida entre las dos opciones:</p>
<ul>
<li>Quedarse con un modelo malo (sin quitar la observación influyente) que verifica las hipótesis.</li>
<li>Concluir que no existe relación entre respuesta y predictoras, desechando el experimento realizado.</li>
</ul>
</div>
<div id="datos-de-papel-4" class="section level5">
<h5><span class="header-section-number">1.4.2.9.3</span> Datos de Papel</h5>
<p>Ajustamos el modelo y obtenemos los valores de diagnóstico.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" title="1"><span class="co"># Modelos</span></a>
<a class="sourceLine" id="cb112-2" title="2">fit.papel &lt;-<span class="st"> </span><span class="kw">lm</span>(tension <span class="op">~</span><span class="st"> </span>madera <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(madera<span class="op">^</span><span class="dv">2</span>), <span class="dt">data =</span> papel)</a>
<a class="sourceLine" id="cb112-3" title="3"><span class="co"># Valores de diagnóstico</span></a>
<a class="sourceLine" id="cb112-4" title="4">diag.papel &lt;-<span class="st"> </span><span class="kw">fortify</span>(fit.papel)</a></code></pre></div>
<p>Estudiamos los gráficos de diagnóstico para detectar residuos grandes (gráfico secuencial de residuos), linealidad y homocedasticidad (gráfico de residuos estandarizados versus valores ajustados), y normalidad (gráfico qq).</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" title="1"><span class="kw">ols_plot_resid_stand</span>(fit.papel)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm043-1.png" width="672" /></p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb114-1" title="1"><span class="kw">ggplot</span>(diag.papel, <span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .stdresid)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb114-2" title="2"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb114-3" title="3"><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm043-2.png" width="672" /></p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" title="1"><span class="kw">ols_plot_resid_qq</span>(fit.papel)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm043-3.png" width="672" /></p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb116-1" title="1"><span class="kw">acf</span>(diag.papel<span class="op">$</span>.stdresid)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm043-4.png" width="672" /></p>
<p>No se observan residuos excesivamente grandes, ni comportamientos anómalos pero si cierta autocorrelación en los residuos debido a la propia estructura del modelo polinómico considerado. Realizamos los tests de diagnóstico:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" title="1"><span class="kw">ols_test_normality</span>(fit.papel)</a></code></pre></div>
<pre><code>## -----------------------------------------------
##        Test             Statistic       pvalue  
## -----------------------------------------------
## Shapiro-Wilk              0.9113         0.0783 
## Kolmogorov-Smirnov        0.198          0.3942 
## Cramer-von Mises          1.5965          1e-04 
## Anderson-Darling          0.6399         0.0806 
## -----------------------------------------------</code></pre>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb119-1" title="1"><span class="kw">ols_test_breusch_pagan</span>(fit.papel)</a></code></pre></div>
<pre><code>## 
##  Breusch Pagan Test for Heteroskedasticity
##  -----------------------------------------
##  Ho: the variance is constant            
##  Ha: the variance is not constant        
## 
##                Data                 
##  -----------------------------------
##  Response : tension 
##  Variables: fitted values of tension 
## 
##         Test Summary         
##  ----------------------------
##  DF            =    1 
##  Chi2          =    0.2755593 
##  Prob &gt; Chi2   =    0.5996267</code></pre>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb121-1" title="1"><span class="kw">durbinWatsonTest</span>(fit.papel)</a></code></pre></div>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1       0.6040252     0.6974667       0
##  Alternative hypothesis: rho != 0</code></pre>
<p>Se verifican las hipótesis de homocedasticidad y normalidad, y como era de espera no se cumple la hipótesis de incorrrelación. Dado que este incumplimiento se debe a la propia estructura del modelo no tendremos en cuenta este resultado par concluir sobre este modelo.</p>
<p>En último lugar realizamos el análisis de influencia:</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb123-1" title="1"><span class="kw">ols_plot_cooksd_chart</span>(fit.papel)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm045-1.png" width="672" /></p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1"><span class="kw">ols_plot_dfbetas</span>(fit.papel)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm045-2.png" width="672" /></p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb125-1" title="1"><span class="kw">ols_plot_dffits</span>(fit.papel)</a></code></pre></div>
<p><img src="libroSTAT_files/figure-html/rlm045-3.png" width="672" /></p>
<p>Tenemos dos observaciones (18 y 19) que se detectan como potencialmente influyentes (distancia de Cook) y que podrían ser consideradas para su eliminación. Como el modelo tiene un buen ajuste y cumple con las hipótesis consideramos el modelo como válido.</p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="comparación-y-selección-de-modelos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="predicción.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["libroSTAT.pdf", "libroSTAT.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
