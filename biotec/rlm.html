<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Unidad 7 Regresión Lineal Múltiple y Polinómica | Modelos Estadísticos</title>
<meta name="description" content="Como extensión a los modelos de regresión lineal simple presentados en la Unidad 6 estudiamos los modelos de regresión lineal múltiple (RLM) y los modelos polinómicos (MP). La diferencia principal...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Unidad 7 Regresión Lineal Múltiple y Polinómica | Modelos Estadísticos">
<meta property="og:type" content="book">
<meta property="og:description" content="Como extensión a los modelos de regresión lineal simple presentados en la Unidad 6 estudiamos los modelos de regresión lineal múltiple (RLM) y los modelos polinómicos (MP). La diferencia principal...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Unidad 7 Regresión Lineal Múltiple y Polinómica | Modelos Estadísticos">
<meta name="twitter:description" content="Como extensión a los modelos de regresión lineal simple presentados en la Unidad 6 estudiamos los modelos de regresión lineal múltiple (RLM) y los modelos polinómicos (MP). La diferencia principal...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Modelos Estadísticos</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Bienvenidos</a></li>
<li><a class="" href="introlibro.html"><span class="header-section-number">1</span> Comenzamos</a></li>
<li><a class="" href="aed.html"><span class="header-section-number">2</span> Análisis exploratorio de datos</a></li>
<li><a class="" href="prob.html"><span class="header-section-number">3</span> Probabilidad</a></li>
<li><a class="" href="inferencia-b%C3%A1sica.html"><span class="header-section-number">4</span> Inferencia básica</a></li>
<li><a class="" href="modelstats.html"><span class="header-section-number">5</span> Modelos estadísticos</a></li>
<li><a class="" href="rls.html"><span class="header-section-number">6</span> Regresión Lineal Simple (RLS)</a></li>
<li><a class="active" href="rlm.html"><span class="header-section-number">7</span> Regresión Lineal Múltiple y Polinómica</a></li>
<li><a class="" href="anova.html"><span class="header-section-number">8</span> Modelos ANOVA</a></li>
<li><a class="" href="ancova.html"><span class="header-section-number">9</span> Modelos ANCOVA</a></li>
<li><a class="" href="smooth.html"><span class="header-section-number">10</span> Modelos aditivos lineales</a></li>
<li><a class="" href="mmixed.html"><span class="header-section-number">11</span> Modelos Lineales Mixtos</a></li>
<li><a class="" href="glm.html"><span class="header-section-number">12</span> Modelos Lineales Generalizados</a></li>
<li><a class="" href="glmbinomial.html"><span class="header-section-number">13</span> GLM respuesta binomial</a></li>
<li><a class="" href="glmpoisson.html"><span class="header-section-number">14</span> GLM Poisson</a></li>
<li><a class="" href="glmtablascont.html"><span class="header-section-number">15</span> GLM para tablas de contingencia</a></li>
<li><a class="" href="glmsuperv.html"><span class="header-section-number">16</span> GLM para datos de supervivencia</a></li>
<li><a class="" href="referencias.html">Referencias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="rlm" class="section level1" number="7">
<h1>
<span class="header-section-number">Unidad 7</span> Regresión Lineal Múltiple y Polinómica<a class="anchor" aria-label="anchor" href="#rlm"><i class="fas fa-link"></i></a>
</h1>
<p>Como extensión a los modelos de regresión lineal simple presentados en la Unidad <a href="rls.html#rls">6</a> estudiamos los <strong>modelos de regresión lineal múltiple (RLM)</strong> y los <strong>modelos polinómicos (MP)</strong>. La diferencia principal entre estos modelos y el de RLS es que estos involucran al menos dos variables predictoras de tipo numérico para tratar de explicar el comportamiento de la respuesta. Aunque la base de construcción del modelo es similar a lo tratado en la unidad anterior veremos y estudiaremos con detalle las particularidades de estos modelos. De hecho, veremos que todos los modelos se pueden expresar matemáticamente de una forma única lo que facilita su estudio, y nos permite considerar tanto modelos simples (con pocas predictoras) como los más complejos (con muchas predictoras).</p>
<p>Antes de pasar a la presentación de estos modelos vamos a ver los ejemplos que iremos trabajando a lo largo de esta unidad. Al igual que en el modelo RLS el primer paso es la representación de los datos recogidos y realizar un pequeño estudio descriptivo sobre la posible asociación entre la respuesta y cada una de las predictoras consideradas, dado que resulta imposible realizar gráficos multivariantes de la respuesta vs todas las predictoras.</p>
<p>Veamos los diferentes ejemplos con los que vamos a trabajar a lo largo de esta unidad.</p>
<p><strong>Ejemplo 1. Datos de Bosque.</strong> Para estimar la producción en madera de un bosque se suele realizar un muestreo previo en el que se realizan una serie de medidas no destructivas. Disponemos de mediciones para 20 árboles, así como el volumen (VOL) de madera que producen una vez cortados. Las variables consideradas son: HT o altura en pies, DBH el diámetro del tronco a 4 píes de altura (en pulgadas), D16 el diámetro del tronco a 16 pies de altura (en pulgadas), y VOL el volumen de madera conseguida (en pies cúbicos). El objetivo del análisis es determinar cuál es la relación entre dichas medidas y el volumen de madera, con el fin de poder predecir este último en función de las primeras.</p>
<div class="sourceCode" id="cb244"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dbh</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10.2</span>, <span class="fl">13.72</span>, <span class="fl">15.43</span>, <span class="fl">14.37</span>, <span class="fl">15</span>, <span class="fl">15.02</span>, <span class="fl">15.12</span>, <span class="fl">15.24</span>, <span class="fl">15.24</span>, <span class="fl">15.28</span>, <span class="fl">13.78</span>, 
     <span class="fl">15.67</span>, <span class="fl">15.67</span>, <span class="fl">15.98</span>, <span class="fl">16.5</span>, <span class="fl">16.87</span>, <span class="fl">17.26</span>, <span class="fl">17.28</span>, <span class="fl">17.87</span>, <span class="fl">19.13</span><span class="op">)</span>
<span class="va">d16</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">9.3</span>, <span class="fl">12.1</span>, <span class="fl">13.3</span>, <span class="fl">13.4</span>, <span class="fl">14.2</span>, <span class="fl">12.8</span>, <span class="fl">14</span>, <span class="fl">13.5</span>, <span class="fl">14</span>, <span class="fl">13.8</span>, <span class="fl">13.6</span>, <span class="fl">14</span>, 
     <span class="fl">13.7</span>, <span class="fl">13.9</span>, <span class="fl">14.9</span>, <span class="fl">14.9</span>, <span class="fl">14.3</span>, <span class="fl">14.3</span>, <span class="fl">16.9</span>, <span class="fl">17.3</span><span class="op">)</span>
<span class="va">ht</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">89</span>, <span class="fl">90.07</span>, <span class="fl">95.08</span>, <span class="fl">98.03</span>, <span class="fl">99</span>, <span class="fl">91.05</span>, <span class="fl">105.6</span>, <span class="fl">100.8</span>, <span class="fl">94</span>, <span class="fl">93.09</span>, <span class="fl">89</span>, <span class="fl">102</span>, 
    <span class="fl">99</span>, <span class="fl">89.02</span>, <span class="fl">95.09</span>, <span class="fl">95.02</span>, <span class="fl">91.02</span>, <span class="fl">98.06</span>, <span class="fl">96.01</span>, <span class="fl">101</span><span class="op">)</span>
<span class="va">vol</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25.93</span>, <span class="fl">45.87</span>, <span class="fl">56.2</span>, <span class="fl">58.6</span>, <span class="fl">63.36</span>, <span class="fl">46.35</span>, <span class="fl">68.99</span>, <span class="fl">62.91</span>, <span class="fl">58.13</span>, <span class="fl">59.79</span>, 
     <span class="fl">56.2</span>, <span class="fl">66.16</span>, <span class="fl">62.18</span>, <span class="fl">57.01</span>, <span class="fl">65.62</span>, <span class="fl">65.03</span>, <span class="fl">66.74</span>, <span class="fl">73.38</span>, <span class="fl">82.87</span>, <span class="fl">95.71</span><span class="op">)</span>
<span class="va">bosque</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">vol</span>, <span class="va">dbh</span>, <span class="va">d16</span>, <span class="va">ht</span><span class="op">)</span>
<span class="co"># Gráficos parciales</span>
<span class="va">datacomp</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/reshape2/man/melt.html">melt</a></span><span class="op">(</span><span class="va">bosque</span>, id.vars <span class="op">=</span> <span class="st">'vol'</span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">datacomp</span><span class="op">)</span> <span class="op">+</span>
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_jitter.html">geom_jitter</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">value</span>, <span class="va">vol</span>, colour <span class="op">=</span> <span class="va">variable</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">variable</span>, scales <span class="op">=</span> <span class="st">"free_x"</span><span class="op">)</span> <span class="op">+</span>
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">""</span>, y <span class="op">=</span> <span class="st">"Volumen"</span><span class="op">)</span> </code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:rlm001"></span>
<img src="18-lmRLM_files/figure-html/rlm001-1.png" alt="Gráfico de dispersión de Volumen respecto de cada predictora." width="95%"><p class="caption">
Figura 7.1: Gráfico de dispersión de Volumen respecto de cada predictora.
</p>
</div>
<p>A simple vista todas las predictoras tienen un efecto positivo en el volumen de madera obtenido, lo cual es bastante obvio, ya que cuanto más grande sea el árbol se espera que su volumen sea más grande. Sin embargo, parece que el efecto de los diámetros es superior al de la altura del árbol (pendientes más pronunciadas) aunque resulta difícil distinguir que diámetro puede ser más relevante ya que ambos se comportan de forma similar. Podemos confirmar este hecho realizando un análisis de correlación para este banco de datos.</p>
<p><strong>Ejemplo 2. Datos de Concentración.</strong> Se ha llevado a cabo un experimento para estudiar la concentración presente de un fármaco en el hígado después de sufrir un tratamiento. Se piensa que las variables que pueden influir en la concentración son el peso del cuerpo, el peso del hígado y la dosis de fármaco administrada.</p>
<div class="sourceCode" id="cb245"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p.cuerpo</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">176</span>, <span class="fl">176</span>, <span class="fl">190</span>, <span class="fl">176</span>, <span class="fl">200</span>, <span class="fl">167</span>, <span class="fl">188</span>, <span class="fl">195</span>, <span class="fl">176</span>, <span class="fl">165</span>, <span class="fl">158</span>, <span class="fl">148</span>, <span class="fl">149</span>, <span class="fl">163</span>, 
              <span class="fl">170</span>, <span class="fl">186</span>, <span class="fl">146</span>, <span class="fl">181</span>, <span class="fl">149</span><span class="op">)</span>
<span class="va">p.higado</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6.5</span>, <span class="fl">9.5</span>, <span class="fl">9.0</span>, <span class="fl">8.9</span>, <span class="fl">7.2</span>, <span class="fl">8.9</span>, <span class="fl">8.0</span>, <span class="fl">10.0</span>, <span class="fl">8.0</span>, <span class="fl">7.9</span>, <span class="fl">6.9</span>, <span class="fl">7.3</span>, <span class="fl">5.2</span>, <span class="fl">8.4</span>, 
              <span class="fl">7.2</span>, <span class="fl">6.8</span>, <span class="fl">7.3</span>, <span class="fl">9.0</span>, <span class="fl">6.4</span><span class="op">)</span> 
<span class="va">dosis</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.88</span>, <span class="fl">.88</span>, <span class="fl">1.0</span>, <span class="fl">.88</span>, <span class="fl">1.0</span>, <span class="fl">.83</span>, <span class="fl">.94</span>, <span class="fl">.98</span>, <span class="fl">.88</span>, <span class="fl">.84</span>, <span class="fl">.80</span>, <span class="fl">.74</span>, <span class="fl">.75</span>, <span class="fl">.81</span>, <span class="fl">.85</span>, 
           <span class="fl">.94</span>, <span class="fl">.73</span>, <span class="fl">.90</span>, <span class="fl">.75</span><span class="op">)</span>
<span class="va">concen</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.42</span>, <span class="fl">.25</span>, <span class="fl">.56</span>, <span class="fl">.23</span>, <span class="fl">.23</span>, <span class="fl">.32</span>, <span class="fl">.37</span>, <span class="fl">.41</span>, <span class="fl">.33</span>, <span class="fl">.38</span>, <span class="fl">.27</span>, <span class="fl">.36</span>, <span class="fl">.21</span>, <span class="fl">.28</span>, <span class="fl">.34</span>, 
            <span class="fl">.28</span>, <span class="fl">.30</span>, <span class="fl">.37</span>, <span class="fl">.46</span><span class="op">)</span>
<span class="va">concentracion</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">p.cuerpo</span>, <span class="va">p.higado</span>, <span class="va">dosis</span>, <span class="va">concen</span><span class="op">)</span>
<span class="co"># Gráficos parciales</span>
<span class="va">datacomp</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/reshape2/man/melt.html">melt</a></span><span class="op">(</span><span class="va">concentracion</span>, id.vars <span class="op">=</span> <span class="st">'concen'</span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">datacomp</span><span class="op">)</span> <span class="op">+</span>
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_jitter.html">geom_jitter</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">value</span>, <span class="va">concen</span>, colour <span class="op">=</span> <span class="va">variable</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/facet_wrap.html">facet_wrap</a></span><span class="op">(</span><span class="op">~</span><span class="va">variable</span>, scales <span class="op">=</span> <span class="st">"free_x"</span><span class="op">)</span> <span class="op">+</span>
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">""</span>, y <span class="op">=</span> <span class="st">"Concentración del fármaco"</span><span class="op">)</span> </code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:rlm002"></span>
<img src="18-lmRLM_files/figure-html/rlm002-1.png" alt="Gráfico de dispersión de la concentración del fármaco respecto de cada predictora." width="95%"><p class="caption">
Figura 7.2: Gráfico de dispersión de la concentración del fármaco respecto de cada predictora.
</p>
</div>
<p>En este caso ninguno de los gráficos parciales muestra una gran asociación entre la concentración del fármaco y cada una de las predictoras. En todos ellos se aprecia una observación un poco más alejada del resto (concentración &gt; 0.6) que podría ser influyente en la obtención del modelo correspondiente.</p>
<p><strong>Ejemplo 3. Datos de Papel. </strong> Banco de datos de Papel de la unidad anterior, donde ya pudimos ver que la tendencia observada se comportaba más como una parábola (polinomio de grado 2) que como una recta.</p>
<div class="sourceCode" id="cb246"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">madera</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1.5</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span>, <span class="fl">4.5</span>, <span class="fl">5</span>, <span class="fl">5.5</span>, <span class="fl">6</span>, <span class="fl">6.5</span>, <span class="fl">7</span>, <span class="fl">8</span>, <span class="fl">9</span>, <span class="fl">10</span>, <span class="fl">11</span>, <span class="fl">12</span>, <span class="fl">13</span>, <span class="fl">14</span>, <span class="fl">15</span><span class="op">)</span>
<span class="va">tension</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">6.3</span>, <span class="fl">11.1</span>, <span class="fl">20.0</span>, <span class="fl">24</span>, <span class="fl">26.1</span>, <span class="fl">30</span>, <span class="fl">33.8</span>, <span class="fl">34</span>, <span class="fl">38.1</span>, <span class="fl">39.9</span>, <span class="fl">42</span>, <span class="fl">46.1</span>, <span class="fl">53.1</span>, 
             <span class="fl">52</span>, <span class="fl">52.5</span>, <span class="fl">48</span>, <span class="fl">42.8</span>, <span class="fl">27.8</span>, <span class="fl">21.9</span><span class="op">)</span>
<span class="va">papel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">madera</span>, <span class="va">tension</span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">papel</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">madera</span>, y <span class="op">=</span> <span class="va">tension</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Concentración de madera"</span>, y <span class="op">=</span> <span class="st">"Resistencia del papel"</span><span class="op">)</span> </code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:rlm003"></span>
<img src="18-lmRLM_files/figure-html/rlm003-1.png" alt="Gráfico de dispersión de resistencia del papel vs concentración de madera." width="95%"><p class="caption">
Figura 7.3: Gráfico de dispersión de resistencia del papel vs concentración de madera.
</p>
</div>
<div id="tipos-de-modelos-1" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Tipos de modelos<a class="anchor" aria-label="anchor" href="#tipos-de-modelos-1"><i class="fas fa-link"></i></a>
</h2>
<p>Vemos las diferencias de expresión de cada uno de los modelos que trabajaremos en esta unidad.</p>
<div id="modelos-de-rlm" class="section level3" number="7.1.1">
<h3>
<span class="header-section-number">7.1.1</span> Modelos de RLM<a class="anchor" aria-label="anchor" href="#modelos-de-rlm"><i class="fas fa-link"></i></a>
</h3>
<p>Los modelos de regresión lineal múltiple surgen cuando tratamos de explicar el comportamiento de una variable predictora de tipo continuo a través de un conjunto de variables predictoras de tipo continuo mediante una función lineal. De hecho, se trata de describir dicha relación a través de una superficie, lineal en las variables explicativas, lo más próxima posible a los valores observados de la respuesta. Si <span class="math inline">\(X_1, X_2, ..., X_p\)</span> son las variables predictoras el modelo viene dado por:</p>
<p><span class="math display" id="eq:ecuacionRLM">\[\begin{equation}
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p + \epsilon 
\tag{7.1}
\end{equation}\]</span></p>
<p>Las hipótesis de este modelo es que los errores se distribuyen de forma independiente mediante una distribución Normal de media cero y varianza constante <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Los parámetros desconocidos de este modelo son <span class="math inline">\((\beta_0, \beta_1, ... , \beta_p, \sigma^2)\)</span> donde:</p>
<ul>
<li>
<span class="math inline">\(\beta_0\)</span> se conoce como interceptación y representa el valor de la respuesta cuando la variable predictora toma el valor cero, interpretándose como un efecto común en la relación entre la predictora y la respuesta.</li>
<li>Los <span class="math inline">\(\beta_i\)</span> son las pendientes de la recta asociadas con cada predictora y representa el aumento o disminución del valor de la respuesta cuando aumentamos en una unidad el valor de la predictora. En este tipo de modelos dicho parámetro se conoce también como el efecto de la predictora sobre la respuesta.</li>
<li>
<span class="math inline">\(\sigma^2\)</span> es la varianza residual del modelo.</li>
</ul>
<p>Dada un muestra de <span class="math inline">\(n\)</span> sujetos de la variable respuesta <span class="math inline">\((y_1, ..., y_n)\)</span> y de las variables predictoras <span class="math inline">\((x_{11}, ..., x_{n1}), (x_{12}, ..., x_{n2}), ..., (x_{1p}, ..., x_{np})\)</span>, el modelo de regresión lineal múltiple se puede escribir como:</p>
<p><span class="math display">\[Y = \left(\begin{array}{c}
  y_1 \\
  y_2 \\
  ...\\
  y_n\\
 \end{array} \right) = 
 \left(\begin{array}{cccc}
  1 &amp; x_{11} &amp; ... &amp; x_{1p}\\
  1 &amp; x_{21} &amp; ...&amp; x_{2p}\\
  ...&amp; ...  &amp; ...&amp; ...\\
  1 &amp;  x_{n1}&amp; ...&amp; x_{np}\\
 \end{array} \right)
 \left(\begin{array}{c}
  \beta_0 \\
  \beta_1 \\
  ....\\
  \beta_p\\
 \end{array} \right) + 
 \left(\begin{array}{c}
  e_1 \\
  e_2 \\
  ...\\
  e_n
 \end{array} \right) = X \beta + \epsilon\]</span></p>
<p>donde <span class="math inline">\(X\)</span> se denomina matriz del diseño, representando el efecto común (columna de 1’s) y el efecto de las predictoras (cada columna con los valores de la variable), y los <span class="math inline">\(e_i\)</span> representan los errores aleatorias para cada uno de los sujetos de la muestra.</p>
<p>Los bancos de datos de bosque y concentración quedarían englobados dentro de este conjunto de modelos con la siguiente propuesta:</p>
<ul>
<li>Datos de bosque</li>
</ul>
<p><span class="math display">\[
\text{vol} = \beta_{0} + \beta_{1}\text{dbh} + \beta_{2}\text{d16} + \beta_{3}\text{ht} + \epsilon
\]</span></p>
<ul>
<li>Datos de concentración</li>
</ul>
<p><span class="math display">\[
\text{concen} = \beta_{0} + \beta_{1}\text{p.cuerpo} + \beta_{2}\text{p.higado} + \beta_{3}\text{dosis} + \epsilon
\]</span></p>
</div>
<div id="modelos-de-rp" class="section level3" number="7.1.2">
<h3>
<span class="header-section-number">7.1.2</span> Modelos de RP<a class="anchor" aria-label="anchor" href="#modelos-de-rp"><i class="fas fa-link"></i></a>
</h3>
<p>Los modelos de regresión lineal múltiple surgen cuando tratamos de explicar el comportamiento de una variable predictora de tipo continuo a través de una variable predictora de tipo continuo mediante una función polinómica lineal. En general, los modelos polinómicos son útiles cuando se aprecia una tendencia curvilínea entre los predictores y la respuesta. Asimismo, a veces constituyen una aproximación sencilla (por serie de Taylor) a modelos complejos e incluso no-lineales. Si <span class="math inline">\(X\)</span> es la variable predictora y queremos un polinomio de grado <span class="math inline">\(k\)</span> el modelo viene dado por:</p>
<p><span class="math display" id="eq:ecuacionMP">\[\begin{equation}
Y = \beta_0 + \beta_1 X + \beta_2 X^2 + ... + \beta_k X^k + \epsilon
\tag{7.2}
\end{equation}\]</span></p>
<p>Las hipótesis de este modelo es que los errores se distribuyen de forma independiente mediante una distribución Normal de media cero y varianza constante <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Los parámetros desconocidos de este modelo son <span class="math inline">\((\beta_0, \beta_1, ... , \beta_k, \sigma^2)\)</span> donde:</p>
<ul>
<li>
<span class="math inline">\(\beta_0\)</span> se conoce como interceptación y representa el valor de la respuesta cuando la variable predictora toma el valor cero, interpretándose como un efecto común en la relación entre la predictora y la respuesta.</li>
<li>Los <span class="math inline">\(\beta_i\)</span> son las pendientes de la recta asociadas con cada predictora y representa el aumento o disminución del valor de la respuesta cuando aumentamos en una unidad el valor de la predictora. En este tipo de modelos dicho parámetro se conoce también como el efecto de la potencia de la predictora sobre la respuesta.</li>
<li>
<span class="math inline">\(\sigma^2\)</span> es la varianza residual del modelo.</li>
</ul>
<p>Dada un muestra de <span class="math inline">\(n\)</span> sujetos de la variable respuesta <span class="math inline">\((y_1, ..., y_n)\)</span> y de la variable predictora <span class="math inline">\((x_{11}, ..., x_{n1})\)</span>, el modelo de regresión polinómico se puede escribir como:</p>
<p><span class="math display">\[Y = \left(\begin{array}{c}
  y_1 \\
  y_2 \\
  ...\\
  y_n\\
 \end{array} \right) = 
 \left(\begin{array}{cccc}
  1 &amp; x_{11} &amp; ... &amp; x^k_{11}\\
  1 &amp; x_{21} &amp; ...&amp; x^k_{21}\\
  ...&amp; ...  &amp; ...&amp; ...\\
  1 &amp;  x_{n1}&amp; ...&amp; x^k_{n1}\\
 \end{array} \right)
 \left(\begin{array}{c}
  \beta_0 \\
  \beta_1 \\
  ....\\
  \beta_k\\
 \end{array} \right) + 
 \left(\begin{array}{c}
  e_1 \\
  e_2 \\
  ...\\
  e_n
 \end{array} \right) = X \beta + \epsilon\]</span></p>
<p>donde <span class="math inline">\(X\)</span> se denomina matriz del diseño, representando el efecto común (columna de 1’s) y el efecto del grado del polinomio (cada columna con los valores de la variable), y los <span class="math inline">\(e_i\)</span> representan los errores aleatorias para cada uno de los sujetos de la muestra.</p>
<p>El banco de datos de papel quedaría englobado dentro de este conjunto de modelos con la siguiente propuesta:</p>
<p><span class="math display">\[
\text{tension} = \beta_{0} + \beta_{1}\text{madera} + \beta_{2}\text{madera}^2 + \epsilon
\]</span></p>
<p>Ambos tipos de modelos se pueden describir mediante una única formulación:
<span class="math display" id="eq:ecuacionML">\[\begin{equation}
Y = X \beta + \epsilon
\tag{7.3}
\end{equation}\]</span></p>
</div>
<div id="expresión-en-r-de-los-modelos" class="section level3" number="7.1.3">
<h3>
<span class="header-section-number">7.1.3</span> Expresión en R de los modelos<a class="anchor" aria-label="anchor" href="#expresi%C3%B3n-en-r-de-los-modelos"><i class="fas fa-link"></i></a>
</h3>
<p>Antes de ver como afecta a la estimación del modelo la presencia de más de una predictora o posible efecto sobre la respuesta, vamos a ver como podemos expresar los modelos RLM y MP en <code>R</code>.</p>
<p>El modelo RLM dado en <a href="rlm.html#eq:ecuacionRLM">(7.1)</a> se expresa como:
<span class="math display">\[Y \sim X_1 + X_2 + ... + X_p\]</span></p>
<p>El modelo RLM para una predictora <span class="math inline">\(X\)</span> dado en <a href="rlm.html#eq:ecuacionMP">(7.2)</a> se expresa como:
<span class="math display">\[Y \sim X + I(X^2) + ... + I(X^k)\]</span></p>
<p>Estas expresiones son una generalización directa del modelo RLS presentado en la unidad anterior.</p>
</div>
<div id="modelo-saturado-y-anidado" class="section level3" number="7.1.4">
<h3>
<span class="header-section-number">7.1.4</span> Modelo saturado y anidado<a class="anchor" aria-label="anchor" href="#modelo-saturado-y-anidado"><i class="fas fa-link"></i></a>
</h3>
<p>En modelos donde hay más de un efecto sobre la predictora, es decir, tenemos diferentes predictoras o un modelo polinómico, debemos introducir dos conceptos que resultan muy relevantes, y que utilizaremos de forma muy habitual en la selección del mejor modelo.</p>
<p>El <strong>modelo saturado</strong> es aquel que contiene todos los efectos asociados con las diferentes predictoras consideradas. Para los tres ejemplos considerados tendríamos:</p>
<p><span class="math display">\[\left\{
 \begin{array}{lc}
  \text{Ejemplo 1}    &amp; vol \sim dbh + d16 + ht\\
  \text{Ejemplo 2}    &amp; concen \sim p.cuerpo + p.higado + dosis\\
  \text{Ejemplo 3}    &amp; resistencia \sim madera + madera^2\\
 \end{array}
 \right. \]</span></p>
<p>Los <strong>modelos anidados</strong> son todos los modelos que podemos considerar y que no contienen todos los efectos asociados con las predictoras. Si tenemos un modelo con dos predictoras <span class="math inline">\(X_1\)</span>, y <span class="math inline">\(X_2\)</span> lo modelos anidados del modelo saturado <span class="math display">\[Y \sim X_1 +X_2\]</span> son:</p>
<p><span class="math display">\[\left\{
 \begin{array}{lc}
  \text{con } X_1     &amp; Y \sim X_1\\
  \text{con } X_2     &amp; Y \sim X_2\\
  \text{Sin ninguna}    &amp; Y \sim 1\\
 \end{array}
 \right. \]</span></p>
<p>Todos ellos están “anidados” dentro del modelo saturado y reflejan diferente información. El primero refleja que la respuesta sólo está relacionada con <span class="math inline">\(X_1\)</span>, el segundo que la respuesta está relacionada con <span class="math inline">\(X_2\)</span>, y el último refleja que no hay ninguna predictora relacionada con la respuesta.</p>
<p>Debemos tener en cuenta que al incluir más de una predictora debemos decidir si todas ellas son relevantes para explicar el comportamiento de la respuesta, o bien si podemos prescindir de algunas de ellas.</p>
<p>La consideración de los diferentes modelos anidados varía en función del modelo con el que trabajemos. En el caso de los de RLM el orden de los modelos anidados no es relevante, pero sin embargo si lo es los modelos polinómicos. No tiene sentido considerar un modelo en el que sólo se incluya el efecto del polinomio de grado 2 pero que no se incluya el de grado 1. Por su propia construcción cuando consideramos un modelo polinómico de grado <span class="math inline">\(k\)</span> se deben considerar obligatoriamente todos los grados desde <span class="math inline">\(1\)</span> hasta <span class="math inline">\(k-1\)</span>. Si consideramos un modelo polinómico de grado 4, el orden de los modelos anidados viene dado por:</p>
<p><span class="math display">\[\left\{
 \begin{array}{ll}
  \text{saturado }     &amp; Y \sim X + X^2 + X^3 + X^4\\
  \text{grado 3 }      &amp; Y \sim X + X^2 + X^3 \\
  \text{grado 2 }      &amp; Y \sim X + X^2 \\
  \text{grado 1 }      &amp; Y \sim X \\
  \text{sin efectos }      &amp; Y \sim 1 \\
 \end{array}
 \right. \]</span></p>
<p>A la hora de ajustar un modelo polinómico, siempre serán preferibles modelos con órdenes pequeños antes que grandes (principio de parsimonia o simplicidad). Siempre trataremos de seleccionar le modelo con un orden más pequeño, es decir, con menos efectos pero con igual predictivo que el modelo saturado.</p>
</div>
</div>
<div id="estimación-e-inferencia" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Estimación e inferencia<a class="anchor" aria-label="anchor" href="#estimaci%C3%B3n-e-inferencia"><i class="fas fa-link"></i></a>
</h2>
<p>Los procesos de estimación e inferencia del RLM y MP se basan en los mismos principios que los del modelo RLS estudiados en la unidad anterior. De hecho, las hipótesis sobre los errores de incorrelación, varianza constante y media cero son suficientes para obtener el ajuste por mínimos cuadrados del modelo propuesto. La normalidad es necesaria para obtener las inferencias y concluir sobre su fiabilidad.</p>
<p>Sin embargo, este tipo de modelos de regresión que consideran más de una predictora adolecen de un problema que puede ser muy relevante en su análisis. Dado que todas las predictoras no vendrán medidas en la misma escala de medida, el modelo obtenido (más concretamente los coeficientes del modelo) exhibe una dependencia de dicha escala que puede provocar que una variable con una variabilidad pequeña aparezca con un coeficiente grande en el modelo estimado. Para evitar esa dependencia se suele trabajar con las variables estandarizadas, es decir, corregidas por su media y desviación típica para eliminar los efectos de escala. Aunque en el apartado teórico mostraremos la solución para las variables en escala original, en la parte práctica mostraremos los coeficientes para las variables estandarizadas y veremos los cambios entre ambos modelos. Para denotar las variables transformadas añadiremos el prefijo <code>Z</code> al nombre de la predictora a la hora de escribir los modelos obtenidos.</p>
<div id="mínimos-cuadrados" class="section level3" number="7.2.1">
<h3>
<span class="header-section-number">7.2.1</span> Mínimos cuadrados<a class="anchor" aria-label="anchor" href="#m%C3%ADnimos-cuadrados"><i class="fas fa-link"></i></a>
</h3>
<p>Para estimar <span class="math inline">\(\beta\)</span> seguimos el criterio de minimizar la suma de cuadrados debida al error, esto es,</p>
<p><span class="math display">\[
min_{\beta} \quad \epsilon'\epsilon = min_{\beta} \quad (Y-X \beta)'(Y-X \beta) = min_{\beta} \quad Y'Y -2 \beta'X'Y + \beta'X'X\beta.
\]</span></p>
<p>Tras derivar la expresión anterior respecto de <span class="math inline">\(\beta\)</span> e igualarlo a cero, se obtiene el estimador de mínimos cuadrados de <span class="math inline">\(\beta\)</span> para el modelo <a href="rlm.html#eq:ecuacionML">(7.3)</a>, <span class="math inline">\(\hat{\beta}\)</span>, resolviendo las <span class="math inline">\(p\)</span> <em>ecuaciones normales</em>:</p>
<p><span class="math display" id="eq:ecuacionesnormales">\[\begin{equation}
X'X \beta=X'Y.
\tag{7.4}
\end{equation}\]</span></p>
<p>A la hora de resolver <a href="rlm.html#eq:ecuacionesnormales">(7.4)</a>, se pueden presentar dos situaciones:</p>
<ul>
<li>Las <span class="math inline">\(p\)</span> ecuaciones normales que resultan de <a href="rlm.html#eq:ecuacionesnormales">(7.4)</a> no son independientes y por lo tanto no existe la inversa de <span class="math inline">\(X'X\)</span>. Esto ocurre cuando las variables explicativas no son independientes entre sí. Entonces el modelo ha de expresarse en términos de menos parámetros (modificarse) o han de incorporarse restricciones adicionales sobre los parámetros para dar una matriz no singular.</li>
</ul>
<p>Cuando <span class="math inline">\((X'X)\)</span> es singular, el estimador de <span class="math inline">\(\beta\)</span> se obtiene a partir de una matriz inversa generalizada <span class="math inline">\(X'X\)</span>, <span class="math inline">\((X'X)^{-}\)</span>, como:</p>
<p><span class="math display" id="eq:solinvgen">\[\begin{equation}
\hat{\beta}=(X'X)^{-} X'Y.
\tag{7.5}
\end{equation}\]</span></p>
<p>Así, diferentes elecciones de la inversa generalizada <span class="math inline">\((X'X)^{-}\)</span> producen diferentes estimaciones de <span class="math inline">\(\beta\)</span>. Sin embargo, el modelo ajustado es el mismo, esto es, <span class="math inline">\(\hat{y}=X \hat{\beta}\)</span> es invariante a la inversa generalizada elegida.</p>
<ul>
<li>Las <span class="math inline">\(p\)</span> ecuaciones normales son independientes, con lo que <span class="math inline">\(X'X\)</span> es no singular y existe su inversa. El estimador de mínimos cuadrados resulta:</li>
</ul>
<p><span class="math display" id="eq:solmincuad">\[\begin{equation}
\hat{\beta}=(X'X)^{-1} (X'Y).
\tag{7.6}
\end{equation}\]</span></p>
</div>
<div id="propiedades" class="section level3" number="7.2.2">
<h3>
<span class="header-section-number">7.2.2</span> Propiedades<a class="anchor" aria-label="anchor" href="#propiedades"><i class="fas fa-link"></i></a>
</h3>
<p>Cuando prescindimos de la hipótesis de normalidad de los errores, obtenemos la estimación por mínimos cuadrados, que tiene las siguientes propiedades:</p>
<ol style="list-style-type: decimal">
<li><p>El estimador de mínimos cuadrados <span class="math inline">\(\hat{\beta}\)</span> minimiza <span class="math inline">\(\epsilon'\epsilon\)</span>, independientemente de la distribución de los errores. La hipótesis de normalidad se añade para justificar las inferencias basadas en estadísticos <span class="math inline">\(t\)</span> o <span class="math inline">\(F\)</span>.</p></li>
<li><p>Los elementos de <span class="math inline">\(\hat{\beta}\)</span> son funciones lineales de las observaciones <span class="math inline">\(y_1, \ldots, y_n\)</span> y son estimadores insesgados de mínima varianza, sea cual sea la distribución de los errores. Así tenemos:</p></li>
</ol>
<p><span class="math display">\[
E(\hat{\beta})=\beta \ \quad \mbox{ y }\ \quad Var(\hat{\beta})=\sigma^2 (X'X)^{-1} .
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Las estimaciones/predicciones de la variable respuesta <span class="math inline">\(y\)</span> se obtienen con el modelo lineal ajustado:</li>
</ol>
<p><span class="math display">\[
\hat{y}=X\hat{\beta}.
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>Los residuos <span class="math inline">\(e=y-X\hat{\beta}\)</span> verifican:</li>
</ol>
<ul>
<li><p><span class="math inline">\(\sum_{i=1}^n e_i \hat{y}_i = 0 \ \Leftrightarrow \ e'\hat{y}=\hat{y}' e = 0\)</span></p></li>
<li><p>La ortogonalidad entre los vectores de estimaciones y de residuos, <span class="math inline">\(\hat{y}\)</span> y <span class="math inline">\(e\)</span> respectivamente, implica el teorema de Pitágoras:</p></li>
</ul>
<p><span class="math display">\[
  |y|^2=|\hat{y}|^2+|e|^2 \ \Leftrightarrow \ \sum_{i=1}^n y_i^2= \sum_{i=1}^n \hat{y}_i^2 + \sum_{i=1}^n e_i^2.
  \]</span></p>
<ul>
<li><span class="math inline">\(\sum_{i=1}^n e_i = 0 \ \Leftrightarrow \ e'\mathbf{1}=\mathbf{1}' e = 0\)</span></li>
</ul>
</div>
<div id="máxima-verosimilitud" class="section level3" number="7.2.3">
<h3>
<span class="header-section-number">7.2.3</span> Máxima verosimilitud<a class="anchor" aria-label="anchor" href="#m%C3%A1xima-verosimilitud"><i class="fas fa-link"></i></a>
</h3>
<p>Como ocurría en el modelo RLS el estimador de mínimos cuadrados coincide con el máximo verosímil, ya que bajo la hipótesis de normalidad de los errores aleatorios, la verosimilitud conjunta tiene la forma:</p>
<p><span class="math display">\[
L(\beta;y) \propto f(y;\beta) \propto \left(\frac{1}{\sigma^2}\right)^{n/2} \quad exp\left\{-\frac{(y-X\beta)'(y-X\beta)}{2 \sigma^2}\right\}, 
\]</span></p>
<p>y maximizar la verosimilitud es equivalente a minimizar la log-verosimilitud cambiada de signo, que coincide con la suma de cuadrados del error para un valor fijo de <span class="math inline">\(\sigma^2\)</span>.</p>
<p>De nuevo utilizaremos la hipótesis de normalidad para proceder con el proceso de inferencia sobre el modelo <a href="rlm.html#eq:ecuacionML">(7.3)</a>.</p>
</div>
<div id="inferencia" class="section level3" number="7.2.4">
<h3>
<span class="header-section-number">7.2.4</span> Inferencia<a class="anchor" aria-label="anchor" href="#inferencia"><i class="fas fa-link"></i></a>
</h3>
<p>Para establecer los procedimientos de inferencia asociados con el modelo <a href="rlm.html#eq:ecuacionML">(7.3)</a> es preciso incorporar la hipótesis de normalidad de los errores. A partir de ella podemos obtener la distribución de los estadísticos y estimadores involucrados en el proceso de inferencia con el modelo lineal ajustado.</p>
<div id="varianza-del-modelo" class="section level4" number="7.2.4.1">
<h4>
<span class="header-section-number">7.2.4.1</span> Varianza del modelo<a class="anchor" aria-label="anchor" href="#varianza-del-modelo"><i class="fas fa-link"></i></a>
</h4>
<p>Podemos obtener un estimador de <span class="math inline">\(\sigma^2\)</span> basado en la variabilidad que ha quedado sin explicar por el modelo, cuantificada por lo que llamamos <strong>suma de cuadrados residual SSE</strong>:</p>
<p><span class="math display">\[
\begin{array}{ll}
SSE=\sum_{i=1}^n (y_i-\hat{y}_i)^2 &amp;= e'e \\
&amp;= y'y - 2 \hat{\beta}' X'y + \hat{\beta}'X'X \hat{\beta} \\
&amp;= y'y - \hat{\beta}' X'y.
\end{array}
\]</span></p>
<p>Puesto que en el modelo lineal propuesto se estiman <span class="math inline">\(p\)</span> parámetros, la suma de cuadrados residual <span class="math inline">\(SSE\)</span> tiene asociados <span class="math inline">\(n-p\)</span> grados de libertad (el número de datos menos el de coeficientes del modelo). El cociente entre <span class="math inline">\(SSE\)</span> y sus grados de libertad, <span class="math inline">\(n-p\)</span>, es el estimador de mínimos cuadrados de <span class="math inline">\(\sigma^2\)</span>, y es además, un estimador insesgado:</p>
<p><span class="math display">\[
\hat{\sigma}^2=s^2 = MSE=\frac{SSE}{n-p}.
\]</span></p>
<p>Asumiendo que el modelo es cierto, la distribución de probabilidad de la varianza del modelo es proporcional a una <span class="math inline">\(\chi^2\)</span> con <span class="math inline">\(n-p\)</span> grados de libertad,</p>
<p><span class="math display">\[
\frac{(n-p)s^2}{\sigma^2} \sim \chi^2_{n-p}.
\]</span></p>
</div>
<div id="coeficientes-del-modelo" class="section level4" number="7.2.4.2">
<h4>
<span class="header-section-number">7.2.4.2</span> Coeficientes del modelo<a class="anchor" aria-label="anchor" href="#coeficientes-del-modelo"><i class="fas fa-link"></i></a>
</h4>
<p>Bajo la hipótesis de normalidad de los errores, tenemos que el estimador máximo-verosímil <span class="math inline">\(\hat{\beta}\)</span> tiene una distribución normal:</p>
<p><span class="math display">\[
\hat{\beta} \sim N(\beta, \sigma^2 (X'X)^{-1}).
\]</span></p>
<p>Esto implica que la distribución marginal de cada uno de los coeficientes de la regresión, <span class="math inline">\(\hat{\beta}_i\)</span>, también es normal,</p>
<p><span class="math display">\[
\hat{\beta}_i \sim N(\beta_i, \sigma^2 C^{X}_{ii}), \ \ i=0, \ldots, p-1, 
\]</span></p>
<p>con <span class="math inline">\(C^{X}_{ii}\)</span> el <span class="math inline">\(i\)</span>-ésimo elemento de la diagonal de la matriz <span class="math inline">\((X'X)^{-1}\)</span>.</p>
<p>En consecuencia, para construir intervalos de confianza o resolver contrastes sobre cada uno de los coeficientes del modelo, individualmente, podemos utilizar estadísticos <span class="math inline">\(t\)</span> que se distribuyen con una distribución <em>t de Student</em> con <span class="math inline">\(n-p\)</span> grados de libertad:</p>
<p><span class="math display">\[
\frac{\hat{\beta}_i-\beta_i}{\sqrt{s^2 C^X_{ii}}} \ \sim \ t_{n-p}, \ \ i=1, \ldots, n, 
\]</span></p>
<p>construidos a partir del estimador de <span class="math inline">\(\sigma^2\)</span>, <span class="math inline">\(s^2\)</span>.</p>
<p>Así, un intervalo de confianza para un coeficiente de interés <span class="math inline">\(\beta_i\)</span> al nivel <span class="math inline">\((1-\alpha)100\%\)</span> viene dado por:</p>
<p><span class="math display">\[
\hat{\beta}_i \pm t_{(n-p, 1-\alpha/2)} \ \sqrt{s^2 \ C^X_{ii}}, 
\]</span></p>
<p>donde <span class="math inline">\(t_{(n-p, 1-\alpha/2)}\)</span> es el cuantil <span class="math inline">\(1-\alpha/2\)</span> de una distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(n-p\)</span> grados de libertad.</p>
<p>El contraste <span class="math inline">\(H_0:\beta_i=0\)</span> se resolverá con el rechazo de <span class="math inline">\(H_0\)</span> a nivel <span class="math inline">\(1-\alpha\)</span> si</p>
<p><span class="math display">\[
|\hat{\beta}_i| &gt; t_{(n-p, 1-\alpha/2)} \ \sqrt{s^2 \ C^X_{ii}}.
\]</span></p>
<p>Cuando se pretende obtener intervalos de confianza para varios coeficientes del modelo a la vez, es recomendable ser más conservador. Hay diversas soluciones propuestas para realizar “comparaciones múltiples”, esto es, testar todos los coeficientes a la vez, y obtener regiones de confianza conjuntas. Quizá el más conocido es el ajuste de Bonferroni, basado en sustituir el cuantil <span class="math inline">\(t_{(n-p, 1-\alpha/2)}\)</span> en la expresión anterior, por <span class="math inline">\(t_{(n-p, 1-\alpha/2q)}\)</span>, si <span class="math inline">\(q\)</span> es el número de coeficientes para los que se desea una estimación en intervalo. Se obtendrán entonces unos intervalos de confianza ‘ensanchados’ respecto a los intervalos de confianza individuales. Si no tenemos ninguna prioridad particular sobre determinados coeficientes, lo lógico será obtener conjuntamente los intervalos de confianza para todos los coeficientes del modelo, esto es, <span class="math inline">\(q=p\)</span>.</p>
<p>Otra opción para la estimación en intervalo es construir una <em>región de confianza conjunta</em> para todos los parámetros <span class="math inline">\(\beta\)</span> del modelo, determinando los puntos <span class="math inline">\(\beta\)</span> de la elipse definida por:</p>
<p><span class="math display">\[
(\beta-\hat{\beta})'X'X (\beta-\hat{\beta})= (p+1) \ s^2 \ F_{(p, n-p, 1-\alpha)}, 
\]</span></p>
<p>donde <span class="math inline">\(F_{(p, n-p, 1-\alpha)}\)</span> es el cuantil <span class="math inline">\(1-\alpha\)</span> de una distribución <span class="math inline">\(F\)</span> con <span class="math inline">\(p\)</span> y <span class="math inline">\(n-p\)</span> grados de libertad.</p>
<p>Es posible construir regiones de confianza conjuntas de este tipo para cualquier subconjunto de coeficientes del modelo. Bastará variar adecuadamente los grados de libertad <span class="math inline">\(p\)</span> y <span class="math inline">\(n-p\)</span>. Estas regiones acaban siendo complicadas de interpretar, especialmente cuando la dimensión de <span class="math inline">\(\beta\)</span> es grande. Sin embargo, en la práctica no se suele hacer cuando el número de predictoras es elevado.</p>
</div>
</div>
<div id="ejemplos-3" class="section level3" number="7.2.5">
<h3>
<span class="header-section-number">7.2.5</span> Ejemplos<a class="anchor" aria-label="anchor" href="#ejemplos-3"><i class="fas fa-link"></i></a>
</h3>
<p>Realizamos el proceso de estimación e inferencia para los modelos saturados correspondientes a los ejemplos presentados al inicio de esta unidad. Obtendremos el modelo para las predictoras en escala original y estandarizadas, representaremos los intervalos de confianza de los coeficientes del modelo, y obtendremos el ajuste final del modelo. Utilizaremos la función <code>tab_model</code> de la libreria <code>sjplot</code> para el análisis de los coeficientes del modelo, ya que nos proporciona más información que la función <code>glm_coef</code>.</p>
<div id="datos-de-bosque" class="section level4" number="7.2.5.1">
<h4>
<span class="header-section-number">7.2.5.1</span> Datos de Bosque<a class="anchor" aria-label="anchor" href="#datos-de-bosque"><i class="fas fa-link"></i></a>
</h4>
<p>Ajustamos un modelo RLM para el conjunto de datos bosque.</p>
<div class="sourceCode" id="cb247"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Ajuste del modelo</span>
<span class="va">fit.bosque</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vol</span> <span class="op">~</span> <span class="va">dbh</span> <span class="op">+</span> <span class="va">d16</span> <span class="op">+</span> <span class="va">ht</span>, data <span class="op">=</span> <span class="va">bosque</span><span class="op">)</span>
<span class="co"># Inferencia sobre los parámetros del modelo</span>
<span class="fu"><a href="https://rdrr.io/pkg/pubh/man/glm_coef.html">glm_coef</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>##     Parameter              Coefficient Pr(&gt;|t|)
## 1 (Intercept) -108.58 (-138.56, -78.6)  &lt; 0.001
## 2         dbh        1.63 (-0.55, 3.8)    0.133
## 3         d16        5.67 (3.12, 8.22)  &lt; 0.001
## 4          ht        0.69 (0.35, 1.04)  &lt; 0.001</code></pre>
<p>de forma que el ajuste obtenido viene dado por:
<span class="math display">\[
\widehat{\text{vol}} = -108.58 + 1.63*\text{dbh} + 5.67*\text{d16} + 0.69*\text{ht} 
\]</span>
La interpretación de los coeficientes nos indica que el valor predicho de volumen aumenta en 1.63 unidades por el aumenta de una unidad de DBH, en 5.67 unidades por cada unidad de D16, y 0.69 unidades por cada unidad de HT. A la vista de los contrastes individuales (p-valores) podemos concluir que los coeficientes asociados con D16 y HT son significativos, es decir, sus coeficientes si sólo esa variable estuviera presente en el modelo serían distintos de cero. Esta información se ve reforzada por los intervalos de confianza individuales, que además muestran que dichos coeficientes son positivos indicando que el VOL aumenta directamente al aumentar los valores de D16 y HT. Por tanto, el modelo anidado dado por:
<span class="math display">\[vol \sim d16 + ht\]</span>
podría ser igualmente válido que el que contiene todas las predictoras. A continuación, se presenta el ajuste obtenido para cada variable de forma marginal.</p>
<p>Representamos gráficamente la estimación e intervalo de confianza de los coeficientes del modelo para apreciar los efectos descritos:</p>
<div class="sourceCode" id="cb249"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.bosque</span>, 
        show.values <span class="op">=</span> <span class="cn">TRUE</span>, 
        vline.color <span class="op">=</span> <span class="st">"yellow"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm004-1.png" width="95%" style="display: block; margin: auto;"></div>
<p>Comparamos los resultados con los del modelo estandarizado. La tabla proporciona las estimaciones e intervalo de confianza al 95% de los parámetros en la escala original (<code>Estimates</code> y <code>CI</code>), las estimaciones y CI de los coeficientes del modelo estandarizado (<code>std.Beta</code> y <code>standarized CI</code>), y el p-valor asociado a cada coeficiente</p>
<div class="sourceCode" id="cb250"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Inferencia sobre los parámetros del modelo</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/tab_model.html">tab_model</a></span><span class="op">(</span><span class="va">fit.bosque</span>, 
     show.std <span class="op">=</span> <span class="cn">TRUE</span>, 
     show.r2 <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table style="border-collapse:collapse; border:none;" class="table table-sm">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="5" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
vol
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-108.58
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-138.56 – -78.60
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.10 – 0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
dbh
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.21
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.55 – 3.80
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.07 – 0.50
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.133
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
d16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
5.67
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.65
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
3.12 – 8.22
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.36 – 0.95
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
ht
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.69
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.24
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.35 – 1.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.12 – 0.36
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="5">
20
</td>
</tr>
</table></div>
<p>Se aprecia como la variable más relevante para explicar el comportamiento del volumen de madera es el diámetro del tronco a 16 pies de altura con un coeficiente estandarizado de 0.65, que es tres veces superior a los coeficientes de las otras predictoras. Podemos ver el gráfico de las estimaciones para el modelo estandarizado:</p>
<div class="sourceCode" id="cb251"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.bosque</span>, 
        show.values <span class="op">=</span> <span class="cn">TRUE</span>, 
        vline.color <span class="op">=</span> <span class="st">"yellow"</span>, 
        type <span class="op">=</span> <span class="st">"std"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm005-2-1.png" width="95%" style="display: block; margin: auto;"></div>
<p>Por último, obtenemos los gráficos del modelo ajustado. Para obtener estos gráficos se asume como valor para la predictoras que no están en el gráfico igual a su media muestral Por ejemplo, para el gráfico de <code>vol</code> con respecto <code>dbh</code> utilizamos el modelo:
<span class="math display">\[
\widehat{\text{vol}} = -108.58 + 1.63*\text{dbh} + 5.67*\overline{\text{d16}} + 0.69*\overline{\text{ht}}
\]</span>
donde <span class="math inline">\(\overline{\text{d16}}\)</span> y <span class="math inline">\(\overline{\text{ht}}\)</span> son respectivamente las medias muestrales de <code>d16</code> y <code>ht</code>. Los gráficos para cada predictora son:</p>
<div class="sourceCode" id="cb252"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.bosque</span>, <span class="st">"pred"</span>,  
        ci.lvl <span class="op">=</span> <span class="cn">NA</span>, 
        show.data <span class="op">=</span> <span class="cn">TRUE</span>, 
        title <span class="op">=</span> <span class="st">"Modelo ajustado"</span><span class="op">)</span></code></pre></div>
<pre><code>## $dbh</code></pre>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm006-1.png" width="95%" style="display: block; margin: auto;"></div>
<pre><code>## 
## $d16</code></pre>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm006-2.png" width="95%" style="display: block; margin: auto;"></div>
<pre><code>## 
## $ht</code></pre>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm006-3.png" width="95%" style="display: block; margin: auto;"></div>
</div>
<div id="datos-de-concentración" class="section level4" number="7.2.5.2">
<h4>
<span class="header-section-number">7.2.5.2</span> Datos de concentración<a class="anchor" aria-label="anchor" href="#datos-de-concentraci%C3%B3n"><i class="fas fa-link"></i></a>
</h4>
<p>Ajustamos un modelo RLM para el conjunto de datos de concentración.</p>
<div class="sourceCode" id="cb256"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Ajuste del modelo</span>
<span class="va">fit.concen</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">p.higado</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span>
<span class="co"># Inferencia</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/tab_model.html">tab_model</a></span><span class="op">(</span><span class="va">fit.concen</span>, 
     show.std <span class="op">=</span> <span class="cn">TRUE</span>, 
     show.r2 <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table style="border-collapse:collapse; border:none;" class="table table-sm">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="5" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
concen
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.15 – 0.68
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.43 – 0.43
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.192
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
p cuerpo
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-3.96
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.04 – -0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-7.13 – -0.79
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.018</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
p higado
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.02 – 0.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.31 – 0.70
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.419
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
dosis
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.18
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.93 – 7.42
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.90 – 7.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.015</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="5">
19
</td>
</tr>
</table></div>
<p>de forma que el ajuste obtenido viene dado por:
<span class="math display">\[
\widehat{\text{concen}} = 0.27 - 0.02*\text{p.cuerpo} + 0.01*\text{p.higado} + 4.18*\text{dosis} 
\]</span>
La interpretación de los coeficientes nos indica que el valor predicho de la concentración aumenta con el peso del hígado y dosis suministrada, pero disminuye con el peso del cuerpo. Los valores tan pequeños de los coeficientes asociados a los pesos podrían indicar que dichas variables no tienen gran capacidad predictiva, pero hay que tener en cuenta que dichas variables están medidas en un escala distinta de la dosis, y que por tanto la estimación de los coeficientes se ve influenciada por dicha escala. Si nos fijamos en los coeficientes estandarizados apreciamos la misma tendencia en todas la preditoras (signo del coeficiente) pero vemos como tanto el <code>p.cuerpo</code> como la <code>dosis</code> tienen un peso similar para explicar el comportamiento de la concentración.</p>
<p>Del análisis de los contrastes individuales podríamos descartar la variable peso del hígado (p-valor &gt;0.05) para explicar el comportamiento de la concentración del compuesto (algo que deberemos comprobar posteriomente), y considerar el resto de predictoras en el modelo anidado:
<span class="math display">\[concen \sim p.cuerpo + dosis\]</span>
Los gráficos de los coeficientes del modelo (no estandarizados y estandarizados) nos permite ver gráficamente estas conclusiones:</p>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste sin estandarizar</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.concen</span>, 
        show.values <span class="op">=</span> <span class="cn">TRUE</span>, 
        vline.color <span class="op">=</span> <span class="st">"yellow"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm008-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb258"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste estandarizados</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.concen</span>, 
        show.values <span class="op">=</span> <span class="cn">TRUE</span>, 
        vline.color <span class="op">=</span> <span class="st">"yellow"</span>, 
        type <span class="op">=</span> <span class="st">"std"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure">
<img src="18-lmRLM_files/figure-html/rlm008-2.png" width="95%" style="display: block; margin: auto;">
En el gráfico de coeficientes sin estandarizar se aprecia el efecto de trabajar en la escala original, dado que el intervalo de confianza del peso del cuerpo es inapreciable y puede llegar a parecer que no tiene efecto sobre la concentración, lo que si queda más claro en el gráfico de los coeficientes estandarizados.</div>
<p>¿qué ocurre cuando realizamos el gráfico del ajuste para este conjunto de datos?</p>
</div>
<div id="datos-de-papel" class="section level4" number="7.2.5.3">
<h4>
<span class="header-section-number">7.2.5.3</span> Datos de papel<a class="anchor" aria-label="anchor" href="#datos-de-papel"><i class="fas fa-link"></i></a>
</h4>
<p>Ajustamos un modelo MP de grado 2 para el conjunto de datos de papel presentados en la unidad anterior.</p>
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Ajuste del modelo</span>
<span class="va">fit.papel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">tension</span> <span class="op">~</span> <span class="va">madera</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">madera</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">papel</span><span class="op">)</span>
<span class="co"># Inferencia</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/tab_model.html">tab_model</a></span><span class="op">(</span><span class="va">fit.papel</span>, 
     show.std <span class="op">=</span> <span class="cn">TRUE</span>, 
     show.r2 <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table style="border-collapse:collapse; border:none;" class="table table-sm">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="6" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
tension
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
std. p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-6.67
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.81
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-13.88 – 0.53
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.58 – 1.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.067
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
madera
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
11.76
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.79
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
9.64 – 13.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.63 – 0.96
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
madera^2
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.85
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.77 – -0.50
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-1.03 – -0.68
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="6">
19
</td>
</tr>
</table></div>
<p>de forma que el ajuste obtenido viene dado por:
<span class="math display">\[
\widehat{\text{tension}} = -6.67 + 11.76*\text{madera} - 0.63*\text{madera}^2
\]</span>
El ajuste obtenido es una parábola invertida (coeficiente negativo en la potencia 2) tal y como se observaba en el gráfico de los datos (Figura <a href="rls.html#fig:rls002">6.2</a>). En este tipo de modelos el análisis inferencial se debe centrar en el estudio del orden más alto, para determinar si es adecuado o si podríamos construir un modelo de un orden más simple. La significatividad del coeficiente (p-valor &lt; 0.05) indica que dicho grado es necesario en el modelo. De hecho, los coeficientes estandarizados muestran un efecto similar tanto en el grado 1 como en grado 2. Lo vemos gráficamente:</p>
<div class="sourceCode" id="cb260"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste sin estandarizar</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.papel</span>, 
        show.values <span class="op">=</span> <span class="cn">TRUE</span>, 
        vline.color <span class="op">=</span> <span class="st">"yellow"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm011-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste estandarizados</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.papel</span>, 
        show.values <span class="op">=</span> <span class="cn">TRUE</span>, 
        vline.color <span class="op">=</span> <span class="st">"yellow"</span>, 
        type <span class="op">=</span> <span class="st">"std"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm011-2.png" width="95%" style="display: block; margin: auto;"></div>
<p>Vemos el gráfico del ajuste obtenido:</p>
<div class="sourceCode" id="cb262"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.papel</span>, <span class="st">"pred"</span>,  
        ci.lvl <span class="op">=</span> <span class="cn">NA</span>, 
        show.data <span class="op">=</span> <span class="cn">TRUE</span>, 
        title <span class="op">=</span> <span class="st">"Modelo ajustado"</span><span class="op">)</span></code></pre></div>
<pre><code>## $madera</code></pre>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm012-1.png" width="95%" style="display: block; margin: auto;"></div>
<p>La tendencia ajustada se corresponde con la observada en los datos del experimento.</p>
</div>
</div>
</div>
<div id="bondad-del-ajuste-1" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Bondad del ajuste<a class="anchor" aria-label="anchor" href="#bondad-del-ajuste-1"><i class="fas fa-link"></i></a>
</h2>
<p>En este punto presentamos los procedimientos de bondad de ajuste habituales en los modelos de regresión: Análisis de la tabla Anova, el coeficiente de determinación, y el coeficiente de determinación ajustado. Por el momento nos centraremos en el estudio de bondad de ajuste del modelo saturado. En las secciones siguientes veremos como determinar el conjunto de predictoras más relevantes para explicar el comportamiento de la respuesta, y utilizaremos de nuevo estos criterios para valorar el ajuste obtenido.</p>
<div id="tabla-anova" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> Tabla ANOVA<a class="anchor" aria-label="anchor" href="#tabla-anova"><i class="fas fa-link"></i></a>
</h3>
<p>Habitualmente, la primera forma de juzgar la calidad del ajuste obtenido consiste en valorar la variabilidad de la respuesta que se ha podido explicar con el modelo propuesto. En lo que sigue, asumiremos que el modelo ajustado es <span class="math inline">\(\hat{y}=X\hat{\beta}\)</span>, donde la matriz de diseño <span class="math inline">\(X\)</span> tiene por columnas todas las variables explicativas consideradas, sean continuas o dummies definidas para representar algún factor. En todo caso, suponemos que hemos estimado <span class="math inline">\(p\)</span> coeficientes, esto es, <span class="math inline">\(\hat{\beta} \in \mathbb{R}^p\)</span>.</p>
<p>Descomponemos pues la variabilidad de las observaciones <span class="math inline">\(y\)</span>, en la parte explicada por el modelo ajustado y corregida por la media de los datos (suma de cuadrados de la regresión), <span class="math inline">\(SSR\)</span>, y la parte residual (suma de cuadrados debida al error) que ha quedado sin explicar, <span class="math inline">\(SSE\)</span>:</p>
<p><span class="math display">\[
\underbrace{(y-\bar{y}1)'(y-\bar{y}1)}_{S_{yy}}= \underbrace{(\hat{y}-\bar{y}1)'(\hat{y}-\bar{y}1)}_{SSR} +\underbrace{e'e}_{SSE}, 
\]</span></p>
<p>donde <span class="math inline">\(\bar{y}=\sum_i y_i/n\)</span>.</p>
<p>Los grados de libertad asociados a <span class="math inline">\(SSR\)</span> son <span class="math inline">\(p-1\)</span>, pues se pierde un parámetro al corregir la estimación <span class="math inline">\(\hat{y}\)</span> (obtenida a partir de <span class="math inline">\(p\)</span> parámetros) por la media <span class="math inline">\(\bar{y}\)</span>. La suma de cuadrados del error <span class="math inline">\(SSE\)</span> tiene asociados <span class="math inline">\(n-p\)</span> grados de libertad, esto es, el número de datos menos el número de parámetros estimados en el modelo. Al dividir las sumas de cuadrados por sus grados de libertad respectivos, obtenemos los cuadrados medios correspondientes, <span class="math inline">\(MSR=SSR/(p-1)\)</span> y <span class="math inline">\(MSE=SSE/(n-p)\)</span>, que nos resultan útiles para valorar la <strong>bondad del ajuste</strong>. El test de bondad de ajuste propone el contraste:</p>
<p><span class="math display" id="eq:RLMtestReg">\[\begin{equation}
H_0: \beta_1=\beta_2=\ldots=\beta_{p-1}=0, \qquad H_1: \mbox{ algún } \beta_i \neq 0.
\tag{7.7}
\end{equation}\]</span></p>
<p>Cuando el modelo es bueno, <span class="math inline">\(MSR\)</span> y <span class="math inline">\(MSE\)</span> siguen sendas distribuciones proporcionales a chi-cuadrados independientes (con la misma constante de proporcionalidad <span class="math inline">\(\sigma^2\)</span>), con <span class="math inline">\(p-1\)</span> y <span class="math inline">\(n-p\)</span> grados de libertad respectivamente; de ahí que su cociente (libre ya de la constante desconocida <span class="math inline">\(\sigma^2\)</span>) resulta tener una distribución <span class="math inline">\(F\)</span> con <span class="math inline">\(p-1\)</span> y <span class="math inline">\(n-p\)</span> grados de libertad:</p>
<p><span class="math display" id="eq:RLMtestF">\[\begin{equation}
F=\frac{SSR/(p-1)}{SSE/(n-p)}=\frac{MSR}{MSE} \ \sim \ F_{(p-1, n-p)}.
\tag{7.8}
\end{equation}\]</span></p>
<p>Así, con dicho estadístico <span class="math inline">\(F\)</span> contrastamos si la variabilidad explicada por el modelo ajustado es suficientemente grande comparada con la que queda sin explicar (la de los residuos); en otras palabras, si el modelo ajustado es significativo para explicar la variabilidad de los datos. Si el p-valor asociado al estadístico F es inferior a la significatividad considerada (generalmente 0.05), rechazamos que el modelo propuesto no explique conjuntamente la respuesta, y concluimos a favor de que algunas de las covariables contienen información significativa para predecir la respuesta, esto es, a favor de la bondad del ajuste. En otro caso, no podemos garantizar significativamente la bondad del modelo propuesto.</p>
<p>La Tabla de Anova es la forma habitual de presentar toda la información de las sumas, medias de cuadrados, estadísticos <span class="math inline">\(F\)</span> y p-valores asociados al contraste de bondad de ajuste del modelo. La salida de la Tabla Anova que proporciona <code>R</code> no es exactamente la habitual presentada en todos los libros. En dicha tabla, en lugar de contrastar globalmente el ajuste a través de la suma de cuadrados asociada a la regresión, se contrasta secuencialmente la significatividad de cada una de las covariables a la hora de explicar la variable respuesta en presencia de las variables que ya han sido incorporadas al modelo (las que quedan por encima en la salida). Sin embargo, con dicha salida es posible calcular el test F de bondad de ajuste.</p>
<p>Utilizaremos diferentes funciones para obtener el estadístico F y el p-valor asociado, y las funciones <code><a href="https://rdrr.io/r/stats/anova.html">anova()</a></code> para obtener la descomposición de la tabla ANOVA.</p>
</div>
<div id="coeficiente-determinación" class="section level3" number="7.3.2">
<h3>
<span class="header-section-number">7.3.2</span> Coeficiente determinación<a class="anchor" aria-label="anchor" href="#coeficiente-determinaci%C3%B3n"><i class="fas fa-link"></i></a>
</h3>
<p>El coeficiente de determinación, <span class="math inline">\(R^2\)</span>, se define como la parte proporcional de la variabilidad de los datos que es explicada por el modelo ajustado:</p>
<p><span class="math display" id="eq:RLMR2">\[\begin{equation}
R^2 = \frac{SSR}{S_{yy}} = 1 - \frac{SSE}{S_{yy}}
\tag{7.9}
\end{equation}\]</span></p>
<p>Por definición tenemos que <span class="math inline">\(0 \leq R^2 \leq 1\)</span>. Un ajuste perfecto de los datos produciría <span class="math inline">\(R^2=1\)</span>. Si ninguna de las variables predictoras <span class="math inline">\(X_1, \ldots, X_{p-1}\)</span> es útil para explicar la respuesta <span class="math inline">\(Y\)</span>, entonces <span class="math inline">\(R^2=0\)</span>.</p>
<p>Siempre es posible conseguir <span class="math inline">\(R^2\)</span> suficientemente grande, simplemente añadiendo más términos en el modelo. Por ejemplo, si hay más de un valor de <span class="math inline">\(y\)</span> para un mismo <span class="math inline">\(x\)</span> observado, un polinomio de grado <span class="math inline">\(n-1\)</span> proporcionará un ajuste “perfecto” (<span class="math inline">\(R^2=1\)</span>) para <span class="math inline">\(n\)</span> datos. Cuando esto no ocurre y hay únicamente un valor de <span class="math inline">\(y\)</span> por cada <span class="math inline">\(x\)</span>, <span class="math inline">\(R^2\)</span> nunca puede ser igual a 1 porque el modelo no puede explicar la variabilidad debida al <em>error puro</em>.</p>
<p>Aunque <span class="math inline">\(R^2\)</span> siempre aumenta cuando añadimos una variable explicativa al modelo, esto no significa necesariamente que el nuevo modelo sea superior al antiguo, es decir, que dicha variable sea útil para explicar mejor los datos. A pesar de que la suma de cuadrados residual <span class="math inline">\(SSE\)</span> del nuevo modelo se reduce por una cantidad igual al anterior <span class="math inline">\(MSE\)</span>, el nuevo modelo tendrá un <span class="math inline">\(MSE\)</span> mayor debido a que pierde un grado de libertad. Por lo tanto, el nuevo modelo será de hecho, peor que el antiguo.</p>
<p>En consecuencia, algunos analistas prefieren utilizar una versión ajustada del estadístico <span class="math inline">\(R^2\)</span>. El <span class="math inline">\(R^2\)</span> <em>ajustado</em> penaliza los modelos que incorporan variables innecesarias dividiendo las sumas de cuadrados por sus grados de libertad, esto es,</p>
<p><span class="math display" id="eq:RLMR2a">\[\begin{equation}
R^2_a=1-\frac{SSE/(n-p)}{S_{yy}/(n-1)}=1-(1-R^2)\left(\frac{n-1}{n-p}\right).
\tag{7.10}
\end{equation}\]</span></p>
<p><span class="math inline">\(R^2_a\)</span> es preferible a <span class="math inline">\(R^2\)</span> cuando sus valores difieren mucho. Su interpretación tiene algún problema debido a que puede tomar valores negativos; esto ocurre cuando el estadístico <span class="math inline">\(F\)</span> toma valores inferiores a 1 (o produce p-valores mayores que 0.05).</p>
</div>
<div id="ejemplos-4" class="section level3" number="7.3.3">
<h3>
<span class="header-section-number">7.3.3</span> Ejemplos<a class="anchor" aria-label="anchor" href="#ejemplos-4"><i class="fas fa-link"></i></a>
</h3>
<p>Analizamos los diferentes ejemplos con los que venimos trabajando a lo largo de la unidad.</p>
<div id="datos-de-bosque-1" class="section level4" number="7.3.3.1">
<h4>
<span class="header-section-number">7.3.3.1</span> Datos de Bosque<a class="anchor" aria-label="anchor" href="#datos-de-bosque-1"><i class="fas fa-link"></i></a>
</h4>
<p>Bondad de ajuste para los datos bosque.</p>
<div class="sourceCode" id="cb264"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Bondad del ajuste</span>
<span class="fu"><a href="https://generics.r-lib.org/reference/glance.html">glance</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC deviance df.residual
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1     0.959         0.951  3.10      125. 2.59e-11     3  -48.7  107.  112.     153.          16
## # … with 1 more variable: nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb266"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Tabla ANOVA</span>
<span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: vol
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## dbh        1 3085.79 3085.79 322.064 5.051e-12 ***
## d16        1  331.85  331.85  34.635 2.303e-05 ***
## ht         1  173.42  173.42  18.100 0.0006056 ***
## Residuals 16  153.30    9.58                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>Tanto el <span class="math inline">\(R^2\)</span> como el <span class="math inline">\(R^2\)</span> ajustado muestran porcentajes del 95% indicando que el modelo ajustado tiene buena capacidad explicativa. Además, el test <span class="math inline">\(F\)</span> de la regresión resulta significativo (p-valor &lt; 0.05) indicando que las predictoras consideradas pueden ser utilizadas para describir el comportamiento del volumen. Los tests individuales de la tabla ANOVA</p>
</div>
<div id="datos-de-concentración-1" class="section level4" number="7.3.3.2">
<h4>
<span class="header-section-number">7.3.3.2</span> Datos de Concentración<a class="anchor" aria-label="anchor" href="#datos-de-concentraci%C3%B3n-1"><i class="fas fa-link"></i></a>
</h4>
<p>Bondad de ajuste para los datos de concentración</p>
<div class="sourceCode" id="cb268"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Bondad del ajuste</span>
<span class="fu"><a href="https://generics.r-lib.org/reference/glance.html">glance</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC deviance df.residual
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1     0.364         0.237 0.0773      2.86  0.0720     3   23.9 -37.9 -33.1   0.0896          15
## # … with 1 more variable: nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb270"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Tabla ANOVA</span>
<span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: concen
##           Df   Sum Sq  Mean Sq F value  Pr(&gt;F)  
## p.cuerpo   1 0.003216 0.003216  0.5383 0.47446  
## p.higado   1 0.003067 0.003067  0.5134 0.48467  
## dosis      1 0.044982 0.044982  7.5296 0.01507 *
## Residuals 15 0.089609 0.005974                  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>El <span class="math inline">\(R^2\)</span> y el <span class="math inline">\(R^2\)</span> ajustado muestran valores bastante bajos indicando poco poder explicativo. Además, el p-valor del test <span class="math inline">\(F\)</span> resulta no significativo indicando que todos los coeficientes del modelo podrían ser considerados iguales a cero. Esto contradice lo visto durante el proceso de estimación de los parámetros del modelo y la tabla ANOVA obtenida donde se aprecia que el efecto asociado con dosis resulta significativo. Este comportamiento puede ser debido al considerar más predictoras de las necesarias o simplemente a que las predictoras no son adecuadas para explicar el comportamiento de la concentración. En el punto siguiente, donde se tratará la selección del mejor modelo, analizaremos este modelo con más detalle y podremos concluir sobre la validez de las predcitoras.</p>
</div>
<div id="datos-de-papel-1" class="section level4" number="7.3.3.3">
<h4>
<span class="header-section-number">7.3.3.3</span> Datos de Papel<a class="anchor" aria-label="anchor" href="#datos-de-papel-1"><i class="fas fa-link"></i></a>
</h4>
<p>Bondad de ajuste para los datos de papel</p>
<div class="sourceCode" id="cb272"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Bondad del ajuste</span>
<span class="fu"><a href="https://generics.r-lib.org/reference/glance.html">glance</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic      p.value    df logLik   AIC   BIC deviance df.residual
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1     0.909         0.897  4.42      79.4      4.91e-9     2  -53.6  115.  119.     313.          16
## # … with 1 more variable: nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb274"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Tabla ANOVA</span>
<span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: tension
##             Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## madera       1 1043.43 1043.43   53.40 1.758e-06 ***
## I(madera^2)  1 2060.82 2060.82  105.47 1.894e-08 ***
## Residuals   16  312.64   19.54                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>En términos de <span class="math inline">\(R^2\)</span> y <span class="math inline">\(R^2\)</span> ajustado el modelo tiene buena capacidad explicativa (porcentajes del 90%) y el test <span class="math inline">\(F\)</span> resulta significativo, indicando que alguno de los coeficientes del modelo debe ser considerado distinto de cero. Dado que se trata de un modelo polinómico nos debemos fijar de la significatividad del término de mayor orden en la tabla ANOVA. En este caso dicho efecto resulta significativo indicando que el modelo propuesto de grado 2 es necesario para explicar el comportamiento de la tensión del papel.</p>
</div>
</div>
</div>
<div id="comparación-y-selección-de-modelos" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> Comparación y selección de modelos<a class="anchor" aria-label="anchor" href="#comparaci%C3%B3n-y-selecci%C3%B3n-de-modelos"><i class="fas fa-link"></i></a>
</h2>
<p>La modelización de datos es siempre una faena tediosa debido a la innumerable cantidad de alternativas posibles. Está por determinar el tipo de modelo, las transformaciones más adecuadas, identificar las variables más relevantes, descartar las innecesarias, y posteriormente abordar la diagnosis y validación del modelo, que trataremos en las secciones siguientes. Si el modelo está mal especificado, las estimaciones de los coeficientes pueden resultar considerablemente sesgadas. Una buena especificación del modelo es un trabajo, en general, complicado de obtener.</p>
<p>Si se ha optado por la modelización lineal de una respuesta en función de una serie de posibles variables predictoras, y el objetivo es seleccionar el mejor subconjunto de predictores para explicar la respuesta, el planteamiento es siempre el de obtener “buenas” predicciones. Sin embargo, sabemos que cuantos más predictores incluyamos en el modelo, mejores predicciones tendremos (menos sesgo), pero a la vez menos precisión sobre ellas (ya que la varianza es proporcional al número de variables predictoras en el modelo). Para la selección del “mejor” modelo habremos de llegar a un compromiso entre estos dos propósitos. Tratamos pues la selección de variables como un problema de comparación y selección de modelos.</p>
<p>Vamos a presentar diversos criterios para comparar modelos y seleccionar el mejor modelo de entre dos alternativas. En ocasiones todos darían los mismos resultados, pero generalmente no, por lo que habrá de ser el analista el que decida qué criterio utilizar en función de sus intereses prioritarios. La selección del modelo se puede realizar con múltiples criterios pero aquí presentamos los más habituales basados en:</p>
<ul>
<li>la significatividad de los predictores que están presentes en el modelo y los que no;</li>
<li>Los estadísticos <span class="math inline">\(AIC\)</span> (<em>Akaike Information Criteria</em>) y <span class="math inline">\(BIC\)</span> (<em>Bayesian Information Criteria</em>);</li>
</ul>
<p>Una vez seleccionado el “mejor” modelo según el criterio elegido, habremos de proseguir la confirmación del mismo realizando la diagnosis y la validación del modelo, que puede fallar en algún paso, lo que nos conduciría de nuevo a la reformulación del modelo (y todos los pasos que le siguen), optando por aquellas correcciones y/o transformaciones de variables sugeridas en el diagnóstico. La consecución del <em>mejor modelo</em> será pues, un procedimiento iterativo, basado en selección y valoración de la calidad del ajuste, diagnóstico y validación. En muchas situaciones prácticas nos conformaremos con encontrar el modelo que tenga un funcionamiento más adecuado aunque no sea prefecto.</p>
<div id="significatividad-de-los-predictores" class="section level3" number="7.4.1">
<h3>
<span class="header-section-number">7.4.1</span> Significatividad de los predictores<a class="anchor" aria-label="anchor" href="#significatividad-de-los-predictores"><i class="fas fa-link"></i></a>
</h3>
<p>Este procedimiento se basa en la comparación de modelos basada en las sumas de cuadrados y el test <span class="math inline">\(F\)</span> resultante de compararlas.</p>
<p>Supongamos que tenemos ajustado un modelo definido por <span class="math inline">\(p\)</span> coeficientes. Si queremos valorar la contribución que hacen al ajuste de los datos un subconjunto de <span class="math inline">\(q\)</span> variables predictoras adicionales, debemos plantear el contraste</p>
<p><span class="math display" id="eq:contrasteparcial">\[\begin{equation}
H_0: y=X_p \beta_p + \epsilon, \ \ vs. \ \ H_1:y=X_{p+q} \beta_{p+q} + \epsilon.
\tag{7.11}
\end{equation}\]</span></p>
<p>Para resolver el contraste <a href="rlm.html#eq:contrasteparcial">(7.11)</a> se utiliza una versión del test <span class="math inline">\(F\)</span> de regresión de la tabla ANOVA. Para resolverlo basta con ajustar los modelos con <span class="math inline">\(p\)</span> y <span class="math inline">\(p+q\)</span> predictoras, para obtener las sumas de cuadrados del error respectivas, <span class="math inline">\(SSE(p)\)</span> y <span class="math inline">\(SSE(p+q)\)</span>. Su diferencia representa la reducción del error debida a la inclusión de los <span class="math inline">\(q\)</span> regresores adicionales, y bajo <span class="math inline">\(H_0\)</span> tienen una distribución chi-cuadrado, independiente de <span class="math inline">\(SSE(p)\)</span>. Se puede definir entonces un estadístico <span class="math inline">\(F\)</span> para realizar la comparación de modelos y resolver el contraste <a href="rlm.html#eq:contrasteparcial">(7.11)</a>, dado por:</p>
<p><span class="math display" id="eq:testFparcial">\[\begin{equation}
F_q=\frac{(SSE(p)-SSE(p+q))/q}{SSE(p)/(n-p)} \sim F_{q, n-p}.
\tag{7.12}
\end{equation}\]</span></p>
<p>Las <span class="math inline">\(q\)</span> variables adicionales se consideran relevantes (significativas) en la explicación de la respuesta, si <span class="math inline">\(F_q\)</span> tiene asociado un p-valor significativo. Un criterio para seleccionar el mejor modelo es quedarse con aquel menos complejo (en términos de predictoras presentes en el modelo) y que pueda considerarse con la misma capacidad predictiva (test <span class="math inline">\(F\)</span> parcial no significativo) que cualquier otro más complejo.</p>
</div>
<div id="estadísticos-aic-y-bic" class="section level3" number="7.4.2">
<h3>
<span class="header-section-number">7.4.2</span> Estadísticos AIC y BIC<a class="anchor" aria-label="anchor" href="#estad%C3%ADsticos-aic-y-bic"><i class="fas fa-link"></i></a>
</h3>
<p>El criterio de información de Akaike (Akaike, 1973) está basado en la función de verosimilitud e incluye una penalización que aumenta con el número de parámetros estimados en el modelo. Premia pues, los modelos que dan un buen ajuste en términos de verosimilitud y a la vez son parsimoniosos (tienen pocos parámetros).</p>
<p>Si <span class="math inline">\(\hat{\beta}\)</span> es el estimador máximo-verosímil del modelo de dimensión <span class="math inline">\(p\)</span>, y <span class="math inline">\(l(\theta)\)</span> denota el logaritmo (neperiano) de la verosimilitud asociada con dicho modelo, el estadístico <span class="math inline">\(AIC\)</span> se define por:</p>
<p><span class="math display" id="eq:AIC">\[\begin{equation}
AIC=-2\, l(\hat{\beta})+2p.
\tag{7.13}
\end{equation}\]</span></p>
<p>Una versión del <span class="math inline">\(AIC\)</span> que tiene en cuenta también el número de datos utilizados en el ajuste, es el <em>Schwarz’s Bayesian criterion</em> (Schwarz, 1978), conocido como <span class="math inline">\(BIC\)</span>, y definido por:</p>
<p><span class="math display" id="eq:BIC">\[\begin{equation}
BIC=-2\, l(\hat{\beta})+log(n)\, p.
\tag{7.14}
\end{equation}\]</span></p>
<p>Si queremos comparar dos modelos con estos criterios, se debe seleccionar el modelo con un menor valor en estos estadísticos.</p>
</div>
<div id="selección-automática" class="section level3" number="7.4.3">
<h3>
<span class="header-section-number">7.4.3</span> Selección automática<a class="anchor" aria-label="anchor" href="#selecci%C3%B3n-autom%C3%A1tica"><i class="fas fa-link"></i></a>
</h3>
<p>Los criterios anteriores resultan de utilidad cunado queremos comparar dos modelos diferentes (“modelos en competencia”), pero pueden resultar poco prácticos si el número de modelos en competencia es muy elevado, es decir, tenemos muchas posibles variables predictoras. Por ese motivo se introducen los conocidos como procedimientos secuenciales que permiten la evaluación de muchos modelos en competencia en muy poco tiempo, utilizando cualquiera de los criterios anteriores.</p>
<p>La idea básica es partir de un modelo con cierto número de regresores, y secuencialmente moverse hacia modelos mejores (según el criterio elegido) con más o menos regresores de entre todos los observados. Una vez elegido el criterio para la selección, distinguimos básicamente entre los siguientes procedimientos secuenciales, en función de cuál es el punto (modelo) de partida y la forma de ir considerando modelos alternativos:</p>
<ul>
<li>
<strong>hacia adelante, </strong> se parte del modelo más simple y se van incluyendo una a una las variables que satisfacen el criterio de inclusión;</li>
<li>
<strong>hacia atrás, </strong> se parte del modelo más complejo y se van excluyendo una a una las variables que satisfacen el criterio de exclusión;</li>
<li>
<strong>paso a paso, </strong> se suele partir de un modelo y en cada paso se incluye o excluye la variable que satisface el criterio de inclusión/exclusión.</li>
</ul>
<p>Hay que tener en cuenta que dependiendo del tipo de modelo deberemos utilizar un tipo de procedimiento u otro. En el caso de los MRP no podemos utilizar el procedimiento hacia adelante, ya que se parte siempre del modelo con un mayor grado y se trata de identificar si dicho grado puede ser eliminado, dado que siempre tratamos de obtener el modelo más parsimonioso. En el caso de los modelos RLM no hay una preferencia con respecto al procedimiento secuencial.</p>
<p>Los procedimientos hacia adelante y hacia atrás los hemos de llevar a cabo en R de forma manual y generalmente se utiliza el test F asociado a cada paso para resolver si una variable o efecto debe entrar o salir del modelo. Para ello utilizaremos las funciones <code><a href="https://rdrr.io/r/stats/add1.html">drop1()</a></code> y <code><a href="https://rdrr.io/r/stats/add1.html">add1()</a></code>. El procedimiento paso a paso es automático y se realiza con la función <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code>.</p>
</div>
<div id="funciones-en-r" class="section level3" number="7.4.4">
<h3>
<span class="header-section-number">7.4.4</span> Funciones en R<a class="anchor" aria-label="anchor" href="#funciones-en-r"><i class="fas fa-link"></i></a>
</h3>
<p>En la librería <code>olsrr</code> dedicada exclusivamente al análisis de modelos de regresión (simple, múltiple y polinómica) se presentan diferentes funciones para los procesos de selección automática de variables utilizando el test <span class="math inline">\(F\)</span> parcial y el criterio AIC. Presentamos sólo aquellas funciones que utilizan como punto de partida el modelo saturado. Dichas funciones son:</p>
<ul>
<li>
<code>ols_step_backward_p(model)</code>: selección desde el modelo saturado mediante el test <span class="math inline">\(F\)</span>. Fijamos el parámetro <code>prem</code> igual a 0.05 para marcar el nivel de significatividad del contraste.</li>
<li>
<code>ols_step_backward_aic(model)</code>: selección desde el modelo saturado mediante AIC.</li>
</ul>
<p>Aunque estas funciones pueden mostrar todo el desarrollo de selección (al igual que la función <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code>), la ventaja principal es que puede mostrar un resumen del proceso final para estudiar el modelo final obtenido. En los ejemplos mostraremos el uso de estas funciones.</p>
</div>
<div id="ejemplos-5" class="section level3" number="7.4.5">
<h3>
<span class="header-section-number">7.4.5</span> Ejemplos<a class="anchor" aria-label="anchor" href="#ejemplos-5"><i class="fas fa-link"></i></a>
</h3>
<p>A continuación, se muestra como utilizar los criterios de selección de variables y los procedimientos secuenciales de selección en los bancos de datos que venimos trabajando en esta unidad.</p>
<div id="datos-de-bosque-2" class="section level4" number="7.4.5.1">
<h4>
<span class="header-section-number">7.4.5.1</span> Datos de Bosque<a class="anchor" aria-label="anchor" href="#datos-de-bosque-2"><i class="fas fa-link"></i></a>
</h4>
<p>Veamos como seleccionar el mejor modelo para los datos de bosque. En puntos anteriores ya hemos obtenido el modelo saturado y pudimos ver como la variable <code>dbh</code> parecía no resultar relevante para explicar el comportamiento del volumen obtenido. Proponemos un nuevo modelo sin dicha variable y comparamos ambos modelos utilizando los criterios de comparación.</p>
<p><em>Para la comparación de modelos anidados siempre deberemos empezar desde el modelo más sencillo al más complejo.</em></p>
<p>Los modelos que deseamos comparar son:
<span class="math display">\[\begin{array}{ll}
M_2: &amp; vol \sim d16 + ht\\
M_1: &amp; vol \sim dbh + d16 + ht
\end{array}\]</span></p>
<div class="sourceCode" id="cb276"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelo saturado</span>
<span class="va">M1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vol</span> <span class="op">~</span> <span class="va">dbh</span> <span class="op">+</span> <span class="va">d16</span> <span class="op">+</span> <span class="va">ht</span>, data <span class="op">=</span> <span class="va">bosque</span><span class="op">)</span>
<span class="co"># Construimos modelo sin dbh</span>
<span class="va">M2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vol</span> <span class="op">~</span> <span class="va">d16</span> <span class="op">+</span> <span class="va">ht</span>, data <span class="op">=</span> <span class="va">bosque</span><span class="op">)</span>
<span class="co"># Comparación mediante test F</span>
<span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">M2</span>, <span class="va">M1</span><span class="op">)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: vol ~ d16 + ht
## Model 2: vol ~ dbh + d16 + ht
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     17 177.36                           
## 2     16 153.30  1     24.06 2.5111 0.1326</code></pre>
<p>El test <span class="math inline">\(F\)</span> parcial resulta no significativo (p-valor = 0.1326) al comparar los modelos <span class="math inline">\(M_1\)</span> y <span class="math inline">\(M_2\)</span>, lo que implica que ambos modelos pueden ser considerados iguales. Comparamos el proceso inferencial en cada modelo, dado que al considerar el modelo más simple estamos admitiendo que <code>dbh</code> no es relevante para explicar el comportamiento del volumen.</p>
<div class="sourceCode" id="cb278"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Comparativa de modelos</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/tab_model.html">tab_model</a></span><span class="op">(</span><span class="va">M1</span>, <span class="va">M2</span>, show.ci <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table style="border-collapse:collapse; border:none;" class="table table-sm">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
vol
</th>
<th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
vol
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-108.58
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-105.90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
dbh
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.133
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
d16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
5.67
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
ht
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.69
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.68
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2">
20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2">
20
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2">
0.959 / 0.951
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2">
0.953 / 0.947
</td>
</tr>
</table></div>
<p>Se puede ver que el <span class="math inline">\(R^2\)</span> ajustado para ambos modelos es prácticamente idéntico reflejando que poseen la misma capacidad explicativa. Los modelos obtenidos muestran estimaciones de los coeficientes muy parecidos para ambos modelos. Eliminar la variable <code>dbh</code> no afecta a la capacidad explicativa del modelo, y no altera la contribución de cada predictora a la explicación de la respuesta. El modelo resultante viene dado por:
<span class="math display">\[
\widehat{\text{vol}} = -105.90 + 7.41*\text{d16} + 0.68*\text{ht} 
\]</span></p>
<p>Utilzamos ahora los criterios <span class="math inline">\(AIC\)</span> y <span class="math inline">\(BIC\)</span> para comparar ambos modelos:</p>
<div class="sourceCode" id="cb279"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">g2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/glance.html">glance</a></span><span class="op">(</span><span class="va">M2</span><span class="op">)</span>
<span class="va">g1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/glance.html">glance</a></span><span class="op">(</span><span class="va">M1</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">g1</span>, <span class="va">g2</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table class="table table-sm">
<thead><tr>
<th style="text-align:right;">
r.squared
</th>
<th style="text-align:right;">
adj.r.squared
</th>
<th style="text-align:right;">
sigma
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
logLik
</th>
<th style="text-align:right;">
AIC
</th>
<th style="text-align:right;">
BIC
</th>
<th style="text-align:right;">
deviance
</th>
<th style="text-align:right;">
df.residual
</th>
<th style="text-align:right;">
nobs
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:right;">
0.96
</td>
<td style="text-align:right;">
0.95
</td>
<td style="text-align:right;">
3.10
</td>
<td style="text-align:right;">
124.93
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
-48.75
</td>
<td style="text-align:right;">
107.49
</td>
<td style="text-align:right;">
112.47
</td>
<td style="text-align:right;">
153.30
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
20
</td>
</tr>
<tr>
<td style="text-align:right;">
0.95
</td>
<td style="text-align:right;">
0.95
</td>
<td style="text-align:right;">
3.23
</td>
<td style="text-align:right;">
170.95
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
-50.20
</td>
<td style="text-align:right;">
108.41
</td>
<td style="text-align:right;">
112.39
</td>
<td style="text-align:right;">
177.36
</td>
<td style="text-align:right;">
17
</td>
<td style="text-align:right;">
20
</td>
</tr>
</tbody>
</table></div>
<p>Si utilizamos el <span class="math inline">\(AIC\)</span> podemos concluir que el modelo preferido es <span class="math inline">\(M_2\)</span> dado que obtenemos un valor más pequeño, mientras que si usamos el <span class="math inline">\(BIC\)</span> el preferido es <span class="math inline">\(M1\)</span>. Sin embargo, dado que en ambos casos las diferencias entre ambos modelos son excesivamente pequeñas concluir que uno es mejor que otro resulta complicado y utilizamos el criterio de simplicidad. Ante modelos parecidos elegimos el menos complejo que en este caso sería el que tiene menos predictoras (modelo <span class="math inline">\(M2\)</span>).</p>
<p>Por último, veremos como utilizar el procedimiento secuencial automático por pasos para obtener el mejor modelo para este conjunto de datos. En este caso partimos del modelo saturado.</p>
<div class="sourceCode" id="cb280"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>## Start:  AIC=48.73
## vol ~ dbh + d16 + ht
## 
##        Df Sum of Sq    RSS    AIC
## &lt;none&gt;              153.30 48.733
## - dbh   1     24.06 177.36 49.649
## - ht    1    173.42 326.72 61.867
## - d16   1    213.21 366.51 64.166</code></pre>
<pre><code>## 
## Call:
## lm(formula = vol ~ dbh + d16 + ht, data = bosque)
## 
## Coefficients:
## (Intercept)          dbh          d16           ht  
##   -108.5758       1.6258       5.6714       0.6938</code></pre>
<p>El proceso de selección comienza a partir del moldeo saturado y determina para cada predictora cual sería el cambio en el <span class="math inline">\(AIC\)</span> (columna AIC) si dicha variable fuera eliminada del modelo. El modelo saturado tiene un <span class="math inline">\(AIC\)</span> de 48.733 (fila <code>&lt;none&gt;</code>), mientras que el modelo donde se elimina la variable <code>dbh</code> (fila <code>- dbh</code>) tiene un <span class="math inline">\(AIC\)</span> de 49.649. Atendiendo al criterio establecido de quedarnos con el modelo con un menor <span class="math inline">\(AIC\)</span> el modelo preferido sería el saturado. Esto contradice los resultados obtenidos con el test <span class="math inline">\(F\)</span> parcial pero es posible cuando tenemos pocos datos o los valores de <span class="math inline">\(AIC\)</span> están muy próximos.</p>
<p>Repetimos el análisis de selección automática con las funciones de la libreria <code>olsrr</code>.</p>
<div class="sourceCode" id="cb283"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_backward_p.html">ols_step_backward_p</a></span><span class="op">(</span><span class="va">fit.bosque</span>, prem <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## 
##                           Elimination Summary                            
## ------------------------------------------------------------------------
##         Variable                  Adj.                                      
## Step    Removed     R-Square    R-Square     C(p)       AIC        RMSE     
## ------------------------------------------------------------------------
##    1    dbh           0.9526      0.9471    4.5111    108.4066    3.2300    
## ------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb285"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_backward_aic.html">ols_step_backward_aic</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] "No variables have been removed from the model."</code></pre>
<p>Como se puede ver la solución es la misma que la obtenida con la función <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code>pero la forma de mostrar los resultados es mucho más simple.</p>
<p>En casos con muchas posibles predictoras puede resultar más útil compara solo los mejores modelos que podríamos obtener con todas las posibles combinaciones de predictoras. Para realizar esta tarea podemos utilizar la función <code><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_best_subset.html">ols_step_best_subset()</a></code>. Veamos su funcionamiento con este ejemplo a pesar de que el número de predictoras es pequeño, y el número de posibles modelos es reducido.</p>
<div class="sourceCode" id="cb287"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_best_subset.html">ols_step_best_subset</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>##  Best Subsets Regression 
## -------------------------
## Model Index    Predictors
## -------------------------
##      1         d16        
##      2         d16 ht     
##      3         dbh d16 ht 
## -------------------------
## 
##                                                     Subsets Regression Summary                                                    
## ----------------------------------------------------------------------------------------------------------------------------------
##                        Adj.        Pred                                                                                            
## Model    R-Square    R-Square    R-Square     C(p)        AIC        SBIC        SBC         MSEP        FPE       HSP       APC  
## ----------------------------------------------------------------------------------------------------------------------------------
##   1        0.9084      0.9033      0.8839    19.8001    119.5982    60.6857    122.5854    381.3477    20.9618    1.1210    0.1120 
##   2        0.9526      0.9471       0.933     4.5111    108.4066    52.1187    112.3895    209.5068    11.9979    0.6521    0.0641 
##   3        0.9591      0.9514      0.9242     4.0000    107.4909    52.6084    112.4696    193.1589    11.4976    0.6388    0.0614 
## ----------------------------------------------------------------------------------------------------------------------------------
## AIC: Akaike Information Criteria 
##  SBIC: Sawa's Bayesian Information Criteria 
##  SBC: Schwarz Bayesian Criteria 
##  MSEP: Estimated error of prediction, assuming multivariate normality 
##  FPE: Final Prediction Error 
##  HSP: Hocking's Sp 
##  APC: Amemiya Prediction Criteria</code></pre>
<p>Se presentan diferentes criterios para valorar el mejor modelo de entre todas las combinaciones posibles. En este caso el analista debe decidir cual de los propuestos es más adecuado. El único criterio que no se encuentra disponible es el test <span class="math inline">\(F\)</span> parcial.</p>
<p>Dado que la capacidad explicativa los dos modelos propuestos es muy similar será preferible el menos complejo. En la fase de diagnóstico ya comprobaremos si ese modelo más simple debe ser modificado o si por el contrario es adecuado para proceder con la fase de predicción.</p>
<p>Almacenamos el nuevo modelo:</p>
<div class="sourceCode" id="cb289"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelo seleccionado</span>
<span class="va">fit.bosque</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vol</span> <span class="op">~</span> <span class="va">d16</span> <span class="op">+</span> <span class="va">ht</span>, data <span class="op">=</span> <span class="va">bosque</span><span class="op">)</span></code></pre></div>
</div>
<div id="datos-de-concentración-2" class="section level4" number="7.4.5.2">
<h4>
<span class="header-section-number">7.4.5.2</span> Datos de Concentración<a class="anchor" aria-label="anchor" href="#datos-de-concentraci%C3%B3n-2"><i class="fas fa-link"></i></a>
</h4>
<p>Veamos como seleccionar el mejor modelo para los datos de concentración. En puntos anteriores ya hemos podido ver que el peso del hígado resultaba poco relevante, con lo que podríamos plantear un contraste para saber si podemos prescindir de dicha variable. Sin embargo, la forma habitual de proceder sería utilizar en primer lugar un procedimiento automático para seleccionar las predictoras y chequear posteriormente mediante un test <span class="math inline">\(F\)</span> parcial si el modelo obtenido posee la misma capacidad explicativa que el modelo saturado.</p>
<p>Planteamos el proceso secuencial:</p>
<div class="sourceCode" id="cb290"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## Start:  AIC=-93.78
## concen ~ p.cuerpo + p.higado + dosis
## 
##            Df Sum of Sq      RSS     AIC
## - p.higado  1  0.004120 0.093729 -94.924
## &lt;none&gt;                  0.089609 -93.778
## - p.cuerpo  1  0.042408 0.132017 -88.416
## - dosis     1  0.044982 0.134591 -88.049
## 
## Step:  AIC=-94.92
## concen ~ p.cuerpo + dosis
## 
##            Df Sum of Sq      RSS     AIC
## &lt;none&gt;                  0.093729 -94.924
## - p.cuerpo  1  0.039851 0.133580 -90.192
## - dosis     1  0.043929 0.137658 -89.621</code></pre>
<pre><code>## 
## Call:
## lm(formula = concen ~ p.cuerpo + dosis, data = concentracion)
## 
## Coefficients:
## (Intercept)     p.cuerpo        dosis  
##     0.28552     -0.02044      4.12533</code></pre>
<p>En la primera iteración el <span class="math inline">\(AIC\)</span> del modelo saturado es igual a -93.78 mientras que el del modelo que prescinde de <code>p.higado</code> es de -94.92. Por tanto, dicha variable se elimina del modelo que pasa a tener un <span class="math inline">\(AIC\)</span> de -94.92. En la segunda iteración la variable candidata a salir es <code>p.cuerpo</code>, pero su <span class="math inline">\(AIC\)</span> asociado es superior al del modelo actual y no se descarta.</p>
<p>Verificamos mediante el test <span class="math inline">\(F\)</span> parcial:</p>
<div class="sourceCode" id="cb293"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelo saturado</span>
<span class="va">M1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.higado</span> <span class="op">+</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span>
<span class="co"># Construimos modelo sin dbh</span>
<span class="va">M2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span>
<span class="co"># Comparación mediante test F</span>
<span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">M2</span>, <span class="va">M1</span><span class="op">)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: concen ~ p.cuerpo + dosis
## Model 2: concen ~ p.higado + p.cuerpo + dosis
##   Res.Df      RSS Df Sum of Sq      F Pr(&gt;F)
## 1     16 0.093729                           
## 2     15 0.089609  1   0.00412 0.6897 0.4193</code></pre>
<p>EL test <span class="math inline">\(F\)</span> resulta no significativo indicando que el modelo más simple tiene la misma capacidad explicativa que el más complejo. Estudiamos dicho modelo comparándolo con el saturado.</p>
<div class="sourceCode" id="cb295"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Comparativa de modelos</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/tab_model.html">tab_model</a></span><span class="op">(</span><span class="va">M1</span>, <span class="va">M2</span>, show.ci <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table style="border-collapse:collapse; border:none;" class="table table-sm">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
concen
</th>
<th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
concen
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.192
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.29
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.155
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
p higado
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.419
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
p cuerpo
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.018</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.019</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
dosis
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.18
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.015</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.13
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.015</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2">
19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2">
19
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2">
0.364 / 0.237
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2">
0.335 / 0.251
</td>
</tr>
</table></div>
<p>Podemos ver coo el <span class="math inline">\(R^2\)</span> ajustado mejora al eliminar <code>p.higado</code> y los coeficientes son prácticamente idénticos:</p>
<p><span class="math display">\[
\widehat{\text{concen}} = 0.29 - 0.02*\text{p.cuerpo} + 4.13*\text{dosis} 
\]</span></p>
<p>Utilizamos ahora las funciones específicas:</p>
<div class="sourceCode" id="cb296"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_backward_p.html">ols_step_backward_p</a></span><span class="op">(</span><span class="va">fit.concen</span>, prem <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## 
##                           Elimination Summary                            
## ------------------------------------------------------------------------
##         Variable                  Adj.                                      
## Step    Removed     R-Square    R-Square     C(p)       AIC        RMSE     
## ------------------------------------------------------------------------
##    1    p.higado      0.3347      0.2515    2.6897    -39.0043    0.0765    
## ------------------------------------------------------------------------</code></pre>
<div class="sourceCode" id="cb298"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_backward_aic.html">ols_step_backward_aic</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## 
##                    Backward Elimination Summary                   
## ----------------------------------------------------------------
## Variable        AIC       RSS     Sum Sq     R-Sq      Adj. R-Sq 
## ----------------------------------------------------------------
## Full Model    -37.858    0.090     0.051    0.36390      0.23668 
## p.higado      -39.004    0.094     0.047    0.33466      0.25149 
## ----------------------------------------------------------------</code></pre>
<p>Almacenamos el modelo resultante para la fase de diagnóstico:</p>
<div class="sourceCode" id="cb300"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit.concen</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span></code></pre></div>
</div>
<div id="datos-de-papel-2" class="section level4" number="7.4.5.3">
<h4>
<span class="header-section-number">7.4.5.3</span> Datos de Papel<a class="anchor" aria-label="anchor" href="#datos-de-papel-2"><i class="fas fa-link"></i></a>
</h4>
<p>Para el bando de datos de Papel se ha propuesto como modelo uno del tipo polinómico de grado 2. El proceso de selección en este caso se basa en comparar el modelo cuadrático frente al lineal para saber si es posible prescindir del grado 2, o si por el contrario es necesario para explicar la tensión del papel.</p>
<p>Los modelos que deseamos comparar son:
<span class="math display">\[\begin{array}{ll}
M_2: &amp; tension \sim madera\\
M_1: &amp; tension \sim madera + I(madera^2)
\end{array}\]</span></p>
<div class="sourceCode" id="cb301"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelo saturado</span>
<span class="va">M1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">tension</span> <span class="op">~</span> <span class="va">madera</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">madera</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">papel</span><span class="op">)</span>
<span class="co"># Construimos modelo sin dbh</span>
<span class="va">M2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">tension</span> <span class="op">~</span> <span class="va">madera</span>, data <span class="op">=</span> <span class="va">papel</span><span class="op">)</span>
<span class="co"># Comparación mediante test F</span>
<span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">M2</span>, <span class="va">M1</span><span class="op">)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: tension ~ madera
## Model 2: tension ~ madera + I(madera^2)
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1     17 2373.46                                  
## 2     16  312.64  1    2060.8 105.47 1.894e-08 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>El test <span class="math inline">\(F\)</span> parcial resulta significativo indicando que los modelos considerados tienen capacidades explicativas estadísticamente distintas. No podemos rechazar el modelo cuadrático frente al modelo lineal. Veamos la tabla de estimación de ambos modelos:</p>
<div class="sourceCode" id="cb303"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Comparativa de modelos</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/tab_model.html">tab_model</a></span><span class="op">(</span><span class="va">M1</span>, <span class="va">M2</span>, show.ci <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table style="border-collapse:collapse; border:none;" class="table table-sm">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
tension
</th>
<th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
tension
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-6.67
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.067
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
21.32
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
madera
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
11.76
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.77
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.014</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
madera^2
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2">
19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2">
19
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2">
0.909 / 0.897
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2">
0.305 / 0.265
</td>
</tr>
</table></div>
<p>El <span class="math inline">\(R^2\)</span> ajustado pasa del 26.5% en el modelo lineal al 89.7% en el modelo cuadrático indicando una gran mejora en la capacidad explicativa, y por tanto eligiendo este último como el modelo que debe pasar a la fase de diagnóstico.</p>
<p>Utilizamos las funciones resumen
Utilizamos ahora las funciones específicas:</p>
<div class="sourceCode" id="cb304"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_backward_p.html">ols_step_backward_p</a></span><span class="op">(</span><span class="va">fit.papel</span>, prem <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] "No variables have been removed from the model."</code></pre>
<div class="sourceCode" id="cb306"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_step_backward_aic.html">ols_step_backward_aic</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] "No variables have been removed from the model."</code></pre>
</div>
</div>
</div>
<div id="multicolinealidad" class="section level2" number="7.5">
<h2>
<span class="header-section-number">7.5</span> Multicolinealidad<a class="anchor" aria-label="anchor" href="#multicolinealidad"><i class="fas fa-link"></i></a>
</h2>
<p>La <strong>multicolinealidad</strong> es un problema relativamente frecuente en regresión lineal múltiple, y en general en análisis con varias variables explicativas, entre cuyas soluciones se halla la selección de variables. Cuando los regresores no están relacionados linealmente entre sí, se dice que son <em>ortogonales</em>. Que exista multicolinealidad significa que las columnas de <span class="math inline">\(X\)</span> no son linealmente independientes. Si existiera una dependencia lineal total entre algunas de las columnas, tendríamos que el rango de la matriz <span class="math inline">\(X'X\)</span> sería menor a <span class="math inline">\(p\)</span> y <span class="math inline">\((X'X)^{-1}\)</span> no existiría. El hecho de que haya multicolinealidad, esto es, una relación casi lineal entre algunos regresores, afecta a la estimación e interpretación de los coeficientes del modelo.</p>
<p>La multicolinealidad no es un problema de violación de hipótesis; simplemente es una situación que puede ocasionar problemas en las inferencias con el modelo de regresión. Nos ocupamos a continuación de examinar las causas de la multicolinealidad, algunos de los efectos que tiene en las inferencias, los métodos básicos para detectar el problema y algunas formas de tratarlo.</p>
<div id="causas" class="section level3" number="7.5.1">
<h3>
<span class="header-section-number">7.5.1</span> Causas<a class="anchor" aria-label="anchor" href="#causas"><i class="fas fa-link"></i></a>
</h3>
<p>Montgomery y Peck (1992) comentan que la colinealidad puede surgir por el método de recogida de datos, restricciones en el modelo o en la población, especificación y sobreformulación del modelo (consideración de más variables de las necesarias); en modelos polinómicos, por ejemplo, se pueden presentar problemas serios de multicolinealidad en la matriz de diseño <span class="math inline">\(X\)</span> cuando el rango de variación de los predictores es muy pequeño. Obviamente, modelos con más covariables son más propicios a padecer problemas de multicolinealidad.</p>
</div>
<div id="efectos" class="section level3" number="7.5.2">
<h3>
<span class="header-section-number">7.5.2</span> Efectos<a class="anchor" aria-label="anchor" href="#efectos"><i class="fas fa-link"></i></a>
</h3>
<p>Los principales efectos de la multicolinealidad son los siguientes:</p>
<ul>
<li>Una multicolinealidad fuerte produce varianzas y covarianzas grandes para los estimadores de mínimos cuadrados. Así, muestras con pequeñas diferencias podrían dar lugar a estimaciones muy diferentes de los coeficientes del modelo. Es decir, las estimaciones de los coeficientes resultan poco fiables cuando hay un problema de multicolinealidad. De hecho, dichos coeficientes vienen a explicar cómo varía la respuesta cuando varía la variable independiente en cuestión y todas las demás quedan fijas; si las variables predictoras están relacionadas entre sí, es inviable que al variar una no lo vayan a hacer las demás y en consecuencia puedan quedar fijas. La multicolinealidad reduce la efectividad del ajuste lineal si su propósito es determinar los efectos de las variables independientes.</li>
<li>A consecuencia de la gran magnitud de los errores estándar de las estimaciones, muchas de éstas no resultarían significativamente distintas de cero: los intervalos de confianza serán ‘grandes’ y por tanto, con frecuencia contendrán al cero.</li>
<li>La multicolinealidad tiende a producir estimaciones de mínimos cuadrados <span class="math inline">\(\hat{\beta}_j\)</span> muy grandes en valor absoluto.</li>
<li>Los coeficientes del ajuste con todos los predictores difieren bastante de los que se obtendrían con una regresión simple entre la respuesta y cada variable explicativa.</li>
<li>La multicolinealidad no afecta al ajuste global del modelo (medidas como la <span class="math inline">\(R^2\)</span>, etc.) y por lo tanto no afecta a la habilidad del modelo para estimar puntualmente la respuesta o la varianza residual. Sin embargo, al aumentar los errores estándar de las estimaciones de los coeficientes del modelo, también lo hacen los errores estándar de las estimaciones de la respuesta media y de la predicción de nuevas observaciones, lo que afecta a la estimación en intervalo.</li>
</ul>
</div>
<div id="diagnósticos" class="section level3" number="7.5.3">
<h3>
<span class="header-section-number">7.5.3</span> Diagnósticos<a class="anchor" aria-label="anchor" href="#diagn%C3%B3sticos"><i class="fas fa-link"></i></a>
</h3>
<p>Existen diversos diagnósticos propuestos para detectar problemas de multicolinealidad. Consideramos los más relevantes, que son:</p>
<ul>
<li>Los <strong>gráficos entre variables explicativas</strong> son útiles para estudiar la relación entre las variables explicativas y su disposición en el espacio, y con ello detectar correlaciones o identificar observaciones muy alejadas del resto de datos y que pueden influenciar notablemente la estimación. Consisten en gráficos de dispersión entre un par de covariables continuas o un par de factores (a través de sus códigos), y gráficos de cajas cuando se trata de investigar la relación entre un factor y una covariable.</li>
<li>Una medida simple de multicolinealidad consiste en la inspección de los elementos fuera de la diagonal de la matriz <span class="math inline">\(X'X\)</span>, es decir, las correlaciones simples <span class="math inline">\(r_{ij}\)</span> entre todos los regresores. Si dos regresores <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j\)</span> son casi linealmente dependientes, entonces <span class="math inline">\(|r_{ij}| \approx 1\)</span>. Sin embargo, cuando la multicolinealidad involucra a varias variables, no hay garantías de detectarla a través de las correlaciones bivariadas.</li>
<li>Puesto que uno de los efectos principales de la multicolinealidad es la inflación de la varianza y covarianza de las estimaciones, es posible calcular unos <strong>factores de inflación de la varianza</strong>, <strong>FIV</strong>, que permiten apreciar tal efecto. En concreto, la varianza de <span class="math inline">\(\hat{\beta}_j\)</span> viene estimada por <span class="math inline">\(Var(\hat{\beta}_j)=s^2 \, C_{jj}\)</span>, donde <span class="math inline">\(C_{jj}^X\)</span> son los elementos de la diagonal de la matriz <span class="math inline">\((X'X)^{-1}\)</span>, es decir,</li>
</ul>
<p><span class="math display">\[
C_{jj}^X=\frac{1}{(1-R_j^2) \, S_{x_j x_j}}, \ \ j=1, 2, \ldots, p, 
\]</span></p>
<p>con <span class="math inline">\(R_j^2\)</span> el coeficiente de determinación múltiple para la regresión de <span class="math inline">\(x_j\)</span> sobre las restantes <span class="math inline">\(p-1\)</span> covariables. Si hay una correlación muy alta entre <span class="math inline">\(x_j\)</span> y los restantes regresores, entonces <span class="math inline">\(R_j^2 \approx 1\)</span>. En particular, puesto que <span class="math inline">\(s^2\)</span> no varía ante un problema de multicolinealidad, si ésta existe, la varianza de <span class="math inline">\(\hat{\beta}_j\)</span> aumenta por un factor igual a <span class="math inline">\(1/(1-R_j^2)\)</span>, que se define como el FIV para <span class="math inline">\(x_j\)</span>:</p>
<p><span class="math display">\[
FIV_j=1/(1-R_j^2).
\]</span></p>
<p>Generalmente, valores de un FIV superiores a 10 dan indicios de un problema de multicolinealidad, si bien su magnitud depende del modelo ajustado. Lo ideal es compararlo con su equivalente en el modelo ajustado, esto es, <span class="math inline">\(1/(1-R^2)\)</span>, donde <span class="math inline">\(R^2\)</span> es el coeficiente de determinación del modelo. Los valores FIV mayores que esta cantidad implican que la relación entre las variables independientes es mayor que la que existe entre la respuesta y los predictores, y por tanto dan indicios de multicolinealidad.</p>
<ul>
<li><p>Dado que la multicolinealidad afecta a la singularidad (rango menor que <span class="math inline">\(p\)</span>) de la matriz <span class="math inline">\(X'X\)</span>, sus valores propios <span class="math inline">\(\lambda_1, \lambda_2, \ldots, \lambda_p\)</span> pueden revelar multicolinealidad en los datos. De hecho, si hay una o más dependencias casi lineales en los datos, entonces uno o más de los valores propios será pequeño.</p></li>
<li><p>En lugar de buscar valores propios pequeños, se puede optar por calcular el <strong>número de condición</strong> de <span class="math inline">\(X'X\)</span>, definido por:</p></li>
</ul>
<p><span class="math display">\[
\kappa = \lambda_{max}/\lambda_{min}, 
\]</span></p>
<p>que es una medida de dispersión en el espectro de valores propios de <span class="math inline">\(X'X\)</span>. Generalmente, si el número de condición es menor que 100, no hay problemas de multicolinealidad. Números de condición entre 100 y 1000 implican multicolinealidad moderada, y mayores que 1000 implican multicolinealidad severa.</p>
<ul>
<li>Los <strong>índices de condición</strong> de la matriz <span class="math inline">\(X'X\)</span> también son útiles para el diagnóstico de multicolinealidad y se definen por:</li>
</ul>
<p><span class="math display">\[
\kappa_j = \lambda_{max}/\lambda_j, \ \ \ j=1, \ldots, p.
\]</span></p>
<p>El número de índices de condición que son grandes (por ejemplo, <span class="math inline">\(\geq 1000\)</span>) es una medida útil del número de dependencias casi lineales en <span class="math inline">\(X'X\)</span>.</p>
<ul>
<li>Otra posibilidad de diagnóstico es a través de un análisis de componentes principales. Este tipo de análisis multivariante se plantea sobre conjuntos de variables relacionadas linealmente entre sí y tiene como finalidad la de definir un conjunto menor de nuevas variables obtenidas como combinación lineal de las originales, y que a la vez resultan ortogonales entre sí. Si el análisis de componentes principales resulta significativo, estamos reconociendo multicolinealidad.</li>
</ul>
</div>
<div id="soluciones" class="section level3" number="7.5.4">
<h3>
<span class="header-section-number">7.5.4</span> Soluciones<a class="anchor" aria-label="anchor" href="#soluciones"><i class="fas fa-link"></i></a>
</h3>
<p>Una vez detectado un problema de multicolinealidad, es recomendable intentar aliviarlo (por sus efectos). Para ello disponemos de diversos recursos, y en función del objetivo del análisis, será más aconsejable uno u otro. Básicamente podemos distinguir como objetivos esenciales:</p>
<ul>
<li>Estimar bien la respuesta media en función de un conjunto de variables explicativas, sin importar demasiado la contribución individual de cada una de esas variables.</li>
<li>Hacer un <strong>análisis de estructura</strong>, esto es, describir el efecto de las variables explicativas en la predicción de la respuesta. Las magnitudes y significatividades de los coeficientes son entonces de interés. Así, en un análisis de estructura es importante conseguir un buen modelo de ajuste para cuantificar bien la información que aportan las variables explicativas sobre la respuesta.</li>
</ul>
<p>Hay tres aproximaciones básicas como remedio a la multicolinealidad:</p>
<ul>
<li><p><strong>Selección de variables</strong> (ver Sección <strong>XX</strong>). Respecto a la selección de variables, lo ideal ante un problema de multicolinealidad es seleccionar aquellas variables predictoras que son más significativas y contienen la mayor parte de la información sobre la respuesta. Sin embargo, hay que actuar con precaución, pues los métodos automáticos de selección de variables son bastante sensibles cuando existe relación entre los regresores y no está garantizado que el modelo resultante tenga menor multicolinealidad. Por otro lado, la capacidad predictiva del modelo puede verse seriamente menguada al reducir el número de covariables consideradas, de modo que este remedio iría más indicado cuando el objetivo del análisis es el 2.</p></li>
<li><p><strong>Redefinición de variables.</strong> Otra alternativa es transformar las covariables. Para ello es importante identificar entre qué covariables hay relación, con el fin de utilizar transformaciones apropiadas. Si varias variables están relacionadas linealmente, a veces funciona considerar la más completa de ellas tal y como es, y transformaciones de las otras con cocientes o diferencias respecto de la más completa. Es decir, si <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j\)</span> están relacionadas y <span class="math inline">\(x_i\)</span> da una información más completa que <span class="math inline">\(x_j\)</span>, se puede considerar un nuevo ajuste que involucre a las variables <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j/x_i\)</span>, o bien a <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j-x_i\)</span>.
Cuando la intuición o el conocimiento de las variables no sugiere ninguna transformación concreta, una opción es llevar a cabo un <em>análisis de componentes principales</em> con el fin de obtener nuevas variables, expresables como combinación lineal de las originales, ortogonales entre sí y que contengan toda la información disponible en las primeras. En ocasiones, las componentes que resultan tienen un significado intuitivo por la forma de asimilar la información de las variables originales, y en ocasiones no, en cuyo caso se puede proceder a la realización de un análisis factorial y a la búsqueda de alguna rotación geométrica que permita llegar a variables “interpretables”.
Una vez obtenidas las componentes <span class="math inline">\(Z\)</span>, se pueden seguir dos alternativas: i) plantear una regresión de la respuesta explicada por todas las componentes principales obtenidas, o ii) ajustar un modelo de regresión sólo con las componentes más relevantes como variables predictoras (<strong>componentes principales incompletas</strong>). En el primer caso, a partir del modelo ajustado <span class="math inline">\(y=Z\gamma+\epsilon\)</span>, es posible recuperar el efecto de las variables originales sobre la respuesta sin más que deshacer el cambio. Esto no es posible para la segunda alternativa, pues las estimaciones que se consiguen están sesgadas; sin embargo, esta opción reduce la varianza de las estimaciones respecto del modelo original.</p></li>
<li><p><strong>Estimación sesgada.</strong> Si uno de los efectos de la multicolinealidad es que aumenta el error estándar de las estimaciones por mínimos cuadrados de los coeficientes del modelo, cabe la posibilidad de utilizar estimadores que, aun sesgados, produzcan estimaciones con menor error estándar y un error cuadrático medio inferior al de los estimadores de mínimos cuadrados (que son, de los insesgados, los de mínima varianza).</p></li>
</ul>
<p>Hay varios procedimientos de estimación sesgada. Las <em>componentes principales incompletas</em> es uno de ellos. La <em>regresión Ridge</em> es otro método interesante. La <strong>regresión Ridge</strong> consiste en utilizar como estimador de <span class="math inline">\(\beta\)</span>, el siguiente:</p>
<p><span class="math display">\[
\hat{\beta}_k=(X'X+kI)^{-1} X'y, 
\]</span></p>
<p>donde <span class="math inline">\(k\)</span> es una constante pequeña arbitraria.</p>
<p>Cuando todos los predictores están estandarizados, tenemos que <span class="math inline">\(X'X\)</span> es la matriz de correlaciones, con unos en la diagonal. Así, la correlación “efectiva” que se consigue ahora entre <span class="math inline">\(x_i\)</span> y <span class="math inline">\(x_j\)</span> es <span class="math inline">\(r_{ij}/(1+k)\)</span>. Es decir, todas las correlaciones se reducen artificialmente en un factor <span class="math inline">\(1/(1+k)\)</span>, reduciendo entonces la multicolinealidad. Valores grandes de <span class="math inline">\(k\)</span> reducen la multicolinealidad pero, como contraprestación, aumentan el sesgo de las estimaciones. Para determinar el valor de <span class="math inline">\(k\)</span> a utilizar, se suelen considerar gráficos en los que se representa <span class="math inline">\(k\)</span> versus las estimaciones del modelo (<em>ridge plots</em>). Para valores pequeños de <span class="math inline">\(k\)</span>, las estimaciones de los coeficientes cambian mucho, mientras que a medida que <span class="math inline">\(k\)</span> aumenta, las estimaciones parecen estabilizarse. Se dice que se consigue un valor óptimo para <span class="math inline">\(k\)</span> cuando se da dicha estabilización en las estimaciones. Este procedimiento resulta pues, algo subjetivo, pero sin embargo ha resultado efectivo en la práctica.</p>
<p>Hay otros procedimientos sesgados de estimación propuestos en la literatura que alivian el problema de la multicolinealidad.</p>
</div>
<div id="ejemplos-6" class="section level3" number="7.5.5">
<h3>
<span class="header-section-number">7.5.5</span> Ejemplos<a class="anchor" aria-label="anchor" href="#ejemplos-6"><i class="fas fa-link"></i></a>
</h3>
<p>A continuación, realizamos el estudio de multicolinealidad para los diferentes bancos de datos que hemos venido trabajando. Para el calculo de los factores de inflacción de la varianza y los números de condición utilizamos la función <code><a href="https://olsrr.rsquaredacademy.com/reference/ols_coll_diag.html">ols_coll_diag()</a></code> de la librería <code>olsrr</code>. Con ella obtenemos el <code>VIF</code> asociado con cada variable, el índice de condición asociado con cada valor propio, y la matriz de correlaciones asociada al modelo ajustado.</p>
<p>En caso de detectar multicolinealidad trataremos de corregirla con los procedimientos presentados.</p>
<div id="datos-de-bosque-3" class="section level4" number="7.5.5.1">
<h4>
<span class="header-section-number">7.5.5.1</span> Datos de bosque<a class="anchor" aria-label="anchor" href="#datos-de-bosque-3"><i class="fas fa-link"></i></a>
</h4>
<p>Para el análisis de multicolinealidad tomamos el modelo obtenido después del proceso de selección de variables de la sección anterior.</p>
<div class="sourceCode" id="cb308"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelos</span>
<span class="va">fit.bosque</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vol</span> <span class="op">~</span> <span class="va">d16</span> <span class="op">+</span> <span class="va">ht</span>, data <span class="op">=</span> <span class="va">bosque</span><span class="op">)</span>
<span class="co"># Análisis de multicolinealidad</span>
<span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_coll_diag.html">ols_coll_diag</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##   Variables Tolerance      VIF
## 1       d16  0.813726 1.228915
## 2        ht  0.813726 1.228915
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##    Eigenvalue Condition Index   intercept         d16           ht
## 1 2.991530311         1.00000 0.000270918 0.001143249 0.0002206333
## 2 0.007330472        20.20137 0.077611612 0.924370594 0.0288009800
## 3 0.001139217        51.24405 0.922117470 0.074486157 0.9709783867</code></pre>
<p>Del análisis realizado no parece detectarse multicolinealidad a través de <span class="math inline">\(VIF\)</span>, ni a través de los índices de condición. El valor de <span class="math inline">\(1/(1-R^2)\)</span> para dicho modelo es 21.28 que es superior a los valore de <span class="math inline">\(VIF\)</span> observados. Por tanto, no parece haber un problema de multicolinealidad con el modelo obtenido.</p>
</div>
<div id="datos-de-concentración-3" class="section level4" number="7.5.5.2">
<h4>
<span class="header-section-number">7.5.5.2</span> Datos de concentración<a class="anchor" aria-label="anchor" href="#datos-de-concentraci%C3%B3n-3"><i class="fas fa-link"></i></a>
</h4>
<p>En este caso analizamos el modelo saturado en primer lugar.</p>
<div class="sourceCode" id="cb310"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelos</span>
<span class="va">fit.concen</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">p.higado</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span>
<span class="co"># Análisis de multicolinealidad</span>
<span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_coll_diag.html">ols_coll_diag</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##   Variables  Tolerance       VIF
## 1  p.cuerpo 0.01919315 52.101917
## 2  p.higado 0.74868308  1.335679
## 3     dosis 0.01944498 51.427154
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##     Eigenvalue Condition Index    intercept     p.cuerpo    p.higado        dosis
## 1 3.980955e+00         1.00000 0.0005211255 1.049346e-05 0.001061756 1.138353e-05
## 2 1.307262e-02        17.45068 0.0912614776 7.180392e-04 0.963765107 8.095775e-04
## 3 5.885352e-03        26.00803 0.8549633200 4.879743e-03 0.028213823 6.508870e-03
## 4 8.720917e-05       213.65475 0.0532540769 9.943917e-01 0.006959314 9.926702e-01</code></pre>
<p>Hay dos <span class="math inline">\(VIF\)</span> que indican multicolinealidad y un número de condición por encima de 100. Probamos con el modelo obtenido en el proceso de selección de variables:</p>
<div class="sourceCode" id="cb312"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelos</span>
<span class="va">fit.concen</span><span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span>
<span class="co"># Análisis de multicolinealidad</span>
<span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_coll_diag.html">ols_coll_diag</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##   Variables  Tolerance      VIF
## 1  p.cuerpo 0.01947892 51.33755
## 2     dosis 0.01947892 51.33755
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##     Eigenvalue Condition Index    intercept     p.cuerpo        dosis
## 1 2.993933e+00         1.00000 0.0009364888 1.884523e-05 2.017998e-05
## 2 5.978794e-03        22.37764 0.9398136118 4.217372e-03 5.578232e-03
## 3 8.781609e-05       184.64349 0.0592498994 9.957638e-01 9.944016e-01</code></pre>
<p>Se siguen presentando problemas de multicolinealidad. Sin embargo, aunque esto puede parecer un problema muy grave no lo es dada la situación experimental dada. Es de esperar que la dosis suministrada este claramente asociada con el peso del sujeto, y por tanto dichas variables tienen que estar relacionadas. Aunque la multicolinealidad afecta a la precisión del modelo (en este caso es poco relevante porque nuestro ajuste es bastante malo) no es un problema con el diagnóstico del modelo. En la sección siguiente determinaremos si el modelo debe ser modificado o si por el contrario nos quedamos con el modelo obtenido tras la selección de variables.</p>
</div>
<div id="datos-de-papel-3" class="section level4" number="7.5.5.3">
<h4>
<span class="header-section-number">7.5.5.3</span> Datos de papel<a class="anchor" aria-label="anchor" href="#datos-de-papel-3"><i class="fas fa-link"></i></a>
</h4>
<p>Para este conjunto de datos es de esperar que los indicadores de multicolinealidad proporcionen resultados altos, ya que al tratarse de un MP la variable predictora es la misma.</p>
<div class="sourceCode" id="cb314"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Análisis de multicolinealidad</span>
<span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_coll_diag.html">ols_coll_diag</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<pre><code>## Tolerance and Variance Inflation Factor
## ---------------------------------------
##     Variables  Tolerance      VIF
## 1      madera 0.05840859 17.12077
## 2 I(madera^2) 0.05840859 17.12077
## 
## 
## Eigenvalue and Condition Index
## ------------------------------
##   Eigenvalue Condition Index  intercept      madera I(madera^2)
## 1  2.7005883        1.000000 0.01001057 0.001973208 0.003447858
## 2  0.2904492        3.049257 0.18853949 0.001001403 0.035409847
## 3  0.0089625       17.358596 0.80144993 0.997025390 0.961142295</code></pre>
<p>El resultado del <span class="math inline">\(VIF\)</span> muestra multicolinealidad pero como es el comportamiento natural para este tipo de modelos se decide no actuar.</p>
</div>
</div>
</div>
<div id="diagnóstico" class="section level2" number="7.6">
<h2>
<span class="header-section-number">7.6</span> Diagnóstico<a class="anchor" aria-label="anchor" href="#diagn%C3%B3stico"><i class="fas fa-link"></i></a>
</h2>
<p>Estudiamos en este punto el proceso de diagnóstico de un modelo RLM o MP de los que hemos venido estudiando hasta ahora. El diagnóstico del modelo es realmente valioso por cuanto nos permite corroborar que se cumplen (o no) cada una de las hipótesis asumidas para el ajuste del modelo y que dan credibilidad a las conclusiones que obtenemos. Este diagnóstico suele sugerir con frecuencia alguna modificación correctora del modelo propuesto y nos obliga a repetir la dinámica de análisis (modelo alternativo y selección de variables) hasta dar con una solución satisfactoria.</p>
<p>La herramienta básica para el diagnóstico del modelo es el análisis de los residuos, tanto a través de gráficos, como de tests que verifican la validez de las hipótesis asumidas en el ajuste del modelo lineal:</p>
<ul>
<li>
<span class="math inline">\(E(\epsilon_i)=0 , \ \forall i=1, \ldots, n \ \rightsquigarrow\)</span> bondad del ajuste o linealidad.</li>
<li>
<span class="math inline">\(Var(\epsilon_i)=\sigma^2, \ \forall i \ \rightsquigarrow\)</span> Varianza constante (homocedasticidad).</li>
<li>
<span class="math inline">\(\epsilon \sim N(0, \sigma^2I) \ \rightsquigarrow\)</span> Normalidad de los errores.</li>
<li>
<span class="math inline">\(Cov(\epsilon_i, \epsilon_j)=0, \forall \ i\neq j \ \rightsquigarrow\)</span> Independencia de los errores.</li>
</ul>
<p>Si encontramos indicios de violación de alguna de ellas, en ocasiones podremos resolverlas a través de las soluciones que proponemos a continuación. Tanto las herramientas de diagnóstico como las soluciones propuestas para cuando encontramos problemas, son una ampliación del análisis de residuos que ya estudiamos para el modelo de regresión lineal simple. Aunque se pueden definir diferentes tipos de residuos, aquí nos concentramos en los que son de uso habitual en el diagnóstico de modelos lineales.</p>
<div id="tipos-de-residuos" class="section level3" number="7.6.1">
<h3>
<span class="header-section-number">7.6.1</span> Tipos de Residuos<a class="anchor" aria-label="anchor" href="#tipos-de-residuos"><i class="fas fa-link"></i></a>
</h3>
<p>Presentamos diversos tipos de residuos, útiles tanto para la diagnosis del modelo como para el análisis de influencia (detección de observaciones influyentes y/o raras o anómalas). Generalmente, los procedimientos de diagnóstico del modelo basados en residuos son gráficos, si bien en ocasiones disponemos de algunos tests basados en ellos.</p>
<div id="residuos-comunes" class="section level4" number="7.6.1.1">
<h4>
<span class="header-section-number">7.6.1.1</span> Residuos comunes<a class="anchor" aria-label="anchor" href="#residuos-comunes"><i class="fas fa-link"></i></a>
</h4>
<p>Los residuos comunes del modelo lineal <span class="math inline">\(y=X\beta+\epsilon\)</span> consisten simplemente en las desviaciones entre los datos observados <span class="math inline">\(y_i\)</span> y los predichos <span class="math inline">\(\hat{y}_i\)</span>, esto es, los obtenidos de:</p>
<p><span class="math display">\[
\textbf{e}=\textbf{y}-\hat{\textbf{y}}=y-X\hat{\beta}=\textbf{y}-X\hat{\beta}=(I-X(X'X)^{-1}X')\textbf{y}
\]</span></p>
<p>cuando <span class="math inline">\(X'X\)</span> es no singular.</p>
<p>Surge así una matriz básica en la definición de los residuos, denominada matriz gorro y definida por:</p>
<p><span class="math display">\[
H=X(X'X)^{-1}X', 
\]</span></p>
<p>que tiene su importancia en la interpretación y redefinición de nuevos tipos de residuos, como veremos. A sus elementos nos referiremos como <span class="math inline">\(h_{ij}\)</span>. Esta matriz <span class="math inline">\(H\)</span> es simétrica (<span class="math inline">\(H'=H\)</span>) e idempotente (<span class="math inline">\(HH=H\)</span>), de dimensión <span class="math inline">\(n \times n\)</span> y de rango <span class="math inline">\(p=rang(X)\)</span>.</p>
<p>En términos de <span class="math inline">\(H\)</span>, los residuos <span class="math inline">\(\textbf{e}\)</span> se pueden escribir como:</p>
<p><span class="math display">\[
\textbf{e} = \textbf{y}-\hat{\textbf{y}} = (I-H) \textbf{y}, 
\]</span></p>
<p>esto es,</p>
<p><span class="math display">\[
e_i=(1-\sum_{j=1}^n h_{ij}) \, y_i=y_i-\hat{y}_i, \ \ \ i=1, \ldots, n.
\]</span></p>
<p>De esta forma se puede demostrar que la varianza de cada residuo viene dada por:
<span class="math display">\[
Var(e_i)=(1-h_{ii})\sigma^2, \ \ i=1, \ldots, n, 
\]</span></p>
<p>y la correlación entre los residuos <span class="math inline">\(e_i\)</span> y <span class="math inline">\(e_j\)</span>:</p>
<p><span class="math display">\[
Cor(e_i, e_j)=\frac{-h_{ij}}{\sqrt{(1-h_{ii})(1-h_{jj})}}.
\]</span></p>
</div>
<div id="residuos-estandarizados." class="section level4" number="7.6.1.2">
<h4>
<span class="header-section-number">7.6.1.2</span> Residuos estandarizados.<a class="anchor" aria-label="anchor" href="#residuos-estandarizados."><i class="fas fa-link"></i></a>
</h4>
<p>Son residuos de media cero y varianza aproximadamente unidad, definidos por:</p>
<p><span class="math display">\[
r_i=\frac{e_i}{\sqrt{s^2}}, \qquad i=1, \ldots, n, 
\]</span></p>
<p>donde <span class="math inline">\(s^2\)</span> es la estimación habitual de <span class="math inline">\(\sigma^2\)</span> que da el cuadrado medio residual.
Una modificación de estos ´residuos son los denominados residuos estudentizados que se interpretan de forma similar a estos. En los ejemplos introduciremos los procedimientos gráficos que podemos utilizar con este tipo de residuos para el estudio de la linealidad y homocedasticidad.</p>
<p><strong>Dado que la verificación de hipótesis se basa en los residuos del modelo, los procedimientos que utilizamos para verificarlas son los mismos a los descritos para el modelo RLS en la unidad anterior. La única diferencia es la existencia de más de una predictora.</strong></p>
</div>
</div>
<div id="linealidad" class="section level3" number="7.6.2">
<h3>
<span class="header-section-number">7.6.2</span> Linealidad<a class="anchor" aria-label="anchor" href="#linealidad"><i class="fas fa-link"></i></a>
</h3>
<p>Si hay alguna variable explicativa que no ha sido incluida en el ajuste del modelo, representarla versus los residuos ayuda a identificar algún tipo de tendencia que dicha variable pueda explicar. Si no se detecta ninguna tendencia en el gráfico de dispersión en principio no tenemos ninguna evidencia que nos sugiera incorporar dicha variable al modelo para predecir mejor la respuesta. Estos gráficos son útiles también para detectar outliers y heterocedasticidad.</p>
</div>
<div id="homocedasticidad" class="section level3" number="7.6.3">
<h3>
<span class="header-section-number">7.6.3</span> Homocedasticidad<a class="anchor" aria-label="anchor" href="#homocedasticidad"><i class="fas fa-link"></i></a>
</h3>
<p>La heterocedasticidad, que es como se denomina el problema de varianza no constante, aparece generalmente cuando el modelo está mal especificado, bien en la relación de la respuesta con los predictores, bien en la distribución de la respuesta, bien en ambas cuestiones. La violación de la hipótesis de varianza constante, <span class="math inline">\(Var(\epsilon)=\sigma^2 I\)</span>, se detecta usualmente a través del análisis gráfico de los residuos:</p>
<ul>
<li>
<strong>Gráficos de residuos versus valores ajustados</strong> <span class="math inline">\(\hat{y}_i\)</span>.- Cuando aparece alguna tendencia como una forma de embudo o un abombamiento, etc., entonces decimos que podemos tener algún problema con la violación de la hipótesis de varianza constante para los errores.</li>
<li>
<strong>Gráficos de residuos versus predictores <span class="math inline">\(\textbf{x}_j\)</span>.-</strong> Básicamente se interpretan como los gráficos de residuos versus valores ajustados <span class="math inline">\(\hat{y}_i\)</span>. Es deseable que los residuos aparezcan representados en una banda horizontal sin tendencias alrededor del cero.</li>
</ul>
<p>Hay numerosos tests en la literatura para reconocer heterocedasticidad. Unos están basados en considerar la variabilidad de los residuos que consiguen explicar las variables explicativas sospechosas de inducir heterocedasticidad. Otros tests están basados en diferenciar las observaciones en grupos de varianza constante y comparar los ajustes obtenidos respecto a la hipótesis de tener una misma varianza común:</p>
<ul>
<li>El <strong>test de Breusch-Pagan</strong>.</li>
<li>El <strong>test de Bartlett</strong> o el <strong>test de Levene</strong>.</li>
</ul>
</div>
<div id="normalidad-2" class="section level3" number="7.6.4">
<h3>
<span class="header-section-number">7.6.4</span> Normalidad<a class="anchor" aria-label="anchor" href="#normalidad-2"><i class="fas fa-link"></i></a>
</h3>
<p>La hipótesis de normalidad de los errores <span class="math inline">\(\epsilon_i\)</span> en el modelo lineal justifica la utilización de los tests <span class="math inline">\(F\)</span> y <span class="math inline">\(t\)</span> para realizar los contrastes habituales y obtener conclusiones confiables a cierto nivel de confianza <span class="math inline">\(1-\alpha\)</span> dado. En muestras pequeñas, la no normalidad de los errores es muy difícil de diagnosticar a través del análisis de los residuos, pues éstos pueden diferir notablemente de los errores aleatorios <span class="math inline">\(\epsilon_i\)</span>.</p>
<p>En muestras grandes no se esperan demasiadas diferencias entre residuos y errores, y por lo tanto hacer un diagnóstico de normalidad sobre los residuos equivale prácticamente a hacerlo sobre los errores mismos.</p>
<p>La forma habitual de diagnosticar no normalidad es a través de los <strong>gráficos qq de normalidad</strong> y de tests como el de <strong>Shapiro-Wilks</strong>, específico para normalidad, o el de bondad de ajuste de <strong>Kolmogorov-Smirnov</strong>.</p>
</div>
<div id="incorrelación" class="section level3" number="7.6.5">
<h3>
<span class="header-section-number">7.6.5</span> Incorrelación<a class="anchor" aria-label="anchor" href="#incorrelaci%C3%B3n"><i class="fas fa-link"></i></a>
</h3>
<p>Para los modelos RLM y MP asumimos que los errores observacionales están incorrelados dos a dos. Si esta hipótesis no es cierta, cabe esperar que un gráfico secuencial de los residuos manifieste alguna tendencia. Sin embargo, hay muchas formas en que los errores pueden estar correlados. De hecho, la independencia entre observaciones es una cuestión justificada básicamente por el muestreo realizado.</p>
<ul>
<li><p>Un gráfico de los residuos en función de la secuencia temporal en que se observaron los datos puede ayudar a apreciar un problema de correlación de los residuos.</p></li>
<li><p>Los gráficos de autocorrelación ayudan a detectar correlación serial, es decir, que un residuo de pende de los residuos anteriores. Dichos gráficos consisten en representar cada residuo (excepto el primero) versus el residuo anterior en la secuencia temporal sospechosa de inducir la correlación.</p></li>
</ul>
<p>Un test habitual para detectar cierto tipo de correlación serial es el <strong>test de Durbin-Watson</strong>.</p>
</div>
<div id="soluciones-a-problemas-detectados-en-el-diagnóstico-del-modelo" class="section level3" number="7.6.6">
<h3>
<span class="header-section-number">7.6.6</span> Soluciones a problemas detectados en el diagnóstico del modelo<a class="anchor" aria-label="anchor" href="#soluciones-a-problemas-detectados-en-el-diagn%C3%B3stico-del-modelo"><i class="fas fa-link"></i></a>
</h3>
<p>Las soluciones a los posibles problemas detectados en el diagnóstico son similares a las utilizadas para los modelos RLS:</p>
<ul>
<li>Propuesta de otros modelos adecuados a la distribución de la respuesta y su relación con los predictores (Modelos Lineales Generalizados que trataremos más adelante).</li>
<li>Transformar la variable respuesta (Transformaciones de Box-Cox).</li>
<li>Transformar las predictoras (Modelos de suavizado).</li>
</ul>
<p>Algunas de las soluciones, como las de transformar las predictoras mediante modelos de suavizado, tendrán una unidad especial de tratamiento ya que se tratan de modelos más generalistas que permiten ajustar muchos tipos de tendencias entre respuesta y predictoras.</p>
</div>
<div id="análisis-de-influencia-1" class="section level3" number="7.6.7">
<h3>
<span class="header-section-number">7.6.7</span> Análisis de influencia<a class="anchor" aria-label="anchor" href="#an%C3%A1lisis-de-influencia-1"><i class="fas fa-link"></i></a>
</h3>
<p>En ocasiones hay algún subconjunto de los datos que influencia desproporcionadamente el ajuste del modelo propuesto, con lo cual las estimaciones y predicciones dependen mucho de él. Es interesante siempre, localizar este tipo de datos, si existen, y evaluar su impacto en el modelo. Si estos datos influyentes son “malos” (provienen de errores en la medición, o de condiciones de experimentación diferentes, etc.) habrían de ser excluidos del ajuste; si son “buenos”, esto es, efectivamente proceden de buenas mediciones aunque raras, contendrán información sobre ciertas características relevantes a considerar en el ajuste. En todo caso, es importante localizarlos, y para ello existen una serie de procedimientos basados en diversos estadísticos que presentamos a continuación.</p>
<p>Hay diversos criterios para valorar la influencia de las observaciones en el ajuste, y en base a los cuales se proponen diversos estadísticos. Vamos a considerar tres de ellos: i) contribución a la estimación de los coeficientes; ii) influencia en la predicción y iii) influencia sobre la precisión de las estimaciones.</p>
<div id="sobre-los-coeficientes-del-modelo" class="section level4" number="7.6.7.1">
<h4>
<span class="header-section-number">7.6.7.1</span> Sobre los coeficientes del modelo<a class="anchor" aria-label="anchor" href="#sobre-los-coeficientes-del-modelo"><i class="fas fa-link"></i></a>
</h4>
<p>Se han construido diversas medidas para valorar la influencia de las observaciones en la estimación de los coeficientes del modelo. Entre ellas, las más habituales son:</p>
<p><strong>Distancia de Cook.</strong> Medida de influencia para una observación <span class="math inline">\(y_i\)</span>, basada en la distancia entre la estimación de mínimos cuadrados obtenida con las <span class="math inline">\(n\)</span> observaciones, <span class="math inline">\(\hat{\textbf{y}}=X \hat{\beta}\)</span>, y la obtenida eliminando dicha observación, <span class="math inline">\(\hat{\textbf{y}}^{(i)}\)</span>. Una formulación habitual del estadístico de Cook es:</p>
<p><span class="math display">\[
D_i=\frac{(\hat{\textbf{y}}-\hat{\textbf{y}}^{(i)})'(\hat{\textbf{y}}-\hat{\textbf{y}}^{(i)})}{p s^2}=\frac{(\hat{\beta}^{(i)}-\hat{\beta})' X'X (\hat{\beta}^{(i)}-\hat{\beta})}{p s^2}, \ \ i=1, \ldots, n, 
\]</span></p>
<p>donde <span class="math inline">\(\hat{\beta}^{(i)}\)</span> es el vector de parámetros estimados en la regresión <span class="math inline">\(\hat{\textbf{y}}^{(i)}\)</span>.</p>
<p>Los puntos con un valor grande del estadístico <span class="math inline">\(D_i\)</span> identifican observaciones tales que el hecho de incluirlas o no en el ajuste dan lugar a diferencias considerables en las estimaciones de los coeficientes. Generalmente se consideran como influyentes aquellas observaciones con un valor del estadístico <span class="math inline">\(D_i&gt;1\)</span>, pero se identifican como potencialemnte influyentes todas aquellas con <span class="math inline">\(D_i&gt;4/n\)</span>, con <span class="math inline">\(n\)</span> el tamaño de la muestra.</p>
<p><strong>DFBETAS.</strong> Estadístico que indica cuánto cambia el coeficiente estimado <span class="math inline">\(\hat{\beta}_j\)</span> en desviaciones estándar para un modelo dado cuando se excluye la <span class="math inline">\(i\)</span>-ésima observación:</p>
<p><span class="math display">\[
DFBETAS_{j, i}=\frac{\hat{\beta}_j-\hat{\beta}^{(i)}_j}{s^2_{(i)} C_{jj}^X}, \quad j=0, 1, \ldots, p; \ i=1, \ldots, n
\]</span></p>
<p>donde <span class="math inline">\(\hat{\beta}^{(i)}_j\)</span> es la j-ésima componente del vector <span class="math inline">\(\hat{\beta}_{(i)}\)</span>, y <span class="math inline">\(C_{jj}^X\)</span> es el elemento <span class="math inline">\(j\)</span> de la diagonal de <span class="math inline">\((X'X)^{-1}\)</span>.</p>
<p>De forma habitual se considera como potencialmente influyente una observación si <span class="math inline">\(|DFBETAS_{j, i}|&gt;2/\sqrt{n}\)</span>, con <span class="math inline">\(n\)</span> el tamaño muestral.</p>
</div>
<div id="influencia-sobre-las-predicciones" class="section level4" number="7.6.7.2">
<h4>
<span class="header-section-number">7.6.7.2</span> Influencia sobre las predicciones<a class="anchor" aria-label="anchor" href="#influencia-sobre-las-predicciones"><i class="fas fa-link"></i></a>
</h4>
<p>Para investigar la influencia de la <span class="math inline">\(i\)</span>-ésima observación sobre los valores predichos por el modelo utilizamos el estadístico <strong>DFFITS</strong>. Se define el estadístico DFFITS para la observación i-ésima como:</p>
<p><span class="math display">\[
DFFITS_i = \frac{\hat{y}_i-\hat{y}^{(i)}_i}{\sqrt{s^2_{(i)} h_{ii}}}, \ \ i=1, \ldots, n, 
\]</span></p>
<p>donde <span class="math inline">\(\hat{y}^{(i)}_i\)</span> es el valor predicho para <span class="math inline">\(y_i\)</span> por el modelo sin utilizar en la estimación la observación <span class="math inline">\(i\)</span>. Así, <span class="math inline">\(DFFITS_i\)</span> se puede interpretar como el número de desviaciones estándar que cambia la predicción de la <span class="math inline">\(i\)</span>-ésima respuesta cuando dicha observación es excluida del ajuste.</p>
<p>Generalmente, una observación para la que <span class="math inline">\(|DFFITS_i|&gt;2 \sqrt{p/n}\)</span> merece ser tratada con atención.</p>
</div>
<div id="influencia-sobre-la-precisión-de-las-estimaciones" class="section level4" number="7.6.7.3">
<h4>
<span class="header-section-number">7.6.7.3</span> Influencia sobre la precisión de las estimaciones<a class="anchor" aria-label="anchor" href="#influencia-sobre-la-precisi%C3%B3n-de-las-estimaciones"><i class="fas fa-link"></i></a>
</h4>
<p>Los diagnósticos vistos hasta ahora cuantifican de algún modo el efecto de las observaciones en las estimaciones. Sin embargo, no proporcionan información alguna sobre la precisión conjunta del ajuste. La precisión de la estimación de <span class="math inline">\(\hat{\beta}\)</span> se puede medir en función del estadístico <span class="math inline">\(\textsf{COVRATIO}\)</span>. Si <span class="math inline">\(COVRATIO_i&lt;1\)</span>, excluir la <span class="math inline">\(i\)</span>-ésima observación proporciona un ajuste más preciso; si <span class="math inline">\(COVRATIO_i&gt;1\)</span>, la <span class="math inline">\(i\)</span>-ésima observación mejora la precisión de la estimación. En este manual no utilizaremos este criterio y nos centraremos en los puntos anteriores</p>
</div>
</div>
<div id="funciones-para-diagnóstico-e-influencia" class="section level3" number="7.6.8">
<h3>
<span class="header-section-number">7.6.8</span> Funciones para diagnóstico e influencia<a class="anchor" aria-label="anchor" href="#funciones-para-diagn%C3%B3stico-e-influencia"><i class="fas fa-link"></i></a>
</h3>
<p>EN la unidad anterior mostramos como realizar los gráficos y test de diagnóstico para un modelo RLS. Esos gráficos se pueden utilizar también en los modelos tratados en esta unidad, pero además se muestran las funciones de la librería <code>olsrr</code> que pueden ser utilizadas para esta tarea. Concretamente:</p>
<ul>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_stand.html">ols_plot_resid_stand()</a></code>: gráfico secuencial de residuos estandarizados.</li>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_stud.html">ols_plot_resid_stud()</a></code>: gráfico secuencial de residuos estudentizados.</li>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_stud_fit.html">ols_plot_resid_stud_fit()</a></code>: residuos estudentizados vs valores ajustados.</li>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_qq.html">ols_plot_resid_qq()</a></code>: gráfico qq de normalidad.</li>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_normality.html">ols_test_normality()</a></code>: tests de normalidad.</li>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html">ols_test_breusch_pagan()</a></code>: Test de Bresuch-Pagan.</li>
</ul>
<p>Aunque la función por excelencia para obtener las medidas de influencia es <code><a href="https://rdrr.io/r/stats/influence.measures.html">influence.measures()</a></code>, la librería <code>olsrr</code> presenta diversas funciones para este análisis con la ventaja de proporcionar herramientas gráficas y valores de detección, que permiten visualizar de forma rápida las posibles observaciones influyentes. Dichas funciones son:</p>
<ul>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_cooksd_chart.html">ols_plot_cooksd_chart()</a></code>: proporciona la distancia de Cook.</li>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dfbetas.html">ols_plot_dfbetas()</a></code>: proporciona los <span class="math inline">\(DFBETAS\)</span>.</li>
<li>
<code><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dffits.html">ols_plot_dffits()</a></code>: proporciona <span class="math inline">\(DFFITS\)</span>.</li>
</ul>
</div>
<div id="ejemplos-7" class="section level3" number="7.6.9">
<h3>
<span class="header-section-number">7.6.9</span> Ejemplos<a class="anchor" aria-label="anchor" href="#ejemplos-7"><i class="fas fa-link"></i></a>
</h3>
<p>Realizamos el diagnóstico y análisis de influencia de los modelos ajustados, tras el proceso de selección de variables.</p>
<div id="datos-de-bosque-4" class="section level4" number="7.6.9.1">
<h4>
<span class="header-section-number">7.6.9.1</span> Datos de Bosque<a class="anchor" aria-label="anchor" href="#datos-de-bosque-4"><i class="fas fa-link"></i></a>
</h4>
<p>En primer lugar, ajustamos el modelo correspondiente y obtenemos los valores de diagnóstico.</p>
<div class="sourceCode" id="cb316"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelos</span>
<span class="va">fit.bosque</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">vol</span> <span class="op">~</span> <span class="va">d16</span> <span class="op">+</span> <span class="va">ht</span>, data <span class="op">=</span> <span class="va">bosque</span><span class="op">)</span>
<span class="co"># Valores de diagnóstico</span>
<span class="va">diag.bosque</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/fortify.html">fortify</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<p>Estudiamos los gráficos de diagnóstico para detectar residuos grandes (gráfico secuencial de residuos), linealidad y homocedasticidad (gráfico de residuos estandarizados versus valores ajustados), y normalidad (gráfico qq).</p>
<div class="sourceCode" id="cb317"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_stand.html">ols_plot_resid_stand</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm032-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb318"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">diag.bosque</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">.fitted</span>, y <span class="op">=</span> <span class="va">.stdresid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm032-2.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb319"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_qq.html">ols_plot_resid_qq</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm032-3.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb320"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/acf.html">acf</a></span><span class="op">(</span><span class="va">diag.bosque</span><span class="op">$</span><span class="va">.stdresid</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm032-4.png" width="95%" style="display: block; margin: auto;"></div>
<p>El gráfico de secuencia de los residuos indica que la observación 18 es potencialemente una observación anómala. Cuando realizamos el análisis de influencia deberemos verificar esta situación para considerar la posible eliminación de esta observación.
El gráfico de residuos versus valores ajustados no muestra ningún tipo de tendencia (linealidad) ni comportamientos extraños que permitan pensar que se incumple la hipótesis de varianza constante.
El gráfico de normalidad también muestra un comportamiento adecuado teniendo en cuenta que el tamaño muestral es muy pequeño.
El gráfico de autocorelación no muestra dependencia entre los residuos, indicando que se cumple la hipótesis de independencia.</p>
<p>Dado que no se ha detectado falta de linealidad entre residuos y valores ajustados no es necesario realizar el gráfico de residuos versus predictoras. Sin embargo, los mostramos aquí para ver el código necesario.</p>
<div class="sourceCode" id="cb321"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">diag.bosque</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">ht</span>, y <span class="op">=</span> <span class="va">.stdresid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm033-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb322"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">diag.bosque</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">d16</span>, y <span class="op">=</span> <span class="va">.stdresid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm033-2.png" width="95%" style="display: block; margin: auto;"></div>
<p>Como era de esperar los gráficos no muestran ningún tipo de tendencia.</p>
<p>Realizamos ahora los tests necesarios para verificar las hipótesis de normalidad, homocedasticidad, e independencia.</p>
<div class="sourceCode" id="cb323"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_normality.html">ols_test_normality</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>## -----------------------------------------------
##        Test             Statistic       pvalue  
## -----------------------------------------------
## Shapiro-Wilk              0.9281         0.1420 
## Kolmogorov-Smirnov        0.1544         0.6712 
## Cramer-von Mises          1.6812         0.0000 
## Anderson-Darling          0.5362         0.1485 
## -----------------------------------------------</code></pre>
<div class="sourceCode" id="cb325"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html">ols_test_breusch_pagan</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>## 
##  Breusch Pagan Test for Heteroskedasticity
##  -----------------------------------------
##  Ho: the variance is constant            
##  Ha: the variance is not constant        
## 
##              Data               
##  -------------------------------
##  Response : vol 
##  Variables: fitted values of vol 
## 
##         Test Summary         
##  ----------------------------
##  DF            =    1 
##  Chi2          =    0.8615473 
##  Prob &gt; Chi2   =    0.353306</code></pre>
<div class="sourceCode" id="cb327"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/durbinWatsonTest.html">durbinWatsonTest</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1       0.1645488      1.487166   0.158
##  Alternative hypothesis: rho != 0</code></pre>
<p>Todos los tests resultan no significativos indicando que se cumplen las hipótesis del modelo. Para la hipótesis de normalidad nos debemos fijar en los resultados de Kolmogorov-Smirnov que tiene un mejor comportamiento, desde el punto de vista estadístico, que Shapiro-Wilk. En caso de discrepancias entre ellos nos debemos quedar con Kolmmogorov-Smirnov.</p>
<p>A pesar de que se cumplen las hipótesis del modelo, obtenemos las medidas de influencia asociadas con el modelo ajustado:</p>
<div class="sourceCode" id="cb329"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_cooksd_chart.html">ols_plot_cooksd_chart</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm035-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb330"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dfbetas.html">ols_plot_dfbetas</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm035-2.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb331"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dffits.html">ols_plot_dffits</a></span><span class="op">(</span><span class="va">fit.bosque</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm035-3.png" width="95%" style="display: block; margin: auto;"></div>
<p>La distancia de Cook muestra dos observaciones (1 y 20) como potencialmente influyentes utilizando el punto de corte más restrictivo. Si utilizamos el punto de corte estándar que determina como influyente a los que tienen una distancia de Cook mayor que 1, ninguna de ellas sería clasificada como influyente.</p>
<p>EL resto de medidas de influencia siguen mostrando a las observaciones 1 y 20 como potencialmente influyentes, pero dado que se cumplen las hipótesis del modelo no nos planteamos la eliminación de dichas observaciones. Además, con tamaños de muestras tan pequeños sólo nos planteamos su eliminación si es la única solución para que se cumplan las hipótesis del modelo.</p>
</div>
<div id="datos-de-concentración-4" class="section level4" number="7.6.9.2">
<h4>
<span class="header-section-number">7.6.9.2</span> Datos de Concentración<a class="anchor" aria-label="anchor" href="#datos-de-concentraci%C3%B3n-4"><i class="fas fa-link"></i></a>
</h4>
<p>Ajustamos el modelo y obtenemos los valores de diagnóstico.</p>
<div class="sourceCode" id="cb332"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelos</span>
<span class="va">fit.concen</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span>
<span class="co"># Valores de diagnóstico</span>
<span class="va">diag.concen</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/fortify.html">fortify</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<p>Estudiamos los gráficos de diagnóstico para detectar residuos grandes (gráfico secuencial de residuos), linealidad y homocedasticidad (gráfico de residuos estandarizados versus valores ajustados), y normalidad (gráfico qq).</p>
<div class="sourceCode" id="cb333"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_stand.html">ols_plot_resid_stand</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm037-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb334"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">diag.concen</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">.fitted</span>, y <span class="op">=</span> <span class="va">.stdresid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm037-2.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb335"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_qq.html">ols_plot_resid_qq</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm037-3.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb336"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/acf.html">acf</a></span><span class="op">(</span><span class="va">diag.concen</span><span class="op">$</span><span class="va">.stdresid</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm037-4.png" width="95%" style="display: block; margin: auto;"></div>
<p>Aunque todos los gráficos parecen mostrar comportamientos adecuados, el gráfico de residuos versus ajustados muestra un punto alejado (valor ajustado alto) del resto lo que podría indicar que debemos tratar ese valor como anómalo y considerar su eliminación del banco de datos. Antes de tomar una decisión revisamos toda la batería de gráficos y tests de diagnóstico e influencia.</p>
<div class="sourceCode" id="cb337"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">diag.concen</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">p.cuerpo</span>, y <span class="op">=</span> <span class="va">.stdresid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm038-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb338"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">diag.concen</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">dosis</span>, y <span class="op">=</span> <span class="va">.stdresid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm038-2.png" width="95%" style="display: block; margin: auto;"></div>
<p>En los gráficos de residuos versus predictoras no se observan comportamientos anómalos.</p>
<p>Realizamos ahora los tests necesarios para verificar las hipótesis de normalidad, homocedasticidad, e independencia.</p>
<div class="sourceCode" id="cb339"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_normality.html">ols_test_normality</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## -----------------------------------------------
##        Test             Statistic       pvalue  
## -----------------------------------------------
## Shapiro-Wilk              0.9544         0.4672 
## Kolmogorov-Smirnov        0.1414         0.7919 
## Cramer-von Mises          5.4464         0.0000 
## Anderson-Darling          0.3769         0.3742 
## -----------------------------------------------</code></pre>
<div class="sourceCode" id="cb341"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html">ols_test_breusch_pagan</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## 
##  Breusch Pagan Test for Heteroskedasticity
##  -----------------------------------------
##  Ho: the variance is constant            
##  Ha: the variance is not constant        
## 
##                Data                
##  ----------------------------------
##  Response : concen 
##  Variables: fitted values of concen 
## 
##         Test Summary          
##  -----------------------------
##  DF            =    1 
##  Chi2          =    0.05255342 
##  Prob &gt; Chi2   =    0.8186782</code></pre>
<div class="sourceCode" id="cb343"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/durbinWatsonTest.html">durbinWatsonTest</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1      -0.0227244      1.762427   0.558
##  Alternative hypothesis: rho != 0</code></pre>
<p>Todos los tests resultan no significativos indicando que se cumplen las hipótesis del modelo.</p>
<p>En último lugar realizamos el análisis de influencia:</p>
<div class="sourceCode" id="cb345"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_cooksd_chart.html">ols_plot_cooksd_chart</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm040-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb346"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dfbetas.html">ols_plot_dfbetas</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm040-2.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb347"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dffits.html">ols_plot_dffits</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm040-3.png" width="95%" style="display: block; margin: auto;"></div>
<p>La distancia de Cook muestra que la observación en la posición 3 es claramente influyente. De hecho, también es influyente en los coeficientes del modelo, y en el valor ajustado. Pasamos a eliminar dicha observación y a ajustar un nuevo modelo. Comenzaremos con el modelo saturado e iremos completando todo el análisis.</p>
<p>Creamos el nuevo banco de datos y ajustamos el nuevo modelo:</p>
<div class="sourceCode" id="cb348"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Datos sin observación 3</span>
<span class="va">concentracion</span> <span class="op">&lt;-</span> <span class="va">concentracion</span><span class="op">[</span><span class="op">-</span><span class="fl">3</span>, <span class="op">]</span>
<span class="co"># Ajuste del modelo</span>
<span class="va">fit.concen</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">concen</span> <span class="op">~</span> <span class="va">p.cuerpo</span> <span class="op">+</span> <span class="va">dosis</span>, data <span class="op">=</span> <span class="va">concentracion</span><span class="op">)</span>
<span class="co"># Modelo ajustado</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/tab_model.html">tab_model</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<div class="inline-table"><table style="border-collapse:collapse; border:none;" class="table table-sm">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
concen
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.33
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.08 – 0.75
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.110
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
p cuerpo
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.04 – 0.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.797
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
dosis
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.88
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-6.37 – 8.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.800
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
18
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.005 / -0.128
</td>
</tr>
</table></div>
<div class="sourceCode" id="cb349"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Bondad del ajuste</span>
<span class="fu"><a href="https://generics.r-lib.org/reference/glance.html">glance</a></span><span class="op">(</span><span class="va">fit.concen</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC deviance df.residual
##       &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1   0.00483        -0.128 0.0762    0.0364   0.964     2   22.4 -36.9 -33.3   0.0871          15
## # … with 1 more variable: nobs &lt;int&gt;</code></pre>
<p>EL test <span class="math inline">\(F\)</span> de la regresión nos indica que la variables predictoras no están relacionadas con la respuesta (p-valor &gt; 0.05), con lo que no tendría sentido seguir trabajando con este modelo y la conclusión obtenida es que no hemos podido obtener una relación entre concentración y peso cuerpo, peso del hígado, y dosis.</p>
<p>El efecto de eliminar una observación (a pesar de que se cumplen las hipótesis del modelo), es que la débil relación que habíamos establecido entre concentración frente a peso del cuerpo y dosis resulta inexistente. En este caso debe ser el investigador el que decida entre las dos opciones:</p>
<ul>
<li>Quedarse con un modelo malo (sin quitar la observación influyente) que verifica las hipótesis.</li>
<li>Concluir que no existe relación entre respuesta y predictoras, desechando el experimento realizado.</li>
</ul>
</div>
<div id="datos-de-papel-4" class="section level4" number="7.6.9.3">
<h4>
<span class="header-section-number">7.6.9.3</span> Datos de Papel<a class="anchor" aria-label="anchor" href="#datos-de-papel-4"><i class="fas fa-link"></i></a>
</h4>
<p>Ajustamos el modelo y obtenemos los valores de diagnóstico.</p>
<div class="sourceCode" id="cb351"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Modelos</span>
<span class="va">fit.papel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">tension</span> <span class="op">~</span> <span class="va">madera</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span><span class="op">(</span><span class="va">madera</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">papel</span><span class="op">)</span>
<span class="co"># Valores de diagnóstico</span>
<span class="va">diag.papel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/fortify.html">fortify</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<p>Estudiamos los gráficos de diagnóstico para detectar residuos grandes (gráfico secuencial de residuos), linealidad y homocedasticidad (gráfico de residuos estandarizados versus valores ajustados), y normalidad (gráfico qq).</p>
<div class="sourceCode" id="cb352"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_stand.html">ols_plot_resid_stand</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm043-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb353"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">diag.papel</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">.fitted</span>, y <span class="op">=</span> <span class="va">.stdresid</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> 
 <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"lm"</span>, se <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm043-2.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb354"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_resid_qq.html">ols_plot_resid_qq</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm043-3.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb355"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/acf.html">acf</a></span><span class="op">(</span><span class="va">diag.papel</span><span class="op">$</span><span class="va">.stdresid</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm043-4.png" width="95%" style="display: block; margin: auto;"></div>
<p>No se observan residuos excesivamente grandes, ni comportamientos anómalos pero si cierta autocorrelación en los residuos debido a la propia estructura del modelo polinómico considerado. Realizamos los tests de diagnóstico:</p>
<div class="sourceCode" id="cb356"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_normality.html">ols_test_normality</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<pre><code>## -----------------------------------------------
##        Test             Statistic       pvalue  
## -----------------------------------------------
## Shapiro-Wilk              0.9113         0.0783 
## Kolmogorov-Smirnov        0.198          0.3942 
## Cramer-von Mises          1.5965          1e-04 
## Anderson-Darling          0.6399         0.0806 
## -----------------------------------------------</code></pre>
<div class="sourceCode" id="cb358"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_test_breusch_pagan.html">ols_test_breusch_pagan</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<pre><code>## 
##  Breusch Pagan Test for Heteroskedasticity
##  -----------------------------------------
##  Ho: the variance is constant            
##  Ha: the variance is not constant        
## 
##                Data                 
##  -----------------------------------
##  Response : tension 
##  Variables: fitted values of tension 
## 
##         Test Summary         
##  ----------------------------
##  DF            =    1 
##  Chi2          =    0.2755593 
##  Prob &gt; Chi2   =    0.5996267</code></pre>
<div class="sourceCode" id="cb360"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">car</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/car/man/durbinWatsonTest.html">durbinWatsonTest</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<pre><code>##  lag Autocorrelation D-W Statistic p-value
##    1       0.6040252     0.6974667       0
##  Alternative hypothesis: rho != 0</code></pre>
<p>Se verifican las hipótesis de homocedasticidad y normalidad, y como era de espera no se cumple la hipótesis de incorrrelación. Dado que este incumplimiento se debe a la propia estructura del modelo no tendremos en cuenta este resultado par concluir sobre este modelo.</p>
<p>En último lugar realizamos el análisis de influencia:</p>
<div class="sourceCode" id="cb362"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_cooksd_chart.html">ols_plot_cooksd_chart</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm045-1.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb363"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dfbetas.html">ols_plot_dfbetas</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm045-2.png" width="95%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb364"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://olsrr.rsquaredacademy.com/reference/ols_plot_dffits.html">ols_plot_dffits</a></span><span class="op">(</span><span class="va">fit.papel</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm045-3.png" width="95%" style="display: block; margin: auto;"></div>
<p>Tenemos dos observaciones (18 y 19) que se detectan como potencialmente influyentes (distancia de Cook) y que podrían ser consideradas para su eliminación. Como el modelo tiene un buen ajuste y cumple con las hipótesis consideramos el modelo como válido.</p>
</div>
</div>
</div>
<div id="predicción" class="section level2" number="7.7">
<h2>
<span class="header-section-number">7.7</span> Predicción<a class="anchor" aria-label="anchor" href="#predicci%C3%B3n"><i class="fas fa-link"></i></a>
</h2>
<p>El proceso de predicción en este tipo de modelos es similar al de los modelos de regresión lineal simple. Si <span class="math inline">\(X_0 \in \mathbb{R}^p\)</span> representa un vector fijo de valores de las variables explicativas contenidas en la matriz de diseño <span class="math inline">\(X\)</span>, podemos predecir la respuesta <span class="math inline">\(y\)</span> en <span class="math inline">\(X_0\)</span> a través del modelo ajustado con</p>
<p><span class="math display">\[
\hat{y}=X_0 \hat{\beta}, 
\]</span>
pero el error asociado a la estimación depende de la situación que estemos prediciendo:</p>
<div id="estimación-de-la-respuesta-media." class="section level3" number="7.7.1">
<h3>
<span class="header-section-number">7.7.1</span> Estimación de la respuesta media.<a class="anchor" aria-label="anchor" href="#estimaci%C3%B3n-de-la-respuesta-media."><i class="fas fa-link"></i></a>
</h3>
<p>La varianza asociada a dicha estimación viene dada por:
<span class="math display">\[
Var[\hat{E}(y|X_0)]=\sigma^2 X_0(X'X)^{-1}X_0'.
\]</span></p>
<p>Un intervalo de confianza a nivel <span class="math inline">\(1-\alpha\)</span> está basado en la distribución <span class="math inline">\(t-Student\)</span>:</p>
<p><span class="math display">\[
\hat{y}_{X_0} \pm
t_{(n-p, 1-\alpha/2)} \ \sqrt{s^2 X_0(X'X)^{-1}X_0'}, 
\]</span></p>
<p>siendo <span class="math inline">\(t_{(n-p, 1-\alpha/2)}\)</span> el cuantil <span class="math inline">\(1-\alpha/2\)</span> de una distribución <span class="math inline">\(t-Student\)</span> con <span class="math inline">\(n-p\)</span> grados de libertad, con <span class="math inline">\(p\)</span> el número de coeficientes en el modelo y <span class="math inline">\(n\)</span> el número de datos.</p>
</div>
<div id="predicción-de-nuevas-observaciones." class="section level3" number="7.7.2">
<h3>
<span class="header-section-number">7.7.2</span> Predicción de nuevas observaciones.<a class="anchor" aria-label="anchor" href="#predicci%C3%B3n-de-nuevas-observaciones."><i class="fas fa-link"></i></a>
</h3>
<p>La predicción de la respuesta <span class="math inline">\(y\)</span> para un determinado valor <span class="math inline">\(X_0\)</span> de las variables explicativas involucra más incertidumbre que la estimación de un promedio. En este caso, la varianza asociada a la predicción es:</p>
<p><span class="math display">\[
Var(\hat{y}|X_0)=\sigma^2 (1+ X_0(X'X)^{-1}X_0').
\]</span></p>
<p>Un intervalo de confianza a nivel <span class="math inline">\(1-\alpha\)</span> para dicha predicción viene dado por:</p>
<p><span class="math display">\[
\hat{y}_{X_0} \pm t_{(n-p, 1-\alpha/2)} \ \sqrt{s^2 \ (1+X_0'(X'X)^{-1}X_0)}.
\]</span></p>
</div>
<div id="ejemplos-8" class="section level3" number="7.7.3">
<h3>
<span class="header-section-number">7.7.3</span> Ejemplos<a class="anchor" aria-label="anchor" href="#ejemplos-8"><i class="fas fa-link"></i></a>
</h3>
<p>Obtenemos únicamente la predicción de la respuesta media para ciertos valores de las predictoras y los gráficos de predicción marginales.</p>
<div id="datos-de-bosque-5" class="section level4" number="7.7.3.1">
<h4>
<span class="header-section-number">7.7.3.1</span> Datos de bosque<a class="anchor" aria-label="anchor" href="#datos-de-bosque-5"><i class="fas fa-link"></i></a>
</h4>
<p>Estamos interesados en conocer el volumen de madera que podemos obtener para las combinaciones de <code>d16</code> y <code>ht</code> dadas por (10, 90), (12, 95), (14, 100) y (16, 105).</p>
<div class="sourceCode" id="cb365"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># cargamos datos de predicción</span>
<span class="va">newpred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>d16 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">12</span>, <span class="fl">14</span>, <span class="fl">16</span><span class="op">)</span>, 
                      ht <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">90</span>, <span class="fl">95</span>, <span class="fl">100</span>, <span class="fl">105</span><span class="op">)</span><span class="op">)</span>
<span class="co"># Predicción para la media de la respuesta</span>
<span class="co"># Opción interval = "confidence" </span>
<span class="va">newdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">newpred</span>, 
           <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit.bosque</span>, <span class="va">newpred</span>, interval <span class="op">=</span> <span class="st">"confidence"</span><span class="op">)</span><span class="op">)</span> 
<span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">newdata</span>, <span class="fl">2</span><span class="op">)</span></code></pre></div>
<pre><code>##   d16  ht   fit   lwr   upr
## 1  10  90 29.11 25.03 33.20
## 2  12  95 47.32 44.83 49.82
## 3  14 100 65.53 63.35 67.71
## 4  16 105 83.74 80.24 87.24</code></pre>
<p>Veamos ahora las predicciones marginales de cada variable:</p>
<div class="sourceCode" id="cb367"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.bosque</span>, <span class="st">"pred"</span>, 
        ci.lvl <span class="op">=</span> <span class="fl">0.95</span>, 
        show.data <span class="op">=</span> <span class="cn">TRUE</span>, 
        title <span class="op">=</span> <span class="st">" "</span><span class="op">)</span></code></pre></div>
<pre><code>## $d16</code></pre>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm047-1.png" width="95%" style="display: block; margin: auto;"></div>
<pre><code>## 
## $ht</code></pre>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm047-2.png" width="95%" style="display: block; margin: auto;"></div>
</div>
<div id="datos-de-papel-5" class="section level4" number="7.7.3.2">
<h4>
<span class="header-section-number">7.7.3.2</span> Datos de papel<a class="anchor" aria-label="anchor" href="#datos-de-papel-5"><i class="fas fa-link"></i></a>
</h4>
<p>Estamos interesados en conocer la tensión del papel para los contenidos de madera dados por 4, 8, y 12.</p>
<div class="sourceCode" id="cb370"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># cargamos datos de predicción</span>
<span class="va">newpred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>madera <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">8</span>, <span class="fl">12</span><span class="op">)</span><span class="op">)</span>
<span class="co"># Predicción para la media de la respuesta</span>
<span class="co"># Opción interval = "confidence" </span>
<span class="va">newdata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">newpred</span>, 
           <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit.papel</span>, <span class="va">newpred</span>, interval <span class="op">=</span> <span class="st">"confidence"</span><span class="op">)</span><span class="op">)</span> 
<span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">newdata</span>, <span class="fl">2</span><span class="op">)</span></code></pre></div>
<pre><code>##   madera   fit   lwr   upr
## 1      4 30.23 27.48 32.98
## 2      8 46.83 43.63 50.03
## 3     12 43.12 39.87 46.37</code></pre>
<p>Veamos ahora las predicciones marginales de cada variable:</p>
<div class="sourceCode" id="cb372"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Gráfico del ajuste</span>
<span class="fu"><a href="https://strengejacke.github.io/sjPlot/reference/plot_model.html">plot_model</a></span><span class="op">(</span><span class="va">fit.papel</span>, <span class="st">"pred"</span>, 
        ci.lvl <span class="op">=</span> <span class="fl">0.95</span>, 
        show.data <span class="op">=</span> <span class="cn">TRUE</span>, 
        axis.title <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Contenido madera"</span>, <span class="st">"Tensión"</span><span class="op">)</span>, 
        title <span class="op">=</span> <span class="st">" "</span><span class="op">)</span></code></pre></div>
<pre><code>## $madera</code></pre>
<div class="inline-figure"><img src="18-lmRLM_files/figure-html/rlm049-1.png" width="95%" style="display: block; margin: auto;"></div>
</div>
</div>
</div>
<div id="ejercicios" class="section level2" number="7.8">
<h2>
<span class="header-section-number">7.8</span> Ejercicios<a class="anchor" aria-label="anchor" href="#ejercicios"><i class="fas fa-link"></i></a>
</h2>
<p>A continuación, se presenta una colección de ejercicios referidos a los modelos de regresión. Los pasos a seguir para la obtención del modelo son los que hemos ido desarrollando: representación gráfica y propuesta de modelo, ajuste, bondad de ajuste, diagnóstico y predicción. En caso de encontrar problemas con el diagnóstico se deberá proponer un nuevo modelo alternativo.</p>
<p><strong>Ejercicio 1.</strong> Se propone a una empresa que fabrica vasos de cristal un nuevo proceso de control de calidad. Hasta ahora la empresa seleccionaba una caja de vasos al final de la fabricación y observaba si había alguno roto. Esto provocaba un gran gasto ya que en caso de encontrar algún defecto la caja se desembala y los vasos vuelven a la cadena de embalaje. Ahora se propone seleccionar vasos antes de embalar y determinar así el porcentaje de defectos. Se desea saber si ambos porcentajes están relacionados. Los datos aparecen a continuación:</p>
<div class="sourceCode" id="cb374"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># carga de datos</span>
<span class="va">cajas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3.0</span>, <span class="fl">3.1</span>, <span class="fl">3.0</span>, <span class="fl">3.6</span>, <span class="fl">3.8</span>, <span class="fl">2.7</span>, <span class="fl">3.1</span>, <span class="fl">2.7</span>, <span class="fl">2.7</span>, <span class="fl">3.3</span>, <span class="fl">3.2</span>, <span class="fl">2.1</span>, <span class="fl">3.0</span>, <span class="fl">2.6</span><span class="op">)</span>
<span class="va">vasos</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3.1</span>, <span class="fl">3.9</span>, <span class="fl">3.4</span>, <span class="fl">4.0</span>, <span class="fl">3.6</span>, <span class="fl">3.6</span>, <span class="fl">3.1</span>, <span class="fl">3.6</span>, <span class="fl">2.9</span>, <span class="fl">3.6</span>, <span class="fl">4.1</span>, <span class="fl">2.6</span>, <span class="fl">3.1</span>, <span class="fl">2.8</span><span class="op">)</span>
<span class="va">ejer01</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">cajas</span>, <span class="va">vasos</span><span class="op">)</span></code></pre></div>
<p><strong>Ejercicio 2.</strong> En 1929 Edwin Hubble investiga la relación entre la distancia (en megaparsecs. 1 parsec=3.26 años luz) de una galaxia a la tierra y la velocidad (en Km/sg) con la cual parece retroceder. Observo que las galaxias aparecen alejarse de nosotros no importa cual sea la dirección en que miremos. Se piensa de hecho que esto es el resultado del ”Big Bang”. Hubble esperaba aportar conocimiento sobre la formación del universo y sobre cual podría ser su evolución en el futuro. Los datos que recogió incluyen las distancias de la tierra a 24 galaxias, así como sus correspondientes velocidades de retroceso. El objetivo principal del estudio que Hubble llevo a cabo era determinar la edad del universo, y para ello establece lo que se conoce hasta ahora como la ley de Hubble:
<span class="math display">\[V = H_0*D\]</span>
donde <span class="math inline">\(V\)</span> es la velocidad, <span class="math inline">\(D\)</span> es la distancia, y <span class="math inline">\(H_0\)</span> es la constante de Hubble.</p>
<div class="sourceCode" id="cb375"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">distancia</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.032</span>, <span class="fl">.034</span>, <span class="fl">.214</span>, <span class="fl">.263</span>, <span class="fl">.275</span>, <span class="fl">.275</span>, <span class="fl">.45</span>, <span class="fl">.5</span>, <span class="fl">.5</span>, <span class="fl">.63</span>, <span class="fl">.8</span>, <span class="fl">.9</span>, <span class="fl">.9</span>, 
        <span class="fl">.9</span>, <span class="fl">.9</span>, <span class="fl">1.0</span>, <span class="fl">1.1</span>, <span class="fl">1.1</span>, <span class="fl">1.4</span>, <span class="fl">1.7</span>, <span class="fl">2.0</span>, <span class="fl">2.0</span>, <span class="fl">2.0</span>, <span class="fl">2.0</span><span class="op">)</span>
<span class="va">velocidad</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">170</span>, <span class="fl">290</span>, <span class="op">-</span><span class="fl">130</span>, <span class="op">-</span><span class="fl">70</span>, <span class="op">-</span><span class="fl">185</span>, <span class="op">-</span><span class="fl">220</span>, <span class="fl">200</span>, <span class="fl">290</span>, <span class="fl">270</span>, <span class="fl">200</span>, <span class="fl">300</span>, <span class="op">-</span><span class="fl">30</span>, <span class="fl">650</span>, 
        <span class="fl">150</span>, <span class="fl">500</span>, <span class="fl">920</span>, <span class="fl">450</span>, <span class="fl">500</span>, <span class="fl">500</span>, <span class="fl">960</span>, <span class="fl">500</span>, <span class="fl">850</span>, <span class="fl">800</span>, <span class="fl">1090</span><span class="op">)</span> 
<span class="va">ejer02</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">distancia</span>, <span class="va">velocidad</span><span class="op">)</span></code></pre></div>
<p>(HINT: En primer lugar debes transformar el modelo teórico propuesto para expresarlo en términos de un modelo RLS. Recuerda almacenar las transformaciones en tu banco de datos para proceder con el ajuste del modelo.)</p>
<p><strong>Ejercicio 3.</strong> Un grupo de ingenieros agrónomos esta estudiando la evolución de un proceso infeccioso sobre un conjunto de plantas. En concreto durante un período de días se calcula de forma aproximada la fracción de infección de dichas plantas. Por este motivo, dos días consecutivos pueden tener fracciones de infección inferiores. Para evitar esto se proponen dos modelos teóricos:
<span class="math display">\[(I) \text{  } y = \beta_0 x^{\beta_1}\]</span>
<span class="math display">\[(II) \text{  } y = \beta_0 + \beta_1 log(x)\]</span></p>
<p>donde y es el grado de infección y x el número de días transcurridos</p>
<div class="sourceCode" id="cb376"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dia</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">200</span>
<span class="va">infecc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.02063762</span>, <span class="fl">0.05637206</span>, <span class="fl">0.11889346</span>, <span class="fl">0.11376972</span>, <span class="fl">0.13772089</span>, <span class="fl">0.19055130</span>, 
      <span class="fl">0.18509772</span>, <span class="fl">0.16887353</span>, <span class="fl">0.19753055</span>, <span class="fl">0.21835949</span>, <span class="fl">0.26677238</span>, <span class="fl">0.26360653</span>, 
      <span class="fl">0.27772497</span>, <span class="fl">0.28447172</span>, <span class="fl">0.28300082</span>, <span class="fl">0.34108177</span>, <span class="fl">0.32594214</span>, <span class="fl">0.28675461</span>, 
      <span class="fl">0.34971616</span>, <span class="fl">0.33537176</span>, <span class="fl">0.33217888</span>, <span class="fl">0.35748261</span>, <span class="fl">0.34925483</span>, <span class="fl">0.36278067</span>, 
      <span class="fl">0.37211460</span>, <span class="fl">0.35783240</span>, <span class="fl">0.41498583</span>, <span class="fl">0.40769174</span>, <span class="fl">0.38800213</span>, <span class="fl">0.44174297</span>, 
      <span class="fl">0.43087261</span>, <span class="fl">0.42190606</span>, <span class="fl">0.45097338</span>, <span class="fl">0.45570700</span>, <span class="fl">0.45946960</span>, <span class="fl">0.46153400</span>, 
      <span class="fl">0.46340109</span>, <span class="fl">0.45549254</span>, <span class="fl">0.45487365</span>, <span class="fl">0.45750686</span>, <span class="fl">0.45521341</span>, <span class="fl">0.46881463</span>, 
      <span class="fl">0.45141048</span>, <span class="fl">0.52372846</span>, <span class="fl">0.50803021</span>, <span class="fl">0.46482596</span>, <span class="fl">0.48254773</span>, <span class="fl">0.48449405</span>, 
      <span class="fl">0.51255671</span>, <span class="fl">0.49833262</span>, <span class="fl">0.50802495</span>, <span class="fl">0.50526564</span>, <span class="fl">0.50777983</span>, <span class="fl">0.53873568</span>, 
      <span class="fl">0.50950327</span>, <span class="fl">0.54693458</span>, <span class="fl">0.48815063</span>, <span class="fl">0.53327501</span>, <span class="fl">0.52645577</span>, <span class="fl">0.53063462</span>, 
      <span class="fl">0.53618898</span>, <span class="fl">0.52077545</span>, <span class="fl">0.52633078</span>, <span class="fl">0.51474555</span>, <span class="fl">0.51575426</span>, <span class="fl">0.54528626</span>, 
      <span class="fl">0.55015967</span>, <span class="fl">0.54419107</span>, <span class="fl">0.56346905</span>, <span class="fl">0.58787669</span>, <span class="fl">0.53886562</span>, <span class="fl">0.50427534</span>, 
      <span class="fl">0.57230842</span>, <span class="fl">0.53970820</span>, <span class="fl">0.54179538</span>, <span class="fl">0.57769618</span>, <span class="fl">0.55308538</span>, <span class="fl">0.53593047</span>, 
      <span class="fl">0.56550374</span>, <span class="fl">0.56060245</span>, <span class="fl">0.56496884</span>, <span class="fl">0.57400395</span>, <span class="fl">0.56030226</span>, <span class="fl">0.58199322</span>, 
      <span class="fl">0.56606007</span>, <span class="fl">0.57844415</span>, <span class="fl">0.59505931</span>, <span class="fl">0.58311616</span>, <span class="fl">0.56916054</span>, <span class="fl">0.59989923</span>, 
      <span class="fl">0.59801493</span>, <span class="fl">0.59031303</span>, <span class="fl">0.58529898</span>, <span class="fl">0.56912505</span>, <span class="fl">0.61003513</span>, <span class="fl">0.57193641</span>, 
      <span class="fl">0.62878888</span>, <span class="fl">0.61677661</span>, <span class="fl">0.58247460</span>, <span class="fl">0.56770688</span>, <span class="fl">0.57505675</span>, <span class="fl">0.59541545</span>, 
      <span class="fl">0.58634056</span>, <span class="fl">0.58530427</span>, <span class="fl">0.57418797</span>, <span class="fl">0.59326985</span>, <span class="fl">0.57940758</span>, <span class="fl">0.56266765</span>, 
      <span class="fl">0.58932866</span>, <span class="fl">0.61620602</span>, <span class="fl">0.58719856</span>, <span class="fl">0.61173102</span>, <span class="fl">0.56806743</span>, <span class="fl">0.60015458</span>, 
      <span class="fl">0.61248238</span>, <span class="fl">0.60893367</span>, <span class="fl">0.60582869</span>, <span class="fl">0.59169408</span>, <span class="fl">0.58829584</span>, <span class="fl">0.58557803</span>, 
      <span class="fl">0.60917339</span>, <span class="fl">0.58862023</span>, <span class="fl">0.59849746</span>, <span class="fl">0.60391548</span>, <span class="fl">0.64663334</span>, <span class="fl">0.59742612</span>, 
      <span class="fl">0.61587231</span>, <span class="fl">0.61341390</span>, <span class="fl">0.59329848</span>, <span class="fl">0.61178139</span>, <span class="fl">0.64276168</span>, <span class="fl">0.62355522</span>, 
      <span class="fl">0.61599580</span>, <span class="fl">0.60735889</span>, <span class="fl">0.57537341</span>, <span class="fl">0.63968664</span>, <span class="fl">0.58846078</span>, <span class="fl">0.63307852</span>, 
      <span class="fl">0.65706008</span>, <span class="fl">0.59059116</span>, <span class="fl">0.63408846</span>, <span class="fl">0.61538542</span>, <span class="fl">0.58975607</span>, <span class="fl">0.59146830</span>, 
      <span class="fl">0.59028687</span>, <span class="fl">0.61224876</span>, <span class="fl">0.59417456</span>, <span class="fl">0.63770437</span>, <span class="fl">0.66647829</span>, <span class="fl">0.59925939</span>, 
      <span class="fl">0.64127259</span>, <span class="fl">0.64141050</span>, <span class="fl">0.63317968</span>, <span class="fl">0.60686830</span>, <span class="fl">0.62514131</span>, <span class="fl">0.62241142</span>, 
      <span class="fl">0.63976259</span>, <span class="fl">0.62153212</span>, <span class="fl">0.64899315</span>, <span class="fl">0.62242964</span>, <span class="fl">0.65143794</span>, <span class="fl">0.60985758</span>, 
      <span class="fl">0.60609047</span>, <span class="fl">0.69656194</span>, <span class="fl">0.62384676</span>, <span class="fl">0.63858650</span>, <span class="fl">0.64578674</span>, <span class="fl">0.62380855</span>, 
      <span class="fl">0.64424572</span>, <span class="fl">0.64170765</span>, <span class="fl">0.63043627</span>, <span class="fl">0.63646096</span>, <span class="fl">0.63488074</span>, <span class="fl">0.67853395</span>, 
      <span class="fl">0.62153691</span>, <span class="fl">0.61483840</span>, <span class="fl">0.63790480</span>, <span class="fl">0.64374543</span>, <span class="fl">0.64664922</span>, <span class="fl">0.62913057</span>, 
      <span class="fl">0.61740673</span>, <span class="fl">0.66430865</span>, <span class="fl">0.63241999</span>, <span class="fl">0.62246721</span>, <span class="fl">0.63541282</span>, <span class="fl">0.63655235</span>, 
      <span class="fl">0.66304830</span>, <span class="fl">0.64289529</span>, <span class="fl">0.65662894</span>, <span class="fl">0.63190605</span>, <span class="fl">0.64652159</span>, <span class="fl">0.63607656</span>, 
      <span class="fl">0.64479640</span>, <span class="fl">0.62532881</span>, <span class="fl">0.61734833</span>, <span class="fl">0.68383389</span>, <span class="fl">0.65622608</span>, <span class="fl">0.61950582</span>, 
      <span class="fl">0.63262438</span>, <span class="fl">0.62145169</span><span class="op">)</span> 
<span class="va">ejer03</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">dia</span>, <span class="va">infecc</span><span class="op">)</span></code></pre></div>
<p>Los modelos teóricos anteriores se pueden transformar a modelos de regresión lineal simple sin muchos problemas. Para el modelo (I) consideramos la transformación logarítmica:</p>
<p><span class="math display">\[log(y) = log(\beta_0) + \beta_1 log(x) \longrightarrow y' = \beta_0 + \beta_1 x'\]</span></p>
<p>donde el <span class="math inline">\('\)</span> indica la nueva variable o parámetro. Podemos estudiar el comportamiento lineal obteniendo dichas variables, y volver al modelo original utilizando las transformaciones.</p>
<p>Para el modelo (II) ya viene expresado como un modelo lineal donde únicamente tenemos que obtener la variable predictora transformada mediante la función logaritmo.</p>
<p><strong>Ejercicio 4.</strong> Se trata de determinar la pérdida de color sufrida por cierto compuesto cuando es sometido a altas temperaturas. Los datos recogidos son los siguientes:</p>
<div class="sourceCode" id="cb377"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">temperatura</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">460</span>, <span class="fl">450</span>, <span class="fl">440</span>, <span class="fl">430</span>, <span class="fl">420</span>, <span class="fl">410</span>, <span class="fl">450</span>, <span class="fl">440</span>, <span class="fl">430</span>, <span class="fl">420</span>, 
         <span class="fl">410</span>, <span class="fl">400</span>, <span class="fl">420</span>, <span class="fl">410</span>, <span class="fl">400</span><span class="op">)</span>
<span class="va">perdida</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.3</span>, <span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.4</span>, <span class="fl">0.6</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.6</span>, <span class="fl">0.6</span>, <span class="fl">0.7</span>, 
       <span class="fl">0.6</span>, <span class="fl">0.6</span>, <span class="fl">0.6</span>, <span class="fl">0.6</span><span class="op">)</span>
<span class="va">ejer04</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">temperatura</span>, <span class="va">perdida</span><span class="op">)</span></code></pre></div>
<p><strong>Ejercicio 5.</strong> Karl Pearson recogió información sobre 1100 familias en Inglaterra en el periodo de 1893 a 1898. En particular este banco de datos contiene las alturas de las madres y las hijas de dichas familias. En concreto se registran las alturas de las hijas mayores de 18 años y las madres de menos de 65 años. Originalmente se estaba interesado en estudiar una posible asociación entre la altura de las madres y las hijas ¿Que podríamos concluir a la vista de los datos? las variables recogidas son: “Mheight” (altura de la madre) y “Dheight” (altura de la hija)</p>
<div class="sourceCode" id="cb378"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"heights"</span><span class="op">)</span>
<span class="va">ejer05</span> <span class="op">&lt;-</span><span class="va">heights</span></code></pre></div>
<p><strong>Ejercicio 6.</strong> Se realiza un estudio de campo para conocer el desarrollo de cierta especie de pez del lago lakemary en EEUU. Para medir el desarrollo se establece la edad de cada pez capturado mediante un procedimiento proporcionado por los biólogos. Además se mide la longitud del pez para tratar de establecer el estado de maduración de cada ejemplar. La investigación trata de relacionar la longitud del pez con su edad para determinar el número de capturas permitidas. Las variables recogidas son: “Age” (edad del pez), y “Length” (longitud del pez en mm).</p>
<div class="sourceCode" id="cb379"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"lakemary"</span><span class="op">)</span>
<span class="va">ejer06</span> <span class="op">&lt;-</span><span class="va">lakemary</span></code></pre></div>
<p><strong>Ejercicio 7.</strong> Se realiza un estudio para determinar el tiempo de erupción del geyser (Old Faithful Geyser, dentro del parque nacional de Yellowstone) a partir del tiempo de espera entre dos erupciones consecutivas. Se trata de analizar la información para determinar el periodo de visitas. Para ellos se recogieron datos durante un periodo determinado que se considera estándar para establecer la distribución de erupciones. Las variables consideradas son: “Duration” (duración de la erupción en segundos) y “Interval” (tiempo de espera entres dos erupciones consecutivas).</p>
<div class="sourceCode" id="cb380"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"geyser"</span><span class="op">)</span>
<span class="va">ejer07</span> <span class="op">&lt;-</span><span class="va">geyser</span></code></pre></div>
<p><strong>Ejercicio 8.</strong> Los datos muestran el porcentaje de calorías totales obtenidas de carbohidratos complejos, para veinte diabéticos dependientes de insulina que habían seguido una dieta alta en carbohidratos durante seis meses. Se consideró que el cumplimiento del régimen estaba relacionado con la edad (en años), age, el peso corporal (relativo al peso “ideal” para la altura), weight, y otros componentes de la dieta como el porcentaje de proteínas ingeridas. Los datos corresponden con la tabla 6.3 de Dobson (2002).</p>
<div class="sourceCode" id="cb381"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ejer08</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"https://goo.gl/Grm8xM"</span>, col_types <span class="op">=</span> <span class="st">"dddd"</span><span class="op">)</span></code></pre></div>
<p><strong>Ejercicio 9.</strong> Es bien sabido que la concentración de colesterol en el suero sanguíneo aumenta con la edad, pero es menos claro si el nivel de colesterol también está asociado con el peso corporal. Los datos muestran para una treinta de mujeres el colesterol sérico (milimoles por litro), la edad (años) y el índice de masa corporal (peso dividido por la altura al cuadrado, donde el peso se midió en kilogramos y la altura en metros). Los datos corresponden con la tabla 6.17 de Dobson (2002).</p>
<div class="sourceCode" id="cb382"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ejer09</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"https://goo.gl/EKXWRc"</span>, col_types <span class="op">=</span> <span class="st">"ddd"</span><span class="op">)</span></code></pre></div>
<p><strong>Ejercicio 10.</strong> En un estudio sobre las diferentes clases de queso cheddar que se fabrican en LaTrobe Valley de Victoria, Australia, se analizaron muestras de queso por su composición química: concentración de ácido acético (escala logarítmica); concentración de sulfuro de hidrógeno (escala logarítmica); y la concentración de ácido láctico. Por otro lado, se paso una muestra de cada uno de ellos a un conjunto de catadores y se registro la puntuación obtenida por cada uno de ellos. Estamos interesados en relacionar la puntuación final de los catadores con los resultados del análisis químico.</p>
<div class="sourceCode" id="cb383"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ejer10</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"https://goo.gl/V4lDNs"</span>, col_types <span class="op">=</span> <span class="st">"dddd"</span><span class="op">)</span></code></pre></div>
<p><strong>Ejercicio 11.</strong> Los datos correspondientes a esta base de datos muestran la producción, Q, en toneladas, la mano de obra, L, en horas, y el capital, K, en horas máquina, de 14 empresas de un sector industrial. Se desea ajustar los datos a la función de producción Cobb-Douglas dada por:
<span class="math display">\[Q = A L^l K^k e^{\epsilon}\]</span></p>
<ul>
<li>Identifica el objetivo u objetivos del problema propuesto. Describe el tipo de variables involucradas para el modelo propuesto. Escribe los modelos, identifica el tipo, e indica el número de parámetros involucrados.</li>
<li>Ajusta los modelos mediante el proceso de selección de variables que consideres más adecuado. Describe los modelos obtenidos (ecuación del modelo) interpretando en términos económicos los coeficientes estimados de dicho modelo, y las medidas de bondad de ajuste de cada uno de ellos.</li>
<li>Realiza el diagnóstico del modelo ajustado indicando los gráficos utilizados y las conclusiones obtenidas. Si el modelo debe ser mejorados indica como lo haces, y describe los resultados del nuevo modelo obtenido.</li>
<li>¿Cuál es la predicción de la producción media para una empresa con 1900 horas de trabajo y 475 de capital? ¿Cuál consideras que es la combinación óptima para determinar las empresas más eficientes en términos de productividad?.</li>
</ul>
<div class="sourceCode" id="cb384"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ejer11</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="st">"https://bit.ly/2UIq9F9"</span>, col_types <span class="op">=</span> <span class="st">"dddd"</span><span class="op">)</span>
<span class="va">ejer11</span> <span class="op">&lt;-</span> <span class="va">ejer11</span> <span class="op"><a href="https://stringr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
 <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html">mutate_if</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/lapply.html">sapply</a></span><span class="op">(</span><span class="va">ejer11</span>, <span class="va">is.character</span><span class="op">)</span>, <span class="va">as.factor</span><span class="op">)</span></code></pre></div>
<p><strong>Ejercicio 12.</strong> La producción de cereales viene determinada principalmente por las condiciones climáticas previas a la recolección. En concreto se recogen las condiciones climáticas en diferentes años. Las características medidas son:</p>
<ul>
<li>anyo = año de la medición.</li>
<li>preinv = precipitación de invierno.</li>
<li>tempmay = temperatura de mayo.</li>
<li>prejun = precipitación de junio.</li>
<li>tempjun = temperatura de junio.</li>
<li>prejul = precipitación de julio.</li>
<li>tempjul = temperatura de julio.</li>
<li>preago = precipitación de agosto.</li>
<li>tempago = temperatura de agosto.</li>
<li>produccion = producción de cereales.</li>
</ul>
<p>Para el banco de datos correspondiente</p>
<ul>
<li>Propón el tipo de modelo a utilizar. Selecciona el mejor modelo basado en el AIC. Expresa el modelo obtenido y extrae todas las conclusiones que se deriven de él. ¿Crees que un procedimiento de selección basado en el test F proporcionaría el mismo modelo?</li>
<li>Las variables no incluidas en dicho modelo puede considerarse que no contribuyen a explicar la producción de cereales. ¿Qué haces para comprobar esto? ¿Las variables incluidas contribuyen de forma significativa a explicar la producción de cereales?</li>
<li>Realiza un análisis de influencia y comenta los resultados obtenidos. ¿Crees necesario plantear un nuevo modelo?</li>
<li>Comprueba las hipótesis sobre el modelo ajustado y comenta los resultados. Si resulta necesario propón un modelo alternativo y analízalo de forma completa.</li>
</ul>
<div class="sourceCode" id="cb385"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lectura</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"https://goo.gl/Yi5g6S"</span>, header <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="va">ejer12</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="va">lectura</span><span class="op">)</span></code></pre></div>
<p><strong>Ejercicio 13.</strong> En un estudio medio ambiental sobre la diversidad de especies de tortuga en las islas Galápagos se recogió información sobre el número de especies endémicas (Endemics), así como el área de la isla (área), la altura del pico más alto de a isla (Elevation), la distancia a la isla más cercana (Nearest), la distancia a la isla de Santa Cruz (Scruz), y el área de la isla más próxima (Adjacent).</p>
<p>El estudio está interesado las condiciones que pueden afectar a un mayor número de especies
endémicas de tortuga sin tener en cuenta el número total de especies presentes.</p>
<ul>
<li>Identifica la variable respuesta, las predictoras, y el tipo de cada una de ellas.</li>
<li>Realiza e interpreta los gráficos individuales descriptivos entre la respuesta y cada predictora de forma individual.</li>
<li>Para tratar de linealizar las relaciones entre respuesta y predictora se transforman tomas las variables con la función logaritmo neperiano. ¿Cómo se interpretan los gráficos individuales descriptivos entre las variables transformadas?</li>
<li>¿Qué tipo de modelo parece el más adecuado para esta situación experimental? Escribe la forma reducida de dicho modelo.</li>
<li>Partiendo del modelo más complejo y utilizando el AIC como criterio de selección, escribe la ecuación del modelo resultante del proceso de selección. ¿Qué podemos decir de la bondad del ajuste del modelo obtenido?</li>
<li>¿Cómo interpretamos los gráficos y test de diagnóstico asociados con el modelo obtenido?</li>
<li>Realiza un análisis de influencia y si lo consideras necesario ajusta un nuevo modelo y analízalo.</li>
<li>En función del modelo obtenido, construye diferentes escenarios para predecir el número de especies en una isla en función de las variables predictoras presentes en él. ¿Cuáles son las condiciones óptimas para la determinación de especies endémicas?</li>
</ul>
<div class="sourceCode" id="cb386"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Endemics</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">23</span>, <span class="fl">21</span>, <span class="fl">3</span>, <span class="fl">9</span>, <span class="fl">1</span>, <span class="fl">11</span>, <span class="fl">0</span>, <span class="fl">7</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">26</span>, <span class="fl">35</span>, <span class="fl">17</span>, <span class="fl">4</span>, <span class="fl">19</span>, <span class="fl">89</span>, <span class="fl">23</span>, 
<span class="fl">2</span>, <span class="fl">37</span>, <span class="fl">33</span>, <span class="fl">9</span>, <span class="fl">30</span>, <span class="fl">65</span>, <span class="fl">81</span>, <span class="fl">95</span>, <span class="fl">28</span>, <span class="fl">73</span>, <span class="fl">16</span>, <span class="fl">8</span>, <span class="fl">12</span><span class="op">)</span>
<span class="va">Area</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">25.09</span>, <span class="fl">1.24</span>, <span class="fl">0.21</span>, <span class="fl">0.1</span>, <span class="fl">0.05</span>, <span class="fl">0.34</span>, <span class="fl">0.08</span>, <span class="fl">2.33</span>, <span class="fl">0.03</span>, <span class="fl">0.18</span>, 
<span class="fl">58.27</span>, <span class="fl">634.49</span>, <span class="fl">0.57</span>, <span class="fl">0.78</span>, <span class="fl">17.35</span>, <span class="fl">4669.32</span>, <span class="fl">129.49</span>, <span class="fl">0.01</span>, <span class="fl">59.56</span>, <span class="fl">17.95</span>, 
<span class="fl">0.23</span>, <span class="fl">4.89</span>, <span class="fl">551.62</span>, <span class="fl">572.33</span>, <span class="fl">903.82</span>, <span class="fl">24.08</span>, <span class="fl">170.92</span>, <span class="fl">1.84</span>, <span class="fl">1.24</span>, <span class="fl">2.85</span><span class="op">)</span>
<span class="va">Elevation</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">346</span>, <span class="fl">109</span>, <span class="fl">114</span>, <span class="fl">46</span>, <span class="fl">77</span>, <span class="fl">119</span>, <span class="fl">93</span>, <span class="fl">168</span>, <span class="fl">71</span>, <span class="fl">112</span>, <span class="fl">198</span>, <span class="fl">1494</span>, 
<span class="fl">49</span>, <span class="fl">227</span>, <span class="fl">76</span>, <span class="fl">1707</span>, <span class="fl">343</span>, <span class="fl">25</span>, <span class="fl">777</span>, <span class="fl">458</span>, <span class="fl">94</span>, <span class="fl">367</span>, <span class="fl">716</span>, <span class="fl">906</span>, <span class="fl">864</span>, <span class="fl">259</span>, <span class="fl">640</span>, 
<span class="fl">147</span>, <span class="fl">186</span>, <span class="fl">253</span><span class="op">)</span>
<span class="va">Nearest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">0.6</span>, <span class="fl">2.8</span>, <span class="fl">1.9</span>, <span class="fl">1.9</span>, <span class="fl">8</span>, <span class="fl">6</span>, <span class="fl">34.1</span>, <span class="fl">0.4</span>, <span class="fl">2.6</span>, <span class="fl">1.1</span>, <span class="fl">4.3</span>, 
<span class="fl">1.1</span>, <span class="fl">4.6</span>, <span class="fl">47.4</span>, <span class="fl">0.7</span>, <span class="fl">29.1</span>, <span class="fl">3.3</span>, <span class="fl">29.1</span>, <span class="fl">10.7</span>, <span class="fl">0.5</span>, <span class="fl">4.4</span>, <span class="fl">45.2</span>, <span class="fl">0.2</span>, <span class="fl">0.6</span>, 
<span class="fl">16.5</span>, <span class="fl">2.6</span>, <span class="fl">0.6</span>, <span class="fl">6.8</span>, <span class="fl">34.1</span><span class="op">)</span>
<span class="va">Scruz</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.6</span>, <span class="fl">26.3</span>, <span class="fl">58.7</span>, <span class="fl">47.4</span>, <span class="fl">1.9</span>, <span class="fl">8</span>, <span class="fl">12</span>, <span class="fl">290.2</span>, <span class="fl">0.4</span>, <span class="fl">50.2</span>, <span class="fl">88.3</span>, 
<span class="fl">95.3</span>, <span class="fl">93.1</span>, <span class="fl">62.2</span>, <span class="fl">92.2</span>, <span class="fl">28.1</span>, <span class="fl">85.9</span>, <span class="fl">45.9</span>, <span class="fl">119.6</span>, <span class="fl">10.7</span>, <span class="fl">0.6</span>, <span class="fl">24.4</span>, <span class="fl">66.6</span>, 
<span class="fl">19.8</span>, <span class="fl">0</span>, <span class="fl">16.5</span>, <span class="fl">49.2</span>, <span class="fl">9.6</span>, <span class="fl">50.9</span>, <span class="fl">254.7</span><span class="op">)</span>
<span class="va">Adjacent</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1.84</span>, <span class="fl">572.33</span>, <span class="fl">0.78</span>, <span class="fl">0.18</span>, <span class="fl">903.82</span>, <span class="fl">1.84</span>, <span class="fl">0.34</span>, <span class="fl">2.85</span>, <span class="fl">17.95</span>, 
<span class="fl">0.1</span>, <span class="fl">0.57</span>, <span class="fl">4669.32</span>, <span class="fl">58.27</span>, <span class="fl">0.21</span>, <span class="fl">129.49</span>, <span class="fl">634.49</span>, <span class="fl">59.56</span>, <span class="fl">0.1</span>, <span class="fl">129.49</span>, 
<span class="fl">0.03</span>, <span class="fl">25.09</span>, <span class="fl">572.33</span>, <span class="fl">0.57</span>, <span class="fl">4.89</span>, <span class="fl">0.52</span>, <span class="fl">0.52</span>, <span class="fl">0.1</span>, <span class="fl">25.09</span>, <span class="fl">17.95</span>, <span class="fl">2.33</span><span class="op">)</span>
<span class="va">ejer13</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">Endemics</span>, <span class="va">Area</span>, <span class="va">Elevation</span>, <span class="va">Nearest</span>, <span class="va">Scruz</span>, <span class="va">Adjacent</span><span class="op">)</span></code></pre></div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="rls.html"><span class="header-section-number">6</span> Regresión Lineal Simple (RLS)</a></div>
<div class="next"><a href="anova.html"><span class="header-section-number">8</span> Modelos ANOVA</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#rlm"><span class="header-section-number">7</span> Regresión Lineal Múltiple y Polinómica</a></li>
<li>
<a class="nav-link" href="#tipos-de-modelos-1"><span class="header-section-number">7.1</span> Tipos de modelos</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#modelos-de-rlm"><span class="header-section-number">7.1.1</span> Modelos de RLM</a></li>
<li><a class="nav-link" href="#modelos-de-rp"><span class="header-section-number">7.1.2</span> Modelos de RP</a></li>
<li><a class="nav-link" href="#expresi%C3%B3n-en-r-de-los-modelos"><span class="header-section-number">7.1.3</span> Expresión en R de los modelos</a></li>
<li><a class="nav-link" href="#modelo-saturado-y-anidado"><span class="header-section-number">7.1.4</span> Modelo saturado y anidado</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#estimaci%C3%B3n-e-inferencia"><span class="header-section-number">7.2</span> Estimación e inferencia</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#m%C3%ADnimos-cuadrados"><span class="header-section-number">7.2.1</span> Mínimos cuadrados</a></li>
<li><a class="nav-link" href="#propiedades"><span class="header-section-number">7.2.2</span> Propiedades</a></li>
<li><a class="nav-link" href="#m%C3%A1xima-verosimilitud"><span class="header-section-number">7.2.3</span> Máxima verosimilitud</a></li>
<li><a class="nav-link" href="#inferencia"><span class="header-section-number">7.2.4</span> Inferencia</a></li>
<li><a class="nav-link" href="#ejemplos-3"><span class="header-section-number">7.2.5</span> Ejemplos</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#bondad-del-ajuste-1"><span class="header-section-number">7.3</span> Bondad del ajuste</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#tabla-anova"><span class="header-section-number">7.3.1</span> Tabla ANOVA</a></li>
<li><a class="nav-link" href="#coeficiente-determinaci%C3%B3n"><span class="header-section-number">7.3.2</span> Coeficiente determinación</a></li>
<li><a class="nav-link" href="#ejemplos-4"><span class="header-section-number">7.3.3</span> Ejemplos</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#comparaci%C3%B3n-y-selecci%C3%B3n-de-modelos"><span class="header-section-number">7.4</span> Comparación y selección de modelos</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#significatividad-de-los-predictores"><span class="header-section-number">7.4.1</span> Significatividad de los predictores</a></li>
<li><a class="nav-link" href="#estad%C3%ADsticos-aic-y-bic"><span class="header-section-number">7.4.2</span> Estadísticos AIC y BIC</a></li>
<li><a class="nav-link" href="#selecci%C3%B3n-autom%C3%A1tica"><span class="header-section-number">7.4.3</span> Selección automática</a></li>
<li><a class="nav-link" href="#funciones-en-r"><span class="header-section-number">7.4.4</span> Funciones en R</a></li>
<li><a class="nav-link" href="#ejemplos-5"><span class="header-section-number">7.4.5</span> Ejemplos</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#multicolinealidad"><span class="header-section-number">7.5</span> Multicolinealidad</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#causas"><span class="header-section-number">7.5.1</span> Causas</a></li>
<li><a class="nav-link" href="#efectos"><span class="header-section-number">7.5.2</span> Efectos</a></li>
<li><a class="nav-link" href="#diagn%C3%B3sticos"><span class="header-section-number">7.5.3</span> Diagnósticos</a></li>
<li><a class="nav-link" href="#soluciones"><span class="header-section-number">7.5.4</span> Soluciones</a></li>
<li><a class="nav-link" href="#ejemplos-6"><span class="header-section-number">7.5.5</span> Ejemplos</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#diagn%C3%B3stico"><span class="header-section-number">7.6</span> Diagnóstico</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#tipos-de-residuos"><span class="header-section-number">7.6.1</span> Tipos de Residuos</a></li>
<li><a class="nav-link" href="#linealidad"><span class="header-section-number">7.6.2</span> Linealidad</a></li>
<li><a class="nav-link" href="#homocedasticidad"><span class="header-section-number">7.6.3</span> Homocedasticidad</a></li>
<li><a class="nav-link" href="#normalidad-2"><span class="header-section-number">7.6.4</span> Normalidad</a></li>
<li><a class="nav-link" href="#incorrelaci%C3%B3n"><span class="header-section-number">7.6.5</span> Incorrelación</a></li>
<li><a class="nav-link" href="#soluciones-a-problemas-detectados-en-el-diagn%C3%B3stico-del-modelo"><span class="header-section-number">7.6.6</span> Soluciones a problemas detectados en el diagnóstico del modelo</a></li>
<li><a class="nav-link" href="#an%C3%A1lisis-de-influencia-1"><span class="header-section-number">7.6.7</span> Análisis de influencia</a></li>
<li><a class="nav-link" href="#funciones-para-diagn%C3%B3stico-e-influencia"><span class="header-section-number">7.6.8</span> Funciones para diagnóstico e influencia</a></li>
<li><a class="nav-link" href="#ejemplos-7"><span class="header-section-number">7.6.9</span> Ejemplos</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#predicci%C3%B3n"><span class="header-section-number">7.7</span> Predicción</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#estimaci%C3%B3n-de-la-respuesta-media."><span class="header-section-number">7.7.1</span> Estimación de la respuesta media.</a></li>
<li><a class="nav-link" href="#predicci%C3%B3n-de-nuevas-observaciones."><span class="header-section-number">7.7.2</span> Predicción de nuevas observaciones.</a></li>
<li><a class="nav-link" href="#ejemplos-8"><span class="header-section-number">7.7.3</span> Ejemplos</a></li>
</ul>
</li>
<li><a class="nav-link" href="#ejercicios"><span class="header-section-number">7.8</span> Ejercicios</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Modelos Estadísticos</strong>" was written by true, true. It was last built on 2022-03-25.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
